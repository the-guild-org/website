import withArticle from '../../ui/blog/article';

export const meta = {
  title: 'Subscriptions and Live Queries - Real Time with GraphQL',
  author: 'laurin',
  tags: ['graphql', 'subscription', 'real-time'],
  date: '2020-10-12',
  description:
    "GraphQL subscriptions are used by many. Live Query Adoption, however, has not advanced that much. Let's take a look at both methods for achieving real-time with GraphQL.",
  image: '',
};

export default withArticle({ ...meta });

Subscriptions are the goto solution for adding real-time capabilities to a GraphQL powered application. At the same time the term GraphQL Live Query floats around and you can often see it being mentioned in the context of subscriptions.

While [GraphQL Subscriptions are part of the GraphQL Specification](https://spec.graphql.org/draft/#sec-Subscription) for some time, GraphQL Live Queries are not part of the specification and further there is no RFC going on.

However, [discussion about GraphQL Live Queries started way back when GraphQL Subscriptions were designed](https://github.com/graphql/graphql-spec/issues/284).

So let's take a recap of GraphQL Subscriptions, take a look at existing Live Query Solutions today and compare the differences between the two solutions for real-time.

# Subscription Recap

The [GraphQL Subscription RFC was merged back in March 2017](https://github.com/graphql/graphql-spec/pull/267).
The first major and wide-adopted transport implementation was (and probably is) [`subscriptions-transport-ws`](https://www.npmjs.com/package/subscriptions-transport-ws) developed by Apollo, unfortunately they seem to have abandoned it since then. Fortunately, we now have a successor [`graphql-transport-ws`](https://github.com/enisdenjo/graphql-transport-ws).

A subscription operation looks similar to this.

```graphql
subscription onPostAddedSubscription {
  onPostAdded {
    post {
      id
      author {
        id
        login
      }
    }
  }
}
```

In contrast to GraphQL query operation a subscription operation is only allowed to select a single field on the GraphQL Subscription root type.

Furthermore, executing a subscription operation represents a stream of results where executing a query operation only results in a single result.

Let's take a quick look at the `graphql-js` reference implementation!

Since promises can not represent multiple values over time, the `graphql-js` reference implementations uses [`AsyncIterator`](https://tc39.es/ecma262/#sec-asynciterable-interface), which is a native structure similar to Obserables (which you might already know if you have digged a bit deeper into the most-widely adopted GraphQL client frameworks).

Each subscription root field must provide a `subscribe` function that returns an `AsyncIterator` and optionally has `resolve` function for mapping the published events.

When a subscription operation is executed, the `subscribe` function of that field resolver is called and the `AsyncIterator` returned by it will be used as the source for the source of events.

Once the `AsyncIterator` publishes a value (payload/event), the optional `resolve` function on the selected subscription root field, is called with the value. All following resolvers in the resolver/type tree behave like normal query resolvers.

The most basic implementation for a counter would look similar to this:

```ts
const sleep = (t = 1000) => new Promise((res) => setTimeout(res, t));

const resolvers = {
  Subscription: {
    countToNumber: {
      subscribe: async function* (_, args) {
        for (let counter = 1; counter <= args.toNumber; counter++) {
          yield { countToNumber };
          await sleep();
        }
      },
    },
  },
};
```

The above subscription will count up to the number provided via the `toNumber` argument (while having a delay of one second between each message) and then complete.

Of course in a real-world application you would want to subscribe to other event sources instead of some static pre-defined events.

The most common used library for such a PubSub engine is [`graphql-subscriptions`](https://github.com/apollographql/graphql-subscriptions).
There are also adapters available for more distributed systems (where all GraphQL API replicas must be notified about the event) e.g. over Redis.

Let's take a look at a more "real-world" like example:

```ts
const resolvers = {
  Subscription: {
    onPostAdded: {
      subscribe: async function* () {
        for await (const { id } of context.pubSub.subscribe('POST_ADDED')) {
          const post = await context.postStore.load(id, context.viewer);
          if (post === null) {
            continue;
          }
          yield { onPostAdded: loadedPost };
        }
      },
    },
  },
  Mutation: {
    postAdd: (_, args, context) => {
      const post = context.postStore.create(args);
      // wo don't wanna publish the whole object via our event emitter, the id should be sufficient
      context.pubSub.emit('POST_ADDED', { id: args.id });
      return post;
    },
  },
};
```

Until now we only took a look a the resolvers. Let's also quickly check the `subscribe` function exported from `graphql-js`, which can be used for executing subscriptions.

```ts
import { subscribe } from 'graphql';

const subscribeResult = await subscribe({
  schema,
  document,
});

if (isAsyncIterable(subscribeResult)) {
  for await (const executionResult of subscribeResult) {
    sendToClient(executionResult);
  }
} else {
  sendToClient(subscribeResult);
}
```

The `subscribe` function returns either a `AsyncIterable` that publishes multiple `ExecutionResult`s or a single `ExecutionResult` in case the setup of the subscription somehow fails.

The interesting thing is that you can use any transport you want for delivering the results to client. The most popular implementation (as mentioned before) is `subscriptions-transport-ws`.
Unfortunately, it is poorly mainted therefore the GraphQL Working Group came up with a new implementation over Websockets, [`graphql-ws`](https://github.com/enisdenjo/graphql-ws)

But you are not forced to use WebSockets at all. HTTP Long-Polling (e.g. via [Server Side Events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events)) might be a more lightweigt solution. For both our server and client.

It is actually a shame that the default `express-graphql` reference HTTP transport implementation does not come with a built-in subscription solution.

Fortunately, libraries like [graphql-helix](https://github.com/danielrearden/graphql-helix) have emerged, which in my humble opinion, should replace the reference HTTP implementation, as it is furthermore not tied to any web server framework.

For public GraphQL APIs I am convinced that Server Sent Events is the future as there is less work required for implementing the protocol.

I also built [my own transport over Socket.io](https://github.com/n1ru4l/graphql-live-queries/tree/main/packages/socket-io-graphql-server), which uses WebSockets by default and HTTP polling as a fallback.

We are free to choose what kind of transport you want to use depending on our needs!

---

Now that we took a look on how GraphQL Subscription resolvers are implemented on the server-side, lets also check out how we can consume the GraphQL API on the client-side!

Usually you will have a network interface that is called by you favorite GraphQL client. Every single one has a different naming and approach of how they work. Apollo calls them links, relay calls the fetcher functions, and urql calls them exchanges.

All of them have one thing in common. They are working with observable like data structures, which basically means all major GraphQL client-libraries decided to use Observables for consuming subscriptions, those in contrast to AsyncIterators are not part of the ECMA Spec (as of October 2020).

Like AsyncIterators a Observable can represent multiple values. As already mentioned client library network interface and transport has a slightly different interface I will use `graphql-ws` with `relay-runtime` as an example.

The example is taken straight from the `graphql-ws` section.

```ts
import {
  Network,
  Observable,
  RequestParameters,
  Variables,
} from 'relay-runtime';
import { createClient } from 'graphql-ws';

const subscriptionsClient = createClient({
  url: 'wss://i.love/graphql',
  connectionParams: () => {
    const session = getSession();
    if (!session) {
      return {};
    }
    return {
      Authorization: `Bearer ${session.token}`,
    };
  },
});

// yes, both fetch AND subscribe handled in one implementation
function fetchOrSubscribe(operation: RequestParameters, variables: Variables) {
  return Observable.create((sink) => {
    if (!operation.text) {
      return sink.error(new Error('Operation text cannot be empty'));
    }
    return subscriptionsClient.subscribe(
      {
        operationName: operation.name,
        query: operation.text,
        variables,
      },
      {
        ...sink,
        error: (err) => {
          if (err instanceof Error) {
            sink.error(err);
          } else if (err instanceof CloseEvent) {
            sink.error(
              new Error(
                `Socket closed with event ${err.code}` + err.reason
                  ? `: ${err.reason}` // reason will be available on clean closes
                  : ''
              )
            );
          } else {
            // GraphQLError[]
            sink.error(new Error(err.map(({ message }) => message).join(', ')));
          }
        },
      }
    );
  });
}

const network = Network.create(fetchOrSubscribe, fetchOrSubscribe);
const store = new Store(new RecordSource());
export const environment = new Environment({ network, store });
```

With this configuration, relay can now execute subscription operations. Because the graphql-ws protocol is way more complex than the GraphQL over HTTP protocol, we use the client exported from the graphql-ws package instead. Some additional bundle-size we got there. As mentioned before SSE might be a better light-weight alternative.

That aside, let's start with a basic subscription that should update one of our components.

Our `PostRender` already shows some content.

```ts
const PostQuery = graphql`
  query PostQuery($postId: ID!) {
    post(id: $postId) {
      id
      title
      content {
        text
      }
      totalLikeCount
    }
  }
`;

const PostRenderer = ({ postId }: { postId: string }) => {
  const { props } = useQuery(PostQuery, /* variables */ { postId });

  return <Post {...props} />;
};
```

As a new feature requirement, the like count of the post should get updated once someone hits the like button.

We could choose different ways of implementing such a subscription.

1. General Subscription for changed post

```graphql
subscription PostChanged($postId: ID!) {
  onPostChanged(postId: $postId) {
    post {
      id
      totalLikeCount
    }
  }
}
```

2. Specific Subscription

```graphql
subscription PostLikeCountChanged($postId: ID!) {
  onPostLikeCountChanged(postId: $postId) {
    totalLikeCount
  }
}
```

Both solutions have different implications.

1. General Subscription for changed post

It is not limited to notifying whether the `totalLikeCount` of the post likes have changed, in the future we could adjust the selection set on the post field as it also returns a `Post` type similar to our already existing `Query.post` field.
It will automatically update the post record already in the cache as the relay store (or apollo-store) can identify the post object via the id field.
The drawback is that you could potentially send too much data over the wire. E.g. if we also wanted to subscribe to title changes all additional selected fields are sent to the client each time the underlying event is emitted, even if only the `totalLikeCount` value has changed.

```tsx
const PostChangedSubscription = graphql`
  subscription PostChanged($postId: ID!) {
    onPostChanged(postId: $postId) {
      post {
        id
        totalLikeCount
      }
    }
  }
`;

const PostRenderer = ({ postId }: { postId: string }) => {
  const { props } = useQuery(PostQuery, /* variables */ { postId });
  // thats all we gotta do
  useSubscription(PostChangedSubscription, /* variables */ { postId });

  return <Post {...props} />;
};
```

2. Specific Subscription

This subscription is specifically designed for only an update of the `totalCount`. However, the subscription result returns no `Post` type. Therefore we cannot make use of the automatic cache updates via the `id`.
We have to additionally define a handler for updating the post in the cache.

```tsx
const PostLikeCountChangedSubscription = graphql`
  subscription PostLikeCountChanged($postId: ID!) {
    onPostLikeCountChanged(postId: $postId) {
      totalCount
    }
  }
`;

const PostRenderer = ({ postId }: { postId: string }) => {
  const { props } = useQuery(PostQuery, /* variables */ { postId });
  useSubscription(
    PostLikeCountChangedSubscription,
    /* variables */ { postId },
    {
      // we need to manually update the cache :(
      updater: (payload, cache) => {
        const record = cache.read(PostQuery, { postId });
        if (record) {
          record.likes.totalCount = payload.onPostLikeCountChanged.totalCount;
        }
      },
    }
  );

  return <Post {...props} />;
};
```

Obviously, for this example, no sane person would actually want to choose the second solution over the first one.

But as our business requirements might get more complex you might need to do manual cache updates.

A very good example for this is lists. Imagine you have a table of data and one item changes.
The easy solution is to just refetch a complete list every time a single item is added/removed/changed.
However, For a list containing hundreds of items only sending the changed item to the client might be the smarter solution...

This can be implemented via a union type.

```graphql
type OnUserAdded {
  user: User!
}
type OnUserRemoved {
  removedUserId: ID!
}

union OnUserListChange = OnUserAdded | OnUserRemoved

type Subscription {
  onUserListChange: OnUserListChange!
}
```

The corresponding code, including handling the cache updates:

```tsx
const UserListQuery = graphql`
  query UserListQuery {
    users {
      id
      name
    }
  }
`

const UserListChangeSubscription = graphql`
  subscription UserListChangeSubscription {
    onUserListChange {
      __typename
      ... on OnUserAdded {
        user {
          id
          name
        }
      }
      ... on OnUserRemoved {
        removedUserId
      }
    }
  }
`

const UserListRenderer = ({ postId }: { postId: string}) => {
  const {props} = useQuery(UserListQuery)
  useSubscription(UserListChangeSubscription,  /* variables */ { postId }, {
    // we need to manually update the cache :(
    updater: (payload, cache) => {
      const record = cache.readQuery(UserListQuery)
      switch (payload.onUserListChange.__typename) {
        case "OnUserAdded": {
          record.users.push(payload.onUserListChange.user)
          break;
        }
        case "onUserRemoved": {
          record.users = record.users.filter(user => user.id !=== payload.onUserListChange.removedUserId)
          break;
        }
      }
    }
  })

  return <UserList {...props} />
}
```

As our application grows the manual cache update code can become so complex and confusing that I have considered switching back into simply refetching the queries in some application.

Fortunately, Relay contributers have [worked on some nice query directives](https://github.com/facebook/relay/issues/3123) that allow reducing such cache update code. It won't cover all cases though.

In all of the above examples we responded (more or less implicit) to data change events.

Subscriptions can be used to apply data changes on the client. But they are probably not the best tool for that.

Before taking a look of what could be a better tool, let's look at another usage example for subscriptions.

```tsx
const OnPlaySound = graphql`
  subscription OnPlayChatSound {
    onPlayChatSound {
      soundUrl
    }
  }
`;

const ChatRenderer = () => {
  const chat = useQuery(ChatQuery);
  useSubscription(OnPlaySound, {
    onNext: (payload) => {
      playSound(payload.onPlayChatSound.soundUrl);
    },
  });

  return <Chat chat={chat} />;
};
```

The difference here is that we are not manipulating our existing data but rather executing a side effect.

Subscriptions can also be used for side-effects that should not alter or touch any data in the cache.

# Live Queries

What is a live query? Well... there is no specification for that so the term is ambiguous. Today, there are several solutions used one could describe as live-queries.

All those solutions have one thing in common: **Trying to keep the Client State in Sync with the Server**.

Which can be paraphrased as **observing data**.

Before we take a look at how all of those implementations, let's break down what we should expect from a live query implementation.

1. Automatically update the execution result once the underlying data selected by the operation changes

2. Efficiently send the updates to the client

3. Don't rely on any specific database/vendor lock-in

4. Easy to adopt with existing GraphQL schema

## Polling a Query

The most easily solution for implementing live queries would be to poll a query in intervalls. Most GraphQL clients have such a feature already implemented.

```ts
const PostQuery = graphql`
  query PostQuery($postId: ID!) {
    post(id: $postId) {
      id
      title
      content {
        text
      }
      likes {
        totalCount
      }
    }
  }
`;

const PostRenderer = ({ postId }: { postId: string }) => {
  const { props } = useQuery(
    PostQuery,
    /* variables */ { postId },
    {
      pollIntervall: 5000,
    }
  );

  return <Post {...props} />;
};
```

Another drawback would be that a lot more data than necessary could be transported over the wire to the client. Even if nothing has changed from the last poll intervall.

1. Automatically updates execution result. **No.** âŒ

Depending upon the use-case that could be a valid solution, but for true real-time applications that require instant feedback a delay of the poll intervall could not be precise enough.

2. Efficiently send updates to client. **No.** âŒ

The whole execution result is sent over to the client for every single time the operation is re-executed.

3. Don't rely on any specific database/vendor lock-in. **Yes.** âœ…

Straight forward, as this does not rely needs any changes on the backend.

4. Easy to adopt with existing GraphQL schema. **Yes.** âœ…

See above ðŸ˜Š

## Live Queries over Subscriptions

We already had a "live query over subscription"-like example above.

```tsx
const PostChangedSubscription = graphql`
  subscription PostChanged($postId: ID!) {
    onPostChanged(postId: $postId) {
      post {
        id
        title
        likes {
          totalCount
        }
      }
    }
  }
`;

const PostRenderer = ({ postId }: { postId: string }) => {
  const { props } = useQuery(PostQuery, /* variables */ { postId });
  // thats all we gotta do
  useSubscription(PostChangedSubscription, /* variables */ { postId });

  return <Post {...props} />;
};
```

Let's ditch the `PostQuery` completely and instead use a `PostSubscription` that always emits an initial event.

```tsx
const PostSubscription = graphql`
  subscription PostSubscription($postId: ID!) {
    post(id: $postId) {
      id
      title
      likes {
        totalCount
      }
    }
  }
`;

const PostRenderer = ({ postId }: { postId: string }) => {
  const { props } = useSubscription(
    PostChangedSubscription,
    /* variables */ { postId }
  );

  return <Post {...props} />;
};
```

A server resolve implementatin could look similar to this:

```tsx
const resolvers = {
  Subscription: {
    post: async function* (_, { id }, context) {
      let loadPost = () => context.postStore.load(id, context.viewer);
      // publish first post
      yield { post: await loadPost() };
      // publish post again once change event is emitted
      for await (const _ of context.pubSub.subscribe(`Post:${id}`)) {
        yield { post: await loadPost() };
      }
    },
  },
};
```

We replace two operations with a single one!

A similar approach is used by [Hasura](https://github.com/hasura/graphql-engine/blob/master/architecture/live-queries.md) and also [PostGraphile](https://www.graphile.org/postgraphile/live-queries/).

The obvious drawback of both platforms is the lock-in into using a specific database. Of course that might not be a problem for most people, but having a general solution that works with any data source would be nice as more complex schema could fetch from different database types or other third party APIs.

Those implementations keep track of all the resources in the execution result and re-execute the subscription operation once any of those resources changes.

The resolver implementation above only responds to emitted post changes. In order keep track of all the resources defined in a operation documents selection set, we will have to come up with a smart abstraction.

Another drawback of subscriptions for live queries is the limitation of only selecting one root subscription field, which is defined by the GraphQL subscription specification. Furthermore, we must also redeclare our query type fields to the subscription type.

There is a workaround we can apply for re-exporting the whole Query type via a sub-field in the subscription type.

```graphql
type Query {
  user(id: ID!): User
  post(id: ID!): Post
}

type Subscription {
  live: Query!
}
```

This approach would allow us to query everything on the query object type via the live field on the subscription object type, without having the limit of only being able to query one resource or having to redeclare every resource field resolver on the subscription type. Neat!

```ts
const PostSubscription = graphql`
  subscription PostSubscription($postId: ID!, $userId: ID!) {
    live {
      post(id: $postId) {
        id
        title
        totalLikeCount
      }
      user(id: $userId) {
        id
        name
      }
    }
  }
`;
```

Okay, now we can select everything we could have selected with our query operation!

1. Automatically updates execution result. **Yes.** âœ…

When using services as Postgraphile and Hasura that is the case. However, if you have any additional resolvers that are added on top of the service schema you cannot implement invalidation for those. In user-land we will have to come up with an implementation of resource tracking by ourselves.

2. Efficiently send updates to client. **No.** âŒ

The whole execution result is sent over to the client for every single time a live query got invalidated.

3. Don't rely on any specific database/vendor lock-in. **Kind of.** âœ³ï¸

For Hasure and Postgraphile? Yes. For our own solution? No!

4. Easy to adopt with existing GraphQL schema. **No.** âŒ

Switching to a framework like Postgraphile or Hasura is no easy task with an existing schema.

## GraphQL Live Queries over Subscriptions with JSON patch

Ideally, we only wanna send a patch to the client that gives instructions how to get from the previous execution result to the next. That has been a big flaw in the previous two implementations.

The RFCs and implementations for the `@defer` and `@stream` introduced ways of sending (delayed) partial results to clients. However, those "patch" operations are currently highly limited to a "replace at path" and "append to list" operation.

A format such as [JSON Patch](https://tools.ietf.org/html/rfc6902) might be a better alternative for live queries.

Lets take a look at a library that actually tried to solve that exact problem with a `live` field that exposes both a result and a JSON patch field: [`graphql-live-subscriptions`](https://github.com/D1plo1d/graphql-live-subscriptions).

**Schema Types for `graphql-live-subscriptions`**

```graphql
scalar JSON

type RFC6902Operation {
    op: String!
    path: String!
    from: String
    value: JSON
  }

type Subscription {
  live: {
    patch: [RFC6902Operation]
    query: Query
  }
}
```

A live query operation can be declared similar to our `PostSubscription` document above.

```ts
const PostSubscription = graphql`
  subscription PostSubscription($postId: ID!, $userId: ID!) {
    live {
      query {
        post(id: $postId) {
          id
          title
          totalLikeCount
        }
        user(id: $userId) {
          id
          name
        }
      }
      patch {
        op
        path
        from
        value
      }
    }
  }
`;
```

The difference is that the type returned by the `live` field has now two fields instead of a single one that represents the `Query` object type. A `query` field, which selects the selection set from above and a `patch` field which is a JSON Patch operation. When executing the given operation against the server the first resul will have the data selected by the `query` field selection set included. All following values, will have no `query` value (`null`) but instead a array of patch operations that describe the changes for updating the last result to the next result.

The clients must then implement the logic for [applying the patch operation to their client cache](https://github.com/n1ru4l/graphql-live-chat/blob/master/packages/frontend/src/jsonpatch.ts). [You can find a example app with both backend and frontend over here](https://github.com/n1ru4l/graphql-live-chat).

The server implementation uses a event emitter and a immutable state tree for detecting changes that must be sent to clients. The patch is automatically generated from the next immutable state that is compared against the last which got emitted via an `EventEmitter`.

While the idea is quite nice the implementation is obviously meant for backends that already use reactive or immutable data structures. Having to rewrite our existing GraphQL layer for supporting live queries is a big trade-off.
Furthermore, the library is not maintained that well. My PRs for making the library compatible with recent GraphQL versions were not merged. Using unions and interfaces was impossible
Having to patch a library with `patch-package` before even being usable is generally a bad sign.

1. Automatically updates execution result. **Yes.** âœ…

If we implement our schema conform to the library, this library delivers precise results once the immutable state has changed.

2. Efficiently send updates to client. **Yes.** âœ…

Initially a result tree is sent to the client. Afterwards, only JSON patches that must be applied to the initial result are sent to the client.

3. Don't rely on any specific database/vendor lock-in. **Kind of.** âœ³ï¸

You don't rely on any third party services, however you are kind of forced into immutability.

4. Easy to adopt with existing GraphQL schema. **It depends.** âœ³ï¸

Adding a immutable layer to our existing schema might be a pretty big change.

## GraphQL Live Queries via the `@live` directive

There are companies out there, like [Facebook](https://www.youtube.com/watch?v=BSw05rJaCpA), that are already using this approach. There is also a graphql framework available in go that supports live queries out of the box! Check out [thunde](https://github.com/samsarahq/thunder).

The idea behind the `@live` directive is that it is used to mark that the client is interested in keeping that query execution result as up to date as possible. The implementation, however, is up to user-land.

```graphql
query($id: ID!) @live {
  post(id: $id) {
    id
    title
    totalLikeCount
  }
}
```

The idea of just making any query without additional overhead a live query is very appealing from the view of a frontend developer.
From a backend perspective, however that raises new questions.
Just adding adirective on the operation on frontend won't make the whole backend reactive.

After having built an example app with `graphql-live-subscriptsions` from scratch, studing the flaws of that library and being uncomfortable with the vendor lock-in of services such as Postgraphile and Hasura, I decided to approach the problem of live queries in a more pluggable way, by using the `@live` directive.

### `@n1ru4l/graphql-live-query` A common definition and set of utilities for determining of a live query

This module provides two things.

1. `GraphQLLiveDirective` that can be added to any schema.

```ts
import { GraphQLSchema, specifiedDirectives } from 'graphql';
import { GraphQLLiveDirective } from '@n1ru4l/graphql-live-query';
import { query, mutation, subscription } from './schema';

const schema = new GraphQLSchema({
  query,
  mutation,
  subscription,
  directives: [
    GraphQLLiveDirective,
    /* Keep @defer/@stream/@if/@skip */ ...specifiedDirectives,
  ],
});
```

2. `isLiveQueryOperationDefinitionNode`

This is a simple function that takes a `DocumentNode` and returns `true` if it is a live query document.

Those two utility functions can be used for any live query implementation.

### `@n1ru4l/in-memory-live-query-store` Keep track and invalidate resources selected by a live query in a efficient, but in generic way

The `InMemoryLiveQueryStore.execute` function is a drop in replacement for the `execute` function provided by the `graphql` package.

When encountering a query operation that is marked with the `@live` directive it will return a `AsyncIterator` instead of a `Promise` that can be used for sending multiple results to the client. Similar to how `subscribe` works.

Internally, the store keeps track of the resources selected in the live query operation selection set.
That means all root query field coordinates (e.g. `Query.post`) and global resource identifiers (e.g. `Post:1`).
The store can than be notified to re-execute live query operations that select a given root query field or resource identifier via the `InMemoryLiveQueryStore.invalidate` method with the corresponding resource identifier or field coordinates.
A resource identifier is composed out of the typename and the actual resolved id value separated by a colon, but can be customized.
For ensuring that the store keeps track of all our query resources we should always select the id field on our object types. The store will only keep track of fields with the name id and the type `ID!` (`GraphQLNonNull(GraphQLID)`).

```ts
import { InMemoryLiveQueryStore } from '@n1ru4l/in-memory-live-query-store';
import { parse } from 'graphql';
import { schema } from './schema';

const inMemoryLiveQueryStore = new InMemoryLiveQueryStore();

const rootValue = {
  todos: [
    {
      id: '1',
      content: 'Foo',
      isComplete: false,
    },
  ],
};

inMemoryLiveQueryStore
  .execute({
    schema,
    operationDocument: parse(/* GraphQL */ `
      query todosQuery @live {
        todos {
          id
          content
          isComplete
        }
      }
    `),
    rootValue: rootValue,
    contextValue: {},
    variableValues: null,
    operationName: 'todosQuery',
  })
  .then(async (result) => {
    if (isAsyncIterable(result)) {
      for (const value of result) {
        // Send to client in real-world app :)
        console.log(value);
      }
    }
  });

// Invalidate by resource identifier
rootValue.todos[0].isComplete = true;
inMemoryLiveQueryStore.invalidate(`Todo:1`);

// Invalidate by root query field coordinate
rootValue.todos.push({ id: '2', content: 'Baz', isComplete: false });
inMemoryLiveQueryStore.invalidate(`Query.todos`);
```

If you are using a ORM library such as prisma you can simply add a middleware for automatically invalidating resource.

**Use prisma middleware for resource invalidation**

```ts
// Register Middleware for automatic model invalidation
prisma.$use(async (params, next) => {
  const resultPromise = next(params);

  if (params.action === 'update') {
    resultPromise.then((res) => {
      if (res?.id) {
        // invalidate `Post:1` on update
        liveQueryStore.invalidate(`${params.model}:${res.id}`);
      }
    });
  }

  return resultPromise;
});
```

The transports `graphql-ws` (GraphQL over WebSocket), `graphql-helix` (GraphQL over SEE) and `@n1ru4l/socket-io-graphql-server` (GraphQL over Socket.io), support providing a custom `execute` function that is allowed to return AsyncIterables (thanks to the recent changes required for `@defer` and `@stream`).
All we have to do is to pass the `InMemoryLiveQueryStore.execute` to our server!

### `@n1ru4l/graphql-live-query-patch`

Optional JSON patch middleware for smaller payloads over the wire.

Instead of making JSON patch required be default, it is a totally optional module, that can be applied on the client and the server for deflating (create patches on the server) and inflating (apply patches on the client) the execution results.
Smaller projects might even be better off not using JSON patch at all, as the patch payload might be bigger as the whole query result.

On the server adding the patch generation middleware is easy function compositon:

```ts
import { flow } from 'io-ts/lib/function';
import { applyLiveQueryPatchDeflator } from '@n1ru4l/graphql-live-query-patch';

const execute = flow(liveQueryStore.execute, execute);
// same as, but less noisy :)
const execute0 = (...args) => execute(liveQueryStore.execute(...args));
```

The patches are created by comparing the latest execution result with the previous execution result.
That means the server will always have to store the latest execution result as long as the live query is active.

On the client applying the middleware is pretty easy as well!

```ts
import { flow } from 'io-ts/lib/function';
import { createLiveQueryPatchInflator } from '@n1ru4l/graphql-live-query-patch';

const execute = compose(networkInterface.execute, createLiveQueryPatchInflator);
// same as, but less noisy :)
const execute0 = (...args) => execute(networkInterface.execute(...args));
```

The library is optimized for network interfaces that return AsyncIterables, but anything can be easily wrapped into a AsyncIterator!

**Example with `graphql-ws`**

```ts
import { pipe } from 'io-ts/lib/function';
import { makeAsyncIterableIteratorFromSink } from '@n1ru4l/push-pull-async-iterable-iterator';
import { applyLiveQueryPatchInflator } from '@n1ru4l/graphql-live-query-patch';
import { createClient } from 'graphql-ws/lib/use/ws';

const client = createClient({
  url: 'ws://localhost:3000/graphql',
});

const asyncIterator = pipe(
  makeAsyncIterableIteratorFromSink((sink) => {
    const dispose = client.subscribe(
      {
        query: 'query @live { hello }',
      },
      {
        next: sink.next,
        error: sink.error,
        complete: sink.complete,
      }
    );
    return () => dispose();
  }),
  applyLiveQueryPatchInflator
);

// stop live query after 5 seconds.
setTimeout(() => {
  asyncIterator.return();
}, 5000);

for await (const executionResult of asyncIterator) {
  console.log(executionResult);
}
```

So let's take a look at this implementation regarding the aspects we used before.

1. Automatically updates execution result. **Yes.** âœ…

The approach of pushing the invalidation responsibility to the user might at first seem like a drawback, but a smart abstraction (such as a ORM middleware), can result in pretty responsive applications.

2. Efficiently send updates to client. **Yes.** âœ…

In caase our execution result payloads are getting to big you can easily enable JSON patches with a middleware.
Furthermore, the middleware is totally live query implementation independent!
That means if our projects requires a different implementation of the live query engine, the middleware can still be applied as long as the execution result is compatible with the live query execution result format.

3. Don't rely on any specific database/vendor lock-in. **Yes.** âœ…

You can use this with any database or third party api, as long as you can invalidate the resources.

4. Easy to adopt with existing GraphQL schema. **Yes.** âœ…

This library to can be added to any existing GraphQL.js schema without hazzle. Resource invalidation code can be added to the mutation resolvers over time as parts as frontend developers complain about live queries not updating.
The possibilities of resource invalidation are endless and the logic for those can be added incrementally.
E.g. via a ORM middleware, in our mutation code or maybe even on our GraphQL gateway.

[GraphQL Live Query libraries and example todo app that sync across all connected clients.](https://github.com/n1ru4l/graphql-live-query)

[More information on how the `InMemoryLiveQueryStore` keeps track of resources here.](https://dev.to/n1ru4l/collecting-graphql-live-query-resource-identifier-with-graphql-tools-5fm5)

## What's next?

I hope that more people will try exploring possibilities with GraphQL live queries. Eventually, we coul even come up with an official RFC for the spec!

If you are a enthusiastic tinkerer and plan to build something with the libraries above, share it with me and everyone else, so we can get more insights into different use-cases and requirements for different applications!
