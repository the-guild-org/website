{
  "data": {
    "repository": {
      "issues": {
        "edges": [
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMTowOTowMyswMTowMM4izryc",
            "node": {
              "title": "How to run React E2E tests purely with hooks",
              "body": "![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*aB7wj3tpGEKr47XjlNKijg.png?raw=true \"Photo by Alex Kondratiev on Unsplash\")\n\n# How to run React E2E tests purely with hooks\n\n## Tested with React-Native and Firebase Test Lab\n\nEvery invention starts with a need. I‚Äôve been working on a personal app for quiet a while now, and as part of the process I hand it out to few people so they can test it (most of them were overseas). One of the major complaints that I got was that the map component didn‚Äôt load. On most devices it did, but in many others it didn‚Äôt.\n\nThis issue had to be addressed, obviously, if I wanted to take my app seriously. Virtual devices using Android emulator didn‚Äôt seem to reproduce the issue, so I had to get a hold on real devices. I made a list of devices that didn‚Äôt support the app component, of what I had encountered thus far, and I started to look for people around me with these devices. Few challenges arouse:\n\n-   It was HARD to find people around me with these devices.\n-   It was HARD to convince these people to give me their phones for a short while, for debugging purposes.\n-   It was HARD to split my time‚Ä¶\n\nI‚Äôve been roaming around the internet, looking for a solution. I‚Äôve found few platforms that provide a way to interact with a collection of real devices using their API, and the one that stood out the most was [Firebase Test Lab](https://firebase.google.com/docs/test-lab/?gclid=CjwKCAiA1fnxBRBBEiwAVUouUvVyHY0_v_JuSIUIV8q_29Q_1oNF2qlqY3L_6U172P4BbnkL4J90-RoC2YgQAvD_BwE). It had a large collection of devices to interact with, and a free daily quota.\n\n\nPerfect! I was really excited to start testing my app with Test Lab. Oh there‚Äôs one thing though -it doesn‚Äôt really work with React Native :( what a pity.\n\nOne of the methods to use Test Lab is by recording a script that essentially guides a robot on how to use the app (known as [Robo](https://firebase.google.com/docs/test-lab/android/robo-ux-test)). The script can be recorded directly from [Android Studio](https://developer.android.com/studio), and it relies heavily on the view XML to fetch elements and attributes. Because React-Native wraps everything with a JavaScript shell, it fails to work as intended (for the most part).\n\n\n## My eureka moment üí°\n\nI realized that for my specific needs, all I had to do was to navigate to the map screen with a real back-end. It didn‚Äôt matter who navigated to the map, a person, a robot, or a script, I just wanted to reproduce the issue. Since my knowledge revolves mainly around JavaScript, I‚Äôve built a solution purely with React hooks, one that could navigate the app and test a desired outcome.\n\n# Introducing Bobcat üò∫üòº\n\nBobcat is a library for testing navigation flows in React. Its API is heavily inspired by classic testing frameworks like [Mocha](https://mochajs.org/) and [Jest](https://jestjs.io/); it has a similar `describe()` / `it()` type of syntax. Let‚Äôs have a look at a simple example script:\n\n\n```javascript\nimport { useState } from 'react';\nimport { useDelayedEffect, useBobcat } from 'react-bobcat';\n\nimport MyButton from './components/MyButton';\nimport { useSignOut } from './services/auth';\n\nexport default () => {\n  const { scope, flow, trap, pass, assert } = useBobcat();\n\n  scope('MyApp', () => {\n    const signOut = useSignOut();\n\n    before(async () => {\n      await signOut();\n    });\n\n    flow('Clicking a button', () => {\n      // MyButton is a React component\n      trap(MyButton, ({ buttonRef, textRef }) => {\n        const [buttonClicked, setButtonClicked] = useState(false);\n\n        useDelayedEffect(() => () => {\n          // buttonRef is referencing a native HTML button element\n          buttonRef.current.click();\n          setButtonClicked(true);\n        }, 1000, [true]);\n\n        useDelayedEffect(() => {\n          if (!buttonClicked) return;\n\n          return () => {\n            assert(textRef.current.innerText, 'Clicked!')\n            pass(); // Go to the next scope/flow\n          };\n        }, 1000, [buttonClicked]);\n      });\n    });\n\n    scope('Another nested scope', () => {\n      flow('Another flow A', () => {\n\n      });\n\n      flow('Another flow B', () => {\n\n      });\n    });\n  });\n\n  scope('You can also define additional external scopes', () => {\n    flow('Etc', () => {\n\n    });\n  });\n};\n```\n\nNote the comments in the code snippet, it should make things more clear. I used the `useDelayedEffect` hook and not an ordinary `useEffect` hook because I wanted to be able to visually observe the component, otherwise it would mount and unmount so quickly I wouldn‚Äôt be able to see it. `buttonRef` and `textRef` are props that are provided directly from `MyButton` component, which can vary depends on your component and your needs. This is how `MyButton` should look like:\n\n\n```javascript\nimport React, { useCallback, useRef, useState } from 'react';\nimport { useBobcat } from 'bobcat';\n\nconst MyButton = () => {\n  const { useTrap } = useBobcat();\n  const buttonRef = useRef();\n  const textRef = useRef();\n  const [text, setText] = useState('');\n\n  const onClick = useCallback(() => {\n    setText('Clicked!');\n  }, [true]);\n\n  useTrap(MyButton, {\n    buttonRef,\n    textRef,\n  });\n\n  return (\n    <div>\n      <button ref={buttonRef} onClick={onClick}>Click me</button>\n      <span ref={textRef}>{text}</span>\n    </div>\n  );\n};\n\nexport default MyButton;\n\n```\n\nThe `useTrap` hook would redirect the script to the trap which is defined under the active flow, so its behavior will change according to the test that you wrote.\n\n\nYou‚Äôve probably noticed by now that I used the `useBobcat` hook to retrieve the test utils. This signifies that there should be a higher order `BobcatProvider` somewhere at the root-level component. Why at the root-level? Because the higher you provide it at the hierarchy, the more control you should have over the app. Since essentially we want to test all the components in our app, it should be defined AS HIGH AS POSSIBLE, like so:\n\n\n```javascript\nimport React from 'react';\n\nimport BobcatRunner from './BobcatRunner';\nimport Navigator from './Navigator';\n\nconst App = () => {\n  return (\n    <BobcatRunner>\n      <Navigator />\n    </BobcatRunner>\n  );\n};\n\nexport default App;\n\n```\n\nThe `BobcatRunner` is a component that calls the `BobcatProvider` internally. It‚Äôs also responsible for resetting the app whenever a flow is finished, so it can begin a session, with the new traps defined underneath it. This is how it should look like:\n\n\n```javascript\nimport React, { useState, useMemo, useEffect } from 'react';\nimport { useAsyncEffect, useBobcat, BobcatProvider } from 'react-bobcat';\n\nimport useScopes from './scopes';\n\nconst DONE_ROUTE = '__DONE__';\n\nconst _BobcatRunner = ({ children }) => {\n  const { run } = useBobcat();\n  const [route, setRoute] = useState('');\n\n  useScopes();\n\n  const running = useMemo(() => run({\n    onPass({ route, date, payload }) {\n      console.log([\n        `[PASS] (${date.toISOString()}) ${route.join(' -> ')}`,\n        payload && payload.message,\n      ].filter(Boolean).join('\\n'));\n    },\n\n    onFail({ route, date, payload }) {\n      console.error([\n        `[FAIL] (${date.toISOString()}) ${route.join(' -> ')}`,\n        payload && payload.message,\n      ].filter(Boolean).join('\\n'));\n    },\n  }), [true]);\n\n  useAsyncEffect(function* () {\n    if (route === DONE_ROUTE) return;\n\n    const { value, done } = yield running.next();\n\n    setRoute(done ? DONE_ROUTE : value);\n  }, [route]);\n\n  if (!route) {\n    return null;\n  }\n\n  return (\n    <React.Fragment key={route}>\n      {children}\n    </React.Fragment>\n  );\n};\n\nconst BobcatRunner = (props) => {\n  return (\n    <BobcatProvider>\n      <_BobcatRunner {...props} />\n    </BobcatProvider>\n  );\n};\n\nexport default BobcatRunner;\n\n```\n\nFor the most part this component should be pretty clear, but the thing I wanna focus on is the `run()` function and how it‚Äôs used asynchronously. `run()` is an [async-generator](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/for-await...of), that is being yielded each time we resolve or reject a test flow. The yielded result is a unique route that is generated based on the given descriptions in our test-suite, so one possible route could be `MyApp -> Clicking a button`. Since the route is unique, it can be used to re-render the app and reset its state, thus the `key` prop.\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*YXn-vpkWlDXaX74fg8R37A.png?raw=true \"Rendering phase at a glance\")\n\nHere‚Äôs how an actual test run of my early-prototyped app looks like:\n\n[https://youtu.be/sFM6iibYT-0](https://youtu.be/sFM6iibYT-0 \"React Native and Firebase Test Lab test with Robo and Bobcat Uploaded by Eytan Manor on 2020-02-08.\")\n\n## Reducing bundle size\n\nBobcat is built for development or testing purposes, so one shall ask ‚Äî ‚Äúif it‚Äôs built into the internals of my app, how can I avoid it in production?‚Äù.\n\nNicely said. Bobcat provides a mock-up module under `react-bobcat/mock`. If used correctly with Babel, we can redirect some `import` statements into different, much more reduced in size dummy functions. Here‚Äôs an example `babel.config.js` (aka `.babelrc`):\n\n\n```javascript\nmodule.exports = {\n  plugins: [\n    ['module-resolver', {\n      'alias': {\n        'react-bobcat': process.env.NODE_ENV === 'test' ? 'react-bobcat' : 'react-bobcat/mock',\n        'my-bobcat-runner' : process.env.NODE_ENV === 'test' ? './BobcatRunner' : './components/Fragment',\n      },\n    }],\n  ],\n};\n\n```\n\n## Installation\n\nThe source is available via [Github](https://github.com/DAB0mB/react-bobcat). Alternatively you can install Bobcat via NPM:\n\n\n```\n$ npm install react-bobcat\n```\n\nor Yarn:\n\n```\n$ yarn add react-bobcat\n```\n\n_\\*Be sure to install React@16.8 or greater._\n\n\n## Call for contributors\n\nThe app mentioned in this article is work in progress. It‚Äôs an amazing social project that uses the absolute latest dev-stack and has many cool libraries and modules like the one above. If you‚Äôre looking for a serious tech challenge, or looking to make a change in the social field, contact me at [emanor6@gmail.com](mailto:emanor6@gmail.com).\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"4bc475f4bb2\",\"publishedDate\":1581372918830,\"url\":\"https://medium.com/the-guild/how-to-run-react-e2e-tests-purely-with-hooks-4bc475f4bb2\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMTowODo0MyswMTowMM4izrwB",
            "node": {
              "title": "The coolest, most underrated design pattern in React",
              "body": "![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*CJ1h6vCuTM2RAW25RKw-Sw.png?raw=true)\n\n# The coolest, most underrated design pattern in React\n\nThere will be times when we would like to pass props and control the behavior of child elements. Let me explain. Let‚Äôs take the following modal for example:\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*-eMkqRJvUiYRv3X7BnT_Ww.png?raw=true)\n\nAs you can see, the modal contains the following elements:\n\n-   A title.\n-   An `x` button.\n\n-   Some text content.\n-   A dismiss button (‚ÄúClose‚Äù).\n-   An action button (‚ÄúSave changes‚Äù).\n\nThese elements should be modifiable if we would like the modal to be properly re-usable. That means that the user would have control over things like the displayed content, dispatched events, style, etc, **of each and every element**. A naive solution would be accepting distinct props for each element like so:\n\n\n```jsx\n<Modal\n  showCloseButton\n  showDismissButton\n  showActionButton\n  title=\"Modal title\"\n  contents=\"Modal body text goes here.\"\n  dismissButtonText=\"Close\"\n  actionButtonText=\"Save changes\"\n  handleDismiss={close}\n  handleAction={save}\n/>\n```\n\nThe problem with that approach is that it spams the props mechanism; it makes the component look inflated and less readable. Moreover, it limits the amount of props that can be passed to child elements, and prevents the user from having a full control over them. You can solve this problem however, by providing a series or generic props objects, where each one represents a different element respectively:\n\n```jsx\n<Modal\n  showCloseButton\n  title=\"Modal title\"\n  contents=\"Modal body text goes here.\"\n  dismissButtonProps={{\n    text: 'Close',\n    handler: close,\n  }}\n  actionButtonProps={{\n    text: 'Save changes',\n    handler: save,\n  }}\n/>\n```\n\nThis solution works, but then again, it doesn‚Äôt solve the spamming issue, plus, we completely abuse the syntactic sugar that JSX provides us with. Instead of using HTML style attribute assignments (`attr=\"value\"`), we‚Äôre obligated to use JSONs.\n\n\n## Bootstrap for the rescue\n\nIn Bootstrap they took a very clever approach. Instead of defining props all over the place, they gave us the ability to directly manipulate the modal‚Äôs children. Using dedicated components, we can achieve the intended functionality that Bootstrap was aiming for:\n\n```jsx\n<Modal.Dialog>\n  <Modal.Header closeButton>\n    <Modal.Title>Modal title</Modal.Title>\n  </Modal.Header>\n\n  <Modal.Body>\n    <p>Modal body text goes here.</p>\n  </Modal.Body>\n\n  <Modal.Footer>\n    <Button variant=\"secondary\" onClick={close}>Close</Button>\n    <Button variant=\"primary\" onClick={save}>Save changes</Button>\n  </Modal.Footer>\n</Modal.Dialog>\n```\n\nGreat! There‚Äôs definitely a progress right there. But we can even take it a step further.\n\n> ### ‚ÄúA step further? What do you mean?‚Äù ‚Äî A confused React developer\n\nEven though things are very declarative and clear with Bootstrap‚Äôs approach, **we‚Äôre still obligated to compose the entire modal**. This means that we cannot use the modal‚Äôs children to fill-up the missing pieces, as if part of the logic was already implemented. It‚Äôs not always that we would like to write the modal‚Äôs contents entirely from scratch, right? Sometimes we would like to use it like some sort of a template. Another point to consider, is that there‚Äôs no filter or restrictions on the children‚Äôs input. Sometimes we would like the user to use only certain elements, and thus make sure that he doesn‚Äôt mess things up. If so, what‚Äôs the right approach that goes along with it?\n\n\n## Introducing the design pattern that has it all\n\nLet‚Äôs recap. Based on what we gathered so far, the new design pattern should have the following characteristics:\n\n-   No spamming of the props mechanism.\n-   Has full control over child elements using `props.children`.\n\n-   Has a template already in place.\n-   Has restrictions on the input.\n\nNow that sounds promising. Let‚Äôs have a look at an example. We will use the Bootstrap `Modal` component as an anchor:\n\n\n```jsx\nconst ModalFromTheFuture = ({ showCloseButton, children }) => {\n  const childProps = useChildProps(props.children, [\n    'title',\n    'contents'\n    'dismissButton',\n    'actionButton',\n  ]);\n\n  return (\n    <Modal.Dialog>\n      <Modal.Header closeButton={showCloseButton}>\n        {childProps.title && <Modal.Title {...childProps.title} />}\n      </Modal.Header>\n\n      <Modal.Body>\n        {childProps.contents && <p {...childProps.contents} />}\n      </Modal.Body>\n\n      <Modal.Footer>\n        {childProps.actionButton && <Button {...childProps.actionButton} variant=\"secondary\" />}\n        {childProps.dismissButton && <Button {...childProps.dismissButton} variant=\"primary\" />}\n      </Modal.Footer>\n    </Modal.Dialog>\n  );\n};\n```\n\nAs you can see, the new modal component uses a hook called `useChildProps()`. This hook will go through \\`props.children\\` and will basically flatten nested props. In addition, it will validate them against a provided white list, to make sure that the right element names were addressed. This is how its implementation should look like:\n\n\n```jsx\nconst useChildProps = (children, whitelist) => {\n  return useMemo(() => [].concat(children).reduce((childProps, child) => {\n    if (whitelist && !whitelist.includes(child.type)) {\n      throw Error(`element <${child.type}> is not supported`);\n    }\n\n    childProps[child.type] = child.props;\n\n    return childProps;\n  }, [children]));\n};\n```\n\n```jsx\n<ModalFromTheFuture showCloseButton>\n  <title>Modal title</title>\n  <contents>Modal body text goes here.</contents>\n  <dismissButton onClick={close}>Close</dismissButton>\n  <actionButton onClick={save}>Save changes</actionButton>\n</ModalFromTheFuture>\n```\n\n> ### ‚ÄúWait a minute, can‚Äôt it cause a confusion with native HTML tag names?‚Äù ‚Äî The developer from before\n\nTrue, but that can also be said about any other React component. Ever since the introduction of component based UI (e.g. Angular, React, Vue or even Web components), new tag names aren‚Äôt so rare to come across by, therefore you shouldn‚Äôt be afraid to use the new design pattern.\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"cd6210956203\",\"publishedDate\":1564532909353,\"url\":\"https://medium.com/the-guild/the-coolest-most-underrated-design-pattern-in-react-cd6210956203\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMTowODoyNiswMTowMM4izrt_",
            "node": {
              "title": "I wrote a customizable CSS engine in JavaScript",
              "body": "![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*CDP25vAz-FoLOBCZVkNxvw.jpeg?raw=true)\n\n# I wrote a **customizable** CSS engine in JavaScript\n\n\n## Custom selectors, custom rules and custom events. You determine its behavior\n\nFor some things CSS is simply not enough, we need JavaScript. I‚Äôm sure that we all experienced it not once, nor twice, the feeling of wanting to have a specific behavior or style that aren‚Äôt supported by CSS. An arbitrary example: selecting an element based on regular expression, playing a transition dynamically to the element‚Äôs changes in dimension, or sticky positioning (which is arguably working in some browsers based on my personal experience). However, this is not why I wrote the CSS engine.\n\nI wrote the engine to repeat the same thinking process that the original developers went through, and to understand the difficulties and challenges that they faced. Why? Because it helps you think. With a custom implementation of CSS you can achieve exactly what I mentioned in the first paragraph and thus understand the mechanism a lot better.\n\n> **disclaimer:** I haven‚Äôt looked into the native implementation of CSS. There‚Äôs a lot you can take from my article (at least I hope), yet please take my words with a grain of salt.\n>\n\n# First thing first ‚Äî demo\n\nHere‚Äôs an example of a stylesheet with a custom rule named `boom`:\n\n\n```css\n.test {\n  boom: red yellow white;\n}\n```\n\nThis rule will change an element‚Äôs contents to ‚ÄúBOOM!‚Äù and its border, background, and text color based on the given parameters. Here‚Äôs the rule in action:\n\n[https://codepen.io/eytan-manor/pen/RXPPvo](https://codepen.io/eytan-manor/pen/RXPPvo \"EventSheet demo \")\n\nIf you‚Äôll look at the demo‚Äôs source code ([**which I highly advice before you continue any further**](https://github.com/DAB0mB/eventsheet/blob/9224349b895ee15efc43d879ceed8786bac660bb/demo.js)) you‚Äôll see how I define custom properties to my stylesheet with the [`Event`](https://github.com/DAB0mB/eventsheet/blob/9224349b895ee15efc43d879ceed8786bac660bb/src/sheet_components/event.js), [`Selector`](https://github.com/DAB0mB/eventsheet/blob/9224349b895ee15efc43d879ceed8786bac660bb/src/sheet_components/selector.js) and [`Rule`](https://github.com/DAB0mB/eventsheet/blob/9224349b895ee15efc43d879ceed8786bac660bb/src/sheet_components/rule.js) classes. The engine does follow the native CSS path, although it‚Äôs still in early stages and doesn‚Äôt support many features and capabilities, such as:\n\n\n-   Separation of concerns for styles and events. They can still be used and modified outside the stylesheet.\n-   Re-evaluation of style if stylesheet gets updated.\n-   Selector context specifiers e.g. [`>`](https://www.w3schools.com/cssref/sel_element_gt.asp) or [`+`](https://www.w3schools.com/cssref/sel_element_pluss.asp) (e.g. `div + span`).\n\n-   Any kind of query ([`@media`](https://www.w3schools.com/cssref/css3_pr_mediaquery.asp), [`@keyframes`](https://www.w3schools.com/cssref/css3_pr_animation-keyframes.asp), [`@import`](https://www.w3schools.com/cssref/pr_import_rule.asp), etc).\n\n\nSince this is a customizable engine, with a little bit of creativity you can implement a lot of things, such as animations, URLs, selection and transformation functions, etc.\n\nIndeed, there‚Äôs a lot going on under the hood and a lot to go through, so let‚Äôs get into the interesting bits.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*kMNazIh94f0QjdgJugxhZw.png?raw=true)\n\n# Keynotes from the implementation\n\n## Reading the stylesheet\n\nReceiving information from a given CSS string is a challenge as for itself. Since I wanted to strictly preserve the original CSS experience, I didn‚Äôt settle for a JSON, but rather an actual sheet with a set of rules and selectors. To parse it, you first need to be familiar with the concept of an [AST](https://en.wikipedia.org/wiki/Abstract_syntax_tree).\n\n\nAST stands for Abstract Syntax Tree, and it‚Äôs made out of a hierarchy of nodes; each node represents a different feature of the syntax. Essentially the AST is an in-memory representation of the code from which data can easily be retrieved. In this case, the retrieved data will be the selectors and the rules underneath them. If you wanna know more about the AST, I recommend you to read my article about [building a Babel plug-in](https://medium.com/the-guild/this-is-how-i-build-babel-plug-ins-b0a13dcd0352).\n\n\nThe CSS is broken down into AST nodes like following:\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*qTaA1_QP3unFKt146wWNAw.png?raw=true)\n\nThe AST is now presented as a plain JSON. To make things even more convenient, I run it through a second iteration where it‚Äôs gonna get wrapped with the classes defined in the registry of the stylesheet, e.g. [`BoomRule`](https://github.com/DAB0mB/eventsheet/blob/9224349b895ee15efc43d879ceed8786bac660bb/demo.js#L31) and [`ClassNameSelector`](https://github.com/DAB0mB/eventsheet/blob/9224349b895ee15efc43d879ceed8786bac660bb/demo.js#L19). A node will be wrapped if it matches the properties of the target class:\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*rQSLHMuLEu1SM1IP5MA73w.png?raw=true)\n\nWith a wrapped AST, not only we can get information about the given CSS string, but we can also call related methods directly from a specific node. So given a node of `Selector` type, we can call the [`test`](https://github.com/DAB0mB/eventsheet/blob/9224349b895ee15efc43d879ceed8786bac660bb/demo.js#L24) method to see whether an element actually matches the selector or not.\n\n\n## Detecting changes in the DOM\n\nThe engine is heavily based on the [`MutationObserver`](https://developer.mozilla.org/en-US/docs/Web/API/MutationObserver) to detect changes in the DOM tree. The mutation observer will trigger a callback with details regards the occurred mutations (see [`MutationRecord`](https://developer.mozilla.org/en-US/docs/Web/API/MutationRecord)) from the recent execution loop. The problem with the `MutationObserver` is that it will create a mutation record for each mutation occurred without taking into an account the final result. That means that if a DOM node was added, removed, added, removed, and then added, it will appear as if it was removed 2 times and added 3 times, rather than added just once.\n\n\nTo overcome this issue, I‚Äôve normalized the collection of mutation records to include only the mutations which are relevant, based on the logic that I just mentioned (see [`normalizeMutations()`](https://github.com/DAB0mB/eventsheet/blob/9224349b895ee15efc43d879ceed8786bac660bb/src/utils/mutations.js#L3)).\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*yUqOCnKv2OljFFe4PU_WOg.png?raw=true)\n\nOne of the core behaviors of CSS is that once it‚Äôs loaded, the style is immediately applied. The catch here, is that the mutation observer callback will not be invoked unless real mutations occurred. One way to apply the loaded style is to force the mutations; remove all nodes and re-add them to the observed element. However, this would be very inefficient.\n\nThe other, more efficient way of solving this is to synthesize the mutations. Yes, go through each and every node in the DOM tree recursively and create a fake mutation JSON. Once it‚Äôs done, the set of mutation records can be injected to the observation callback and the style should be applied based defined customizations to the engine (see [`synthesizeMutations()`](https://github.com/DAB0mB/eventsheet/blob/9224349b895ee15efc43d879ceed8786bac660bb/src/utils/mutations.js#L90)).\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*xFw2c8844paHh2MeWfzOlA.png?raw=true)\n\nOne thing to note is that we‚Äòre likely to change the `style` attribute inside rule event handlers, which will unnecessarily re-trigger the mutation callback and might potentially cause an infinite mutation loop. To avoid that I used the [`takeRecords()`](https://developer.mozilla.org/en-US/docs/Web/API/MutationObserver/takeRecords) function to dispose the pending mutations from triggering.\n\n\n```javascript\nfunction observerCallback (mutations, observer) {\n  // Will cause more mutations\n  updateStyle(mutations)\n  // Will dispose pending mutations\n  observer.takeRecords()\n}\n```\n\n## Triggering custom events\n\nEvents management is a crucial part in the implementation because it will determine the efficiency of the engine. If events aren‚Äôt disposed or reallocated exactly when needed, this will dramatically affect how fast will things work.\n\nWith each mutation callback, elements are filtered based on the selectors found in the stylesheet AST. Once an element has been cherry-picked, event listeners will be added to it based on the set of rules that are defined under the CSS block that the target selector represents at the current iteration.\n\nThe engine uses a very naive approach where events are disposed and reallocated for a specific element whenever there are incoming mutations of addition or attribute modification types. This way I make sure that even if a node was modified and a selector is not relevant anymore, only the right handlers would run once a specific event has been triggered.\n\n```javascript\nfunction handleMutations(mutations, observer, { addedNodes, removedNodes, modifiedNodes } = normalizeMutations(mutations)) {\n  addedNodes.concat(modifiedNodes).forEach((mutation) => {\n    this.removeEventListeners(mutation)\n    this.addEventListeners(mutation)\n  })\n}\n\n```\n\nIf you looked at the source code of the demo, you probably noticed that each rule has a disposal function. In case you didn‚Äôt, here‚Äôs a snapshot of a sample rule:\n\n```javascript\nclass BorderRule extends EventSheet.Rule {\n  static get ruleName() {\n    return 'border'\n  }\n\n  ['on initialize'](e, params) {\n    const border = e.target.style.border\n\n    e.target.style.border = params\n\n    return function dispose() {\n      e.target.style.border = border\n    }\n  }\n}\n```\n\nThe disposal function will run each time the selector is not relevant anymore in which case the element in question will stop listening to the event. So how did I make sure that the disposal function runs on each event disposal? Simple. I‚Äôve splitted the logic into a dedicated module which is responsible for managing the events (see [events.js](https://github.com/DAB0mB/eventsheet/blob/9224349b895ee15efc43d879ceed8786bac660bb/src/utils/events.js)).\n\n\nThe module will add and remove events for given event target as normally, but in addition to that, it will store the event handler alongside the disposal method with internal cache maps. Once an event is removed, the corresponding disposal methods in the cache will be called as well.\n\n```javascript\nfunction addEventListener (target, event, handler) {\n  const wrappedHandler = (e) => {\n    const dispose = handler(e)\n\n    if (dispose != null && typeof dispose != 'function') {\n      throw TypeError('return value must be a function')\n    }\n\n    // Private property\n    _(wrappedHandler).dispose = dispose\n  }\n  \n  // ... store in cache ...\n}\n\nfunction removeEventListener (target, event, handler) {\n  // ... restore from cache ...\n  \n  const dispose = _(wrappedHandler).dispose\n\n  dispose()\n  \n  // ... delete from cache ...\n}\n```\n\n# How can it be better?\n\n## Disposing and reallocating events only when necessary\n\nRight now all registered events for a specific element are being disposed and re-allocated to make sure that only the right handlers will run; this way if a selector becomes irrelevant due to recent changes to the element, it won‚Äôt effect its style.\n\nThis is a not all-too-bad yet naive approach. It works well, but it‚Äôs inefficient, something which will become very noticeable once the stylesheet will grow bigger and bigger. One thing that can be done is to run the [`test()`](https://github.com/DAB0mB/eventsheet/blob/9224349b895ee15efc43d879ceed8786bac660bb/demo.js#L24) function of a specific selector **before** event listeners are disposed. If there has been a change in the outcome of tests, only then proceed to disposing and reallocating the event listeners.\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*2AovcPdi7l0HRz-lVkVsFA.png?raw=true)\n\nThis can be taken a step further by observing which properties of the element has changed during the application of specific rule, and store them all in-order. Once a selector becomes irrelevant and its rules don‚Äôt apply anymore, the style would be re-evaluated only relatively to the style properties which are not affected anymore. This is a very complex mechanism to implement but still achievable.\n\n```css\n/* <div class=\"test shadow\">  --->  <div class=\"shadow> */\n\n.test {\n  /*\n    This affects the border, background and text properties. If the selector .test becomes irrelevant,\n    only the rules which affect the properties in question will be re-evaluated.\n  */\n  boom: red yellow white;\n}\n\n:not(.test) {\n  border: 1px solid black; /* re-evaluate */\n  background: white; /* re-evaluate */\n  color: black; /* re-evaluate */\n}\n\n.shadow {\n  box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75); /* DON'T re-evaluate */\n}\n```\n\n## **Unleashing the full potential using web-assembly and WebGL**\n\n\nOne of the clear advantages of a native CSS engine over its JavaScript equivalent, is that it‚Äôs written in a low level language such as C or C++. That can be compensated with the usage of [Web Assembly](https://webassembly.org/), where we can write our code with [Rust](https://www.rust-lang.org/) and compile it to a low-level language that can run on the browser. To top things up, we can use [WebGL](https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API) or a library such as [GPU.JS](https://gpu.rocks/) to run vector calculations in parallel using all cores of the GPU.\n\n\nNeedless to say that this is only relevant if you want to implement graphical manipulations such as element shadows, text stroke or image filtering. It‚Äôs better to keep things simple and use only the style API which is offered to us right out of the box by the browser.\n\n# Concept: Rethink event handling in UI frameworks\n\nMost modern UI frameworks such as [React](https://reactjs.org/), [Angular](https://angular.io) and [Vue](https://vuejs.org/) are tightly coupling event registering and handing with the component itself. While this has proven itself to work (greatly) over the years, a customizable stylesheet (or eventsheet as you may call it) can be an alternative that can offer some benefits.\n\n\n```javascript\neventSheet.attach(`\n  .form .field {\n    font-size: 14px;\n    line-height: 14px;\n    width: 100%;\n    padding: 5px;\n  }\n\n  .form .field.name {\n    max-length: 30;\n  }\n\n  .form .field.date {\n    ensure-date-input;\n  }\n  \n  .form .button.submit {\n    handle-submit;\n  }\n`)\n\neventSheet.observe(formEl)\n```\n\n-   The sheet can be loaded and applied on any existing DOM element regardless of the used UI framework.\n-   The sheet is heavily customizable and can easily share rules and behaviors between different DOM elements.\n-   The sheet is very declarative and easy to go through. It‚Äôs flat with no indentions of few levels deep.\n-   different sheets can be loaded on top of different customizations of selectors and rules.\n-   The sheet is light weight and can be loaded quickly.\n\nHave any counter claims? Prove me wrong! Or maybe prove me right :-) Constructive criticism with solid arguments from any side of the divide will be more than welcome.\n\n‚òÜ The source code is available on [GitHub](https://github.com/DAB0mB/eventsheet) ‚òÜ\n\n\n> **Note:** It‚Äôs still just a concept. DO NOT use in production.\n>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"b1e05c8914fe\",\"publishedDate\":1564003930623,\"url\":\"https://medium.com/the-guild/i-wrote-a-customizable-css-engine-in-javascript-b1e05c8914fe\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMTowNzozOSswMTowMM4izroP",
            "node": {
              "title": "Injectable services in React",
              "body": "![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*Ld9bh_dmakdkMOP3ByZc7Q.jpeg?raw=true)\n\n# Injectable services in React\n\n## How they‚Äôre implemented and their similarities with Angular services\n\nReact provides a fantastic API for building components. It‚Äôs light-weight and intuitive, and became a sensation in the dev community for a reason. With the introduction of the most recent API features: [hooks](https://reactjs.org/docs/hooks-overview.html) and [context/provider](https://reactjs.org/docs/context.html), components have became not only more functional, but also more testable. Let me explain.\n\n\nSo far, when we wanted a component to use an external service, we would simply implement it in a separate module, import it, and use its exported methods, like so:\n\n```javascript\n// auth-service.js\nexport const signUp = (body) => {\n  return fetch({\n    method: 'POST',\n    url: `${API}/sign-up`,\n    headers: {\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify(body),\n  });\n};\n\nexport const signIn = (body) => {\n  return fetch({\n    method: 'POST',\n    url: `${API}/sign-in`,\n    headers: {\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify(body),\n  });\n};\n```\n\n```jsx\n// auth-components.jsx\nimport React from 'react';\nimport auth from './auth-service'\n\nconst { useCallback } = React;\n\nexport const SignInButton = ({ username, password, onSignIn }) => {\n  const signIn = useCallback(() => {\n    auth.signIn({ username, password }).then(onSignIn);\n  }, [username, password, onSignIn]);\n\n  return (\n    <button onClick={signIn}>\n      Sign-In\n    </button>\n  );\n};\n\nexport const SignUpButton = ({ username, password, verifiedPass, onSignUp }) => {\n  const signUp = useCallback(() => {\n    auth.signUp({ username, password, verifiedPass }).then(onSignUp);\n  }, [username, password, verifiedPass, onSignUp]);\n\n  return (\n    <button onClick={signUp}>\n      Sign-Up\n    </button>\n  );\n};\n```\n\n> Keep in mind that this is NOT how I would actually write my code in production, there‚Äôs no error handling, and both components are defined under a single module which I don‚Äôt see as a good practice, but for demonstration purposes it‚Äôs more than enough.\n\nThe components above would work well within a React app, because essentially they can achieve what they were implemented for. However, if we would like to unit-test these components, we would encounter a problem, **because the only way to test these components would be via e2e tests, or by completely mocking the fetch API**. Either way, the solutions are not in our favor. Either we completely overkill it with testing, or we make use of a not-so-simple mocking solution for an ENTIRE native API. Below is an example:\n\n\n```jsx\n// auth-components.test.jsx\nimport React from 'react';\nimport { act, render, fireEvent } from '@testing-library/react';\nimport { SignInButton, SignUpButton } from './auth-components';\n\ndescribe('SignInButton', () => {\n  test('invokes callback on successful sign-in', () => {\n    const onSignIn = jest.fn();\n\n    const { getByTestId } = render(\n      <SignInButton onSignIn={onSignIn} />\n    );\n\n    const button = getByTestId('button');\n\n    act(() => {\n      fireEvent.click(button);\n    });\n\n    expect(onSignIn).toHaveBeenCalled();\n  });\n});\n\ndescribe('SignUpButton', () => {\n  test('invokes callback on successful sign-up', () => {\n    const onSignUp = jest.fn();\n\n    const { getByTestId } = render(\n      <SignUpButton onSignUp={onSignUp} />\n    );\n\n    const button = getByTestId('button');\n\n    act(() => {\n      fireEvent.click(button);\n    });\n\n    expect(onSignUp).toHaveBeenCalled();\n  });\n});\n```\n\nIf so, how does one suppose to overcome this problem?\n\n# Let‚Äôs learn from our Angular fellows\n\nI know what you‚Äôre probably thinking right now‚Ä¶ What is this guy thinking, promoting Angular design patterns which are completely no match for the great React. First of all, React is not perfect, and always has places for improvements. If it was already perfect, they wouldn‚Äôt have kept working on it on Facebook. Second, I like React, and I believe in it very much, this is why I would like to make it better by ensuring best practices. So before you close your tab in anger please continue reading and listen to what I have to say :-)\n\nIn the Angular team, they came up with a clever approach. Instead of relying on hard-coded imports, what they did they provided a mechanism that would let us inject our services before we initialize the component. With that approach, we can easily mock-up our services, because with the injection system it‚Äôs very easy to control what implementation of the services is it gonna use. So this is how it would practically look like:\n\n```typescript\n// auth-module.ts\nimport { NgModule } from '@angular/core';\nimport { SignInButton, SignUpButton } from './auth-components';\nimport AuthService from './auth-service';\n\n@NgModule({\n  declarations: [\n    SignInButton,\n    SignUpButton,\n  ],\n  providers: [\n    AuthService\n  ],\n})\nclass AuthModule {}\n\nexport deafult AuthModule;\n```\n\n```typescript\n// auth-components.ts\nimport { Component, Input, Output, EventEmitter } from '@angular/core';\nimport AuthService from './auth-service'\n\n@Component({\n  selector: 'app-sign-in-button',\n  template: `\n    <button (click)={signIn()} />\n  `,\n})\nexport class SignInButton {\n  @Input()\n  username: string;\n  @Input()\n  password: string;\n  @Output()\n  onSignIn = new EventEmitter<void>();\n\n  constructor(private auth: AuthService) {}\n\n  signIn() {\n    const body = {\n      username: this.username,\n      password: this.password,\n    };\n\n    this.auth.signIn(body).then(() => {\n      this.onSignIn.emit();\n    });\n  }\n}\n\n@Component({\n  selector: 'app-sign-in-button',\n  template: `\n    <button (click)={signUp()} />\n  `,\n})\nexport class SignInButton {\n  @Input()\n  username: string;\n  @Input()\n  password: string;\n  @Input()\n  verifiedPass: string;\n  @Output()\n  onSignOut = new EventEmitter<void>();\n\n  constructor(private auth: AuthService) {}\n\n  signUp() {\n    const body = {\n      username: this.username,\n      password: this.password,\n      verifiedPass: this.verifiedPass,\n    };\n\n    this.auth.signUp(body).then(() => {\n      this.onSignUp.emit();\n    });\n  }\n}\n```\n\nAnd now if we would like to test it, all we have to do is to replace the injected service, like mentioned earlier:\n\n```typescript\n// auth-components.test.ts\nimport { async, ComponentFixture, TestBed } from '@angular/core/testing';\nimport AuthService from './auth-service';\n\ndescribe('Authentication components', () => {\n  test('invokes callback on successful sign-in', () => {\n    describe('SignInButton', () => {\n      TestBed.configureTestingModule({\n        declarations: [SignInButton],\n        providers: [{\n          provider: AuthService,\n          useValue: { signIn: () => {} },\n        }],\n      }).compileComponents();\n\n      const signIn = jest.fn();\n      const signInButton = TestBed.createComponent(SignInButton);\n      signInButton.onSignIn.subscribe(onSignIn);\n      expect(signIn).toHaveBeenCalled();\n    });\n  });\n\n  describe('SignUpButton', () => {\n    test('invokes callback on successful sign-out', () => {\n      TestBed.configureTestingModule({\n        declarations: [SignUpButton],\n        providers: [{\n          provider: AuthService,\n          useValue: { signUp: () => {} },\n        }],\n      }).compileComponents();\n\n      const signUp = jest.fn();\n      const signUpButton = TestBed.createComponent(SignUpButton);\n      signUpButton.onSignUp.subscribe(onSignUp);\n      expect(signUp).toHaveBeenCalled();\n    });\n  });\n});\n```\n\nTo put things simple, I‚Äôve created a diagram that describes the flow:\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*BoRdtW7oGI_jzUc6y3NoXQ.png?raw=true)\n\n# Applying the same design pattern in React\n\nNow that we‚Äôre familiar with the design pattern, thanks to Angular, let‚Äôs see how we can achieve the same thing in React using its API. Let‚Äôs briefly revisit [React‚Äôs context API](https://reactjs.org/docs/context.html):\n\n\n```jsx\n// auth-service.jsx\nimport React from 'react';\n\nconst { createContext, useContext } = React;\n\nconst AuthContext = createContext(null);\n\nexport const AuthProvider = (props) => {\n  const value = {\n    signIn: props.signIn || signIn,\n    signUp: props.signUp || signUp,\n  };\n\n  return (\n    <AuthProvider.Provider value={value}>\n      {props.children}\n    </AuthProvider.Provider>\n  );\n};\n\nexport const useAuth = () => {\n  return useContext(AuthContext);\n};\n\nconst signUp = (body) => {\n  // ...\n};\n\nconst signIn = (body) => {\n  // ...\n};\n```\n\nThe context can be seen as the container that holds our service, aka the `value` prop, as we can see in the example above. The provider defines what `value` the context will hold, so when we consume it, we will be provided with it. This API is the key for a mockable test unit in React, because the `value` can be replaced with whatever we want. Accordingly, we will wrap our `auth-service.tsx`:\n\n\n```jsx\n// auth-service.jsx\nimport React from 'react';\n\nconst { createContext, useContext } = React;\n\nconst AuthContext = createContext(null);\n\nexport const AuthProvider = (props) => {\n  const value = {\n    signIn: props.signIn || signIn,\n    signUp: props.signUp || signUp,\n  };\n\n  return (\n    <AuthProvider.Provider value={value}>\n      {props.children}\n    </AuthProvider.Provider>\n  );\n};\n\nexport const useAuth = () => {\n  return useContext(AuthContext);\n};\n\nconst signUp = (body) => {\n  // ...\n};\n\nconst signIn = (body) => {\n  // ...\n};\n```\n\nAnd we will update our component to use the new `useAuth()` hook:\n\n\n```jsx\n// auth-components.jsx\nimport React from 'react';\nimport { useAuth } from './auth-service'\n\nconst { useCallback } = React;\n\nexport const SignInButton = ({ username, password, onSignIn }) => {\n  const auth = useAuth();\n\n  const signIn = useCallback(() => {\n    auth.signIn({ username, password }).then(onSignIn);\n  }, [username, password, onSignIn]);\n\n  // ...\n};\n\nexport const SignInButton = ({ username, password, verifiedPass, onSignUp }) => {\n  const auth = useAuth();\n\n  const signUp = useCallback(() => {\n    auth.signUp({ username, password, verifiedPass }).then(onSignUp);\n  }, [username, password, verifiedPass, onSignUp]);\n\n  // ...\n};\n```\n\nBecause the `useAuth()` hook uses the context API under the hood, it can be easily replaced with a different value. All we have to do is to tell the provider to store a different value under its belonging context. Once we use the context, the received value should be the same one that was defined by the provider:\n\n\n```jsx\n// auth-components.test.jsx\nimport React from 'react';\nimport { act, render, fireEvent } from '@testing-library/react';\nimport { SignInButton, SignUpButton } from './auth-components';\n\ndescribe('SignInButton', () => {\n  test('invokes callback on successful sign-in', () => {\n    const onSignIn = jest.fn();\n\n    const { getByTestId } = render(\n      <AuthProvider signIn={Promise.resolve}>\n        <SignInButton onSignIn={onSignIn} />\n      </AuthProvider>\n    );\n\n    // ...\n  });\n});\n\ndescribe('SignUpButton', () => {\n  test('invokes callback on successful sign-up', () => {\n    const onSignUp = jest.fn();\n\n    const { getByTestId } = render(\n      <AuthProvider signUp={Promise.resolve}>\n        <SignUpButton onSignUp={onSignUp} />\n      </AuthProvider>\n    );\n\n    // ...\n  });\n});\n```\n\nOne might ask: ‚ÄúDoes this mean that I need to wrap each and every service with the context API?‚Äù, And my answer is: ‚ÄúIf you‚Äôre looking to deliver an enterprise quality React app, then yes‚Äù. Unlike Angular, React is more loose, and doesn‚Äôt force this design pattern, so you can actually use what works best for you.\n\nBefore I finish this article, here are some few things that I would like to see from the community, that I believe will make this work flow a lot easier:\n\n-   Have a 3rd party library that would wrap a service with the context API and would simplify it.\n-   Have an ESLint rule that will force the usage of injectable React services.\n\nWhat do you think? Do you agree with the design pattern or not? Are you gonna be one of the early adopters? Write your thoughts in the comments section below. Also feel free to follow me on [Medium](https://medium.com/@eytanmanor), or alternatively you can follow me on:\n\n\n-   [GitHub](https://github.com/DAB0mB)\n\n-   [Twitter](https://twitter.com/eytan_manor)\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*hqBvYJsSarLskEkI73IvIw.jpeg?raw=true)\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"de0136b6d476\",\"publishedDate\":1561387840918,\"url\":\"https://medium.com/the-guild/injectable-services-in-react-de0136b6d476\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMTowNzoxMyswMTowMM4izrk5",
            "node": {
              "title": "<üíÖ> Introducing a new encapsulation method for Styled-Components with Babel",
              "body": "![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*mlEERn6nS_ulsxBbXjfMng.png?raw=true \"babel-plugin-scoped-styled-components\")\n\n# \\<üíÖ> Introducing a new encapsulation method for Styled-Components with Babel\n\n## TL;DR: Use private class names instead of a dedicated component. \\*\\*experimental\\*\\*\n\n[Styled-Components](https://www.styled-components.com/) has brought something new to the table when in was first introduced and is one of the most popular CSS-related libraries out there with over 20k stars on GitHub. Style encapsulation has always been an issue in the web world, and people tried to solve it in many ways, of which [Shadow DOM](https://developer.mozilla.org/en-US/docs/Web/Web_Components/Using_shadow_DOM) and [Angular‚Äôs emulated view encapsulation](https://angular.io/api/core/ViewEncapsulation).\n\n\nI like the approach of Styled-Components, mostly because it‚Äôs compatible with React which seems to be the leading UI library in the echo system as for now, but also because of how nicely it sits in the virtual DOM tree.\n\nFor those who aren‚Äôt familiar with Styled-Components, here‚Äôs a quick example of how you would apply style on a React.Component:\n\n```jsx\nconst Button = styled.button `\n  border-radius: 999px;\n`\n\nconst RedButton = styled(Button) `\n  color: red;\n`\n\nconst GreenButton = styled(Button) `\n  color: green;\n`\n\nconst BlueButton = styled(Button) `\n  color: blue;\n`\n\nconst Dashboard = (\n  <div>\n    <RedButton />\n    <GreenButton />\n    <BlueButton />\n  </div>\n)\n```\n\nHowever, as good as it is, there are some major drawbacks for creating a dedicated component for each styled element:\n\n-   It‚Äôs longer to write than defining a class.\n-   It‚Äôs less efficient, because it has to go through the rendering phase of React.\n-   It breaks the HTML naming conventions and we can‚Äôt differentiate between a regular element and a React.Component anymore.\n-   IMHO, combining multiple styles with Styled-Components mixins is less elegant and not as easy as specifying multiple classes per single element (see [issue on GitHub as reference](https://github.com/styled-components/styled-components/issues/773)).\n\n\nWhen I was writing the [WhatsApp-Clone](https://github.com/Urigo/WhatsApp-Clone-Client-React) I used a different approach to overcome the problems mentioned above. Instead of creating a dedicated component for each styled element, I used a container that has all the CSS rules with private classes. By private classes I mean, classes which start with an underscore (e.g. `_my-class`). This way I‚Äôm less likely to collide globally defined CSS rules:\n\n\n```jsx\nconst DashboardStyle = styled.div `\n  ._btn {\n    border-radius: 999px;\n  }\n\n  ._red-btn {\n    color: red;\n  }\n\n  ._green-btn {\n    color: green;\n  }\n\n  ._blue-btn {\n    color: blue;\n  }\n`\n\nconst Dashboard = (\n  <DashboardStyle>\n    <button className=\"_btn _red-btn\" />\n    <button className=\"_btn _green-btn\" />\n    <button className=\"_btn _blue-btn\" />\n  </DashboardStyle>\n)\n```\n\nAs much as I love this approach, it doesn‚Äôt achieve full encapsulation. A nested child component which has a similar class selector as its parent will result in a merged style, which is not necessarily what we want. Each component should leave independently of its ancestors, which is what Styled-Components are all about.\n\n# Introducing babel-plugin-scoped-styled-components\n\nIndeed, this problem is solvable with a transpiler. Not only we can achieve full encapsulation this way, but it‚Äôs also highly efficient due to its independence from a runtime library.\n\nSo by loading a single plug-in, the recent code snippet I just showed you would be transformed into the following code:\n\n```jsx\nconst DashboardStyle = styled.div `\n  .${props => props.__scopename}-btn {\n    border-radius: 999px;\n  }\n\n  .${props => props.__scopename}-red-btn {\n    color: red;\n  }\n\n  .${props => props.__scopename}-green-btn {\n    color: green;\n  }\n\n  .${props => props.__scopename}-blue-btn {\n    color: blue;\n  }\n`\n\nconst Dashboard = (\n  <DashboardStyle __scopename=\"__scope0\">\n    <button className=\"__scope0-red-btn\" />\n    <button className=\"__scope0-green-btn\" />\n    <button className=\"__scope0-blue-btn\" />\n  </DashboardStyle>\n)\n```\n\nI also thought of creating a runtime wrapper around Styled-Components where I basically iterate through `props.children` and edit their class names, but there are some advantages for using an AOT compiler over a runtime solution:\n\n\n-   You don‚Äôt have to import a library different than `styled-components` and it‚Äôs easily integratable with existing projects.\n\n-   It‚Äôs more efficient.\n-   Encapsulation can be done based on the module you‚Äôre currently at and not based on the virtual DOM tree. This behavior is not craved in stone as it can be easily modified by specifying certain attributes, but at-least the option is there.\n-   It‚Äôs more strict and declarative.\n\nThe source code is available on [GitHub](https://github.com/DAB0mB/babel-plugin-scoped-styled-components), or it can be downloaded via NPM (or Yarn):\n\n\n```\n$ npm install babel-plugin-scoped-styled-components\n```\n\nOnce you install it, be sure to load it in your `.babelrc`:\n\n\n```\n{\n  \"plugins\": [\"babel-plugin-scoped-styled-components\"]\n}\n```\n\nI‚Äôm aware that there are certain limitations to that approach as for now, but I would like to see more interest and contribution before I continue any further with the development. Please share your thoughts everyone, let me know what do you think by commenting below or by [opening an issue on GitHub](https://github.com/DAB0mB/babel-plugin-scoped-styled-components/issues).\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"bec5cbb671dd\",\"publishedDate\":1551715188900,\"url\":\"https://medium.com/the-guild/introducing-a-new-encapsulation-method-for-styled-components-with-babel-bec5cbb671dd\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMTowNzowMyswMTowMM4izrjq",
            "node": {
              "title": "WhatsApp Clone using React (Hooks+Suspense), GraphQL, Apollo, TypeScript and PostgreSQL",
              "body": "![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*cSBu9zeo8fSnf1Cc-UeR_g.jpeg?raw=true)\n\n# Fully functional WhatsApp Clone using React (Hooks+Suspense), GraphQL, Apollo, TypeScript and PostgreSQL\n\n## An open-source full-stack example app made with React 16.7 (Hooks & Suspense), TypeScript, GraphQL-Subscriptions/Codegen/Modules and PostgreSQL\n\nYou might have seen it around already ‚Äî an open-source WhatsApp Clone tutorial; a project which was originally started in 2015 by [Urigo](https://github.com/urigo) based on [Angular-Meteor](https://angular-meteor.com/tutorials/whatsapp2-tutorial) and [Ionic](https://ionicframework.com/), and have been throughout different incarnations ever since.\n\n\nThis time around, I‚Äôm happy to announce that a new version of the WhatsApp Clone is coming, and it‚Äôs based on [React 16.7](https://reactjs.org/) ([Hooks](https://reactjs.org/docs/hooks-intro.html) & [Suspense](https://reactjs.org/docs/react-api.html#suspense)), [Styled-Components](https://github.com/styled-components/styled-components), [Material-UI](https://github.com/mui-org/material-ui), [TypeScript](https://www.typescriptlang.org/), [Apollo](https://www.apollographql.com/), [GraphQL-Subscriptions](https://www.youtube.com/watch?v=Wi7P39sF2nw)/[Codegen](https://graphql-code-generator.com)/[Modules](https://graphql-modules.com/), [PostgreSQL](https://www.postgresql.org/) and [TypeORM](https://github.com/typeorm/typeorm).\n\n\n[**Click me to go to the tutorial page**](https://www.tortilla.academy/Urigo/WhatsApp-Clone-Tutorial/master/latest/step/0)\n\n\n> A more in depth step-by-step tutorial is expected in the near future\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*fFUJd7moWtjvMZ5dE-A80g.gif?raw=true \"WE WERE ON A BREAK!!!!\")\n\n# What is it good for?\n\nThis app was built with all the latest and hottest technologies out there. The purpose is simple ‚Äî it should be a guideline for building a proper app, thus we thought very carefully regards the design patterns and architecture used in it, plus, we made sure to cover all communication methods with a GraphQL-back-end in different variations (query, mutation, subscription). This way whenever you‚Äôre looking to start a new app, maintain an existing one or upgrade your dev-stack, the WhatsApp-clone can be a great source to start with! It‚Äôs full stack and has a complete flow.\n\n# Why did we choose this dev-stack?\n\nReact, GraphQL, Apollo, PostgreSQL and TypeScript for obvious reasons ‚Äî they are backed by a strong ecosystem that grows rapidly. These technologies can be used in endless variations, and there‚Äôs no one way which is the most right of doing so, but we chose a way that makes the most sense for us and that we truly believe in when it comes to building apps. We‚Äôve connected it all with [TypeORM](https://github.com/typeorm/typeorm/), [GraphQL-Code-Generator](https://graphql-code-generator.com/), [GraphQL-Modules](https://graphql-modules.com/) for the following reasons:\n\n\n-   The GraphQL back-end was implemented using [GraphQL-Modules](https://graphql-modules.com) where logic was splitted into feature based modules. GraphQL-Modules is a library which provides you with the ability to manage and maintain your GraphQL schema in a scalable and reusable way. Not once nor twice I have seen people who struggle with that and get tangled upon their own creation, and with GraphQL-Modules where you have a very defined structure, this problem can be easily solved. You can read more in [this series of 7 blog posts about it](https://medium.com/the-guild/graphql-modules-feature-based-graphql-modules-at-scale-2d7b2b0da6da).\n\n-   Every GraphQL/TypeScript definition was automatically generated with [GraphQL-Code-Generator](https://graphql-code-generator.com/) using a single command call. There‚Äôs no need to maintain the same thing twice if it already exists in one way or another. This way you don‚Äôt have to write TypeScript type definitions for your GraphQL documents (queries, mutations and subscriptions), GraphQL resolvers and GraphQL types.\n\n-   The new version of React 16.7 was used with Hooks and Suspense and 100% of the project is made out of function components. The front-end communicates with the back-end using only hooks and there was no use in GraphQL-React components, which makes async tasks look a lot more readable with no extra indentations.\n-   We used TypeORM to correctly split the logic of the entities in the database and define the relationships between them. ORMs are controversial these days, but they can help a lot in some cases and we thought a good example could be valuable to the community.\n\n# What to expect?\n\n-   Basic authentication.\n-   Image uploading with [Cloudinary](https://cloudinary.com/).\n\n-   Live updates with GraphQL Subscriptions.\n-   100% function components with React Hooks.\n-   GraphQL communication with [react-apollo-hooks](https://github.com/trojanowski/react-apollo-hooks).\n\n\nThis can be extremely useful for those who have little to no background in one of the technologies in our dev-stack. We will let you know when it‚Äôs ready and will publish it due time, until then be sure to follow [our publication](https://medium.com/the-guild) and the Github repositories.\n\n\n# Influence\n\nWe want to hear your opinions!\n\nShould we choose another library and technology over another? Could we write the code better/cleaner? Should we add a specific feature to the app? We want to hear it all!\n\nPlease tell us now so we could integrate your feedback on the tutorial itself!\n\nWe want to keep evolving the stack and as the tutorial would be based on git commits, we want to create the same clone with different tech-stacks and compare them on this real app using code diffs.\n\nEverything is completely free and open source, and we want your help and (**not financial**) contribution!\n\n\nBest place would be to open an issue or create a PR on the repositories:\n\n-   Server ‚Äî [urigo/WhatsApp-Clone-Server](https://github.com/Urigo/WhatsApp-Clone-server)\n\n-   Client ‚Äî [urigo/WhatsApp-Clone-Client-React](https://github.com/Urigo/WhatsApp-Clone-Client-React)\n\n\nAgain, all types of feedback is welcome, write freely!\n\nSee you in the tutorial!\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"de1840c27d21\",\"publishedDate\":1549040225606,\"url\":\"https://medium.com/the-guild/whatsapp-clone-using-react-hooks-suspense-graphql-apollo-typescript-and-postgresql-de1840c27d21\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMTowNjo0NCswMTowMM4izrhj",
            "node": {
              "title": "Use this magical Babel plugin and get a performance boost for your React components",
              "body": "![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*ytNEFZJa5z-5mWrwitD4yQ.jpeg?raw=true)\n\nWith the introduction of React hooks (in React 16.8-alpha) arose an issue ‚Äî calculations are being unnecessarily re-evaluated due to declarations being done within the rendering phase.\n\nTo put things simple, if now we‚Äôre using class components, and we store calculation results on the class instance to save ourselves some precious processing power:\n\n```jsx\nclass MyComponent extends React.Component {\n  constructor(props) {\n    super(props)\n    \n    this.transformedData = props.data\n      .filter(props.filterPredicate)\n      .sort(props.sortComparator)\n  }\n  \n  render() {\n    return (\n      <div>\n        <button onClick={this.goBack} />\n        <ul>\n          {this.transformedData.map(({ id, value }) => {\n            <li key={id}>{value}</li>\n          )}\n        </ul>\n      </div>\n    )\n  }\n  \n  goBack = () => {\n    this.props.history.pop()\n  }\n}\n```\n\nIn the near future, we will have no choice but to do everything within the rendering method itself, dictated by hooks:\n\n```jsx\nconst MyComponent = ({\n  data,\n  history,\n  filterPredicate,\n  sortComparator,\n}) => {\n  const transformedData = data\n    .filter(filterPredicate)\n    .sort(sortComparator)\n\n  const goBack = () => {\n    history.pop()\n  }\n\n  return (\n    <div>\n      <button onClick={goBack} />\n      <ul>\n        {transformedData.map(({ id, value }) => {\n          <li key={id}>{value}</li>\n        )}\n      </ul>\n    </div>\n  )\n}\n```\n\nTo solve this problem, the React team invented a couple of methods: `useCallback()` and `useMemo()`. Each of them is used for different reasons but they‚Äôre quiet similar, and essentially they‚Äôre used as guard functions that will re-activate themselves only if certain parameters were changed. I recommend you to go through the [official React docs](https://reactjs.org/docs/hooks-reference.html#usecallback) to get a better perspective on these. If we were to implement it in the example above, it should look like so:\n\n\n```jsx\nconst MyComponent = ({\n  data,\n  history,\n  filterPredicate,\n  sortComparator,\n}) => {\n  const transformedData = useMemo(() =>\n    data\n      .filter(filterPredicate)\n      .sort(sortComparator)\n  , [\n    history,\n    filterPredicate,\n    sortComparator,\n  ])\n\n  const goBack = useCallback(() => {\n    history.pop()\n  }, [history])\n\n  return (\n    <div>\n      <button onClick={goBack} />\n      <ul>\n        {transformedData.map(({ id, value }) => {\n          <li key={id}>{value}</li>\n        )}\n      </ul>\n    </div>\n  )\n}\n```\n\nWait a minute‚Ä¶ So does it mean that I have to wrap all my declarations in these hooks just to get performance which is on a par with class components?!\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*K46rrPy7Syh6HEzheSssOQ.jpeg?raw=true)\n\nThat‚Äôs right Vladimir. Even the React team suggested that, and I quote from their docs:\n\n> ### ‚ÄúIn the future, a sufficiently advanced compiler could create this array automatically‚Äù ‚Äî React\n\nIt‚Äôs a good thing I love React and I think of the future. That‚Äôs why I invented this Babel plug-in called `babel-plugin-react-persist`, and it addresses exactly that issue! All you have to do is edit your `.babelrc` file and the code will be automatically transformed! Not only that, the plug-in also takes care of optimizing inline anonymous functions in JSX attributes. This way each rendering phase will have a similar instance of the intended callback. So given the following code:\n\n\n```jsx\nexport default ({\n  data,\n  sortComparator,\n  filterPredicate,\n  history,\n}) => {\n  const transformedData = data\n    .filter(filterPredicate)\n    .sort(sortComparator)\n\n  return (\n    <div>\n      <button className=\"back-btn\" onClick={() => history.pop()} />\n      <ul className=\"data-list\">\n        {transformedData.map(({ id, value }) => (\n          <li className=\"data-item\" key={id} onClick={() => history.push(`data/${id}`)}>{value}</li>\n        ))}\n      </ul>\n    </div>\n  )\n}\n```\n\nThe plug-in will generate:\n\n```jsx\nlet _anonymousFnComponent, _anonymousFnComponent2\n\nexport default ({ data, sortComparator, filterPredicate, history }) => {\n  const transformedData = React.useMemo(() =>\n    data.filter(filterPredicate).sort(sortComparator)\n  , [data, data.filter, filterPredicate, sortComparator])\n\n  return React.createElement(_anonymousFnComponent2 = _anonymousFnComponent2 || (() => {\n    const _onClick2 = React.useCallback(() => history.pop(), [history, history.pop])\n\n    return (\n      <div>\n        <button className=\"back-btn\" onClick={_onClick2} />\n        <ul className=\"data-list\">\n          {transformedData.map(({ id, value }) =>\n            React.createElement(_anonymousFnComponent = _anonymousFnComponent || (() => {\n              const _onClick = React.useCallback(() =>\n                history.push(`data/${id}`)\n              , [history, history.push, id])\n\n              return (\n                <li className=\"data-item\" key={id} onClick={_onClick}>\n                  {value}\n                </li>\n              )\n            }), { key: id })\n          )}\n        </ul>\n      </div>\n    )\n  }), null)\n}\n```\n\nSo what are you waiting for? Go visit the official [GitHub repo](https://github.com/DAB0mB/babel-plugin-react-persist) and get yourself a copy of the plug-in! Have any suggestions or feature request? Feel free to open a ticket in the [repo‚Äôs issues page](https://github.com/DAB0mB/babel-plugin-react-persist/issues) or comment below!\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"f27fea9554aa\",\"publishedDate\":1548086426096,\"url\":\"https://medium.com/the-guild/use-this-magical-babel-plugin-and-get-a-performance-boost-for-your-react-components-f27fea9554aa\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMTowNjoyOCswMTowMM4izrfv",
            "node": {
              "title": "This is how our brain detects shapes",
              "body": "## And so shall the computer‚Ä¶\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*4ZlUc2Lu3EL91aF6ha3AIA.gif?raw=true \"A demonstration of the algorithm.\")\n\nThere was this time I was trying to create a studio where you can sketch primitives and transform them with touch gestures (credit to [Guy Manor](https://www.linkedin.com/in/guy-manor-519099143/) for the idea ‚ù§). As part of my work I had to create an algorithm that could normalize drawn shapes, because there‚Äôs no use to a set of dozens of vertices which together look like nothing but one big mess. The result can be seen in the GIF above. Looks pretty nice right?\n\n\nIn this article I‚Äôm gonna go through the algorithm that I used to detect shapes. I‚Äôm aware of the fact that in the real world there are much more parameters and it can be much harder sometimes to detect certain shapes, especially the abstract ones which are made out of arcs, but this algorithm still works well and is useful for most use cases. The algorithm assumes that we work in a 2D space and will produce a set of normalized vectors, a cricle, a rectangle, or any pre-defined shape in a given shapes atlas. **If you wanna cut straight to the chase then a JS implementation of the algorithm is consumable in the following Git repo:** [github.com/Appfairy/shapeit](https://github.com/Appfairy/shapeit/).\n\n\nWithout further or do let‚Äôs go through the algorithm!\n\n---\n\n-   If a given sketch is open, try to lengthen first and last vectors in hope to find intersection and create a closed area.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*JVE3PxJrTI8cvYtQWom8zw.jpeg?raw=true)\n\n-   Look for all the closed areas within the given sketch and reduce all the areas which don‚Äôt pass a certain threshold. If the area is less than a constant value, splice its vertices.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*VdRCW27D7MZ3KT9qKzoPcg.jpeg?raw=true)\n\n-   Assuming that we‚Äòre down to only a single area, try to match it with a circle by calculating the standard deviation of each radius from the center of the shape to one of its vertices. If standard deviation is less than a constant value, it must be a circle.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*I_WGi4aihZbzRKD6dAWcXw.jpeg?raw=true)\n\n-   If a circle was not found, reduce the level of detail of the polygon by splicing vertices which cause an insignificant angle change.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*jN89DwaL1awNs78DilkeZA.jpeg?raw=true)\n\n-   Sometimes we might be down to a single vector or a set of vectors in case there was no closed area in the given sketch.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*Lz9JlQylZmH6I8_RgbaCVA.jpeg?raw=true)\n\nNow this part is slightly more complicated. We‚Äôre gonna try to match the normalized polygon with one of the shapes in the atlas of pre-defined shapes. Besides of actually detecting whether the polygon represents a certain shape or not, we‚Äôll also need to take the found match in the atlas and transform it to match as closely as possible to the average properties of the polygon. So our atlas may consist of any closed 2D polygons such as: A triangle, a rhombus, a trapezoid, a hexagon, etc.\n\nShape matching is done with score calculation based on different parameters. The higher the score is the more likely we‚Äôre to accept a certain shape is the intended one. We will calculate the score of the drawn polygon relatively to all pre-defined shapes in atlas with the same amount of vectors, and if the highest score is greater than a certain threshold, then that would be it. A score calculation for a shape will be done based on the co-sinuses of the angles between the vectors and the ratios between the vectors.\n\n**Note that order matters.** It doesn‚Äôt matter where the series starts or ends, as long as there‚Äôs consistency between the values, that‚Äôs how we‚Äôre gonna evaluate the score.\n\n\nSince shapes with more vectors are more likely to receive a lower score, in nearly all cases, we will use a dynamic threshold which will increase or decrease itself based on the target amount of vectors. After testing different variations of the calculation method, starting with the most naive one ‚Äî a linear method, I‚Äôve reached a conclusion that a radial-exponential one would be the most accurate for the use case:\n\n```javascript\nfunction getScoreThreshold(edgesNumber) {\n  return Math.sin((Math.PI / 2) * (thresholds.minShapeScore ** (edgesNumber)));\n}\n```\n\nOnce we‚Äôve determined what shape does the polygon match to, we will start a process of trying to transforming the pre-defined shape to have properties as closely as possible to the polygon‚Äôs: Scale, angle, direction and position.\n\n-   For the scale we will simply calculate the average length of all vectors and divide the 2 values to find the right multiplication.\n-   For the angle, we will repeat the same process, but in addition, we will try different variations of radians (_let r the average radian of the polygon_): `r, -r, œÄ + r, œÄ - r, r + .5œÄ, -r - .5œÄ, .5œÄ - r, 1.5œÄ + r` .\n\n-   We will repeat angle matching for a mirrored version of the shape aka a different ‚Äúdirection‚Äù.\n-   We will position the scaled, rotated and (potentially) mirrored shape and position its center on top of the drawn polygon‚Äôs center.\n-   Out of all transformed shapes with different angle variations, we will take the one whose average vertices deviation is the smallest compared to the drawn polygon‚Äôs vertices.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*9a3EKlnMyR8-lUZtKbpYDA.jpeg?raw=true)\n\nIt might be very possible that we haven‚Äôt found a matching shape in the atlas! In which case we can return the normalized polygon, unless, it has 4 edges. If our polygon has 4 edges we should try to match it with a rectangle.\n\nFirst we will try to determine whether the polygon is intended to have 4 right angles by calculating all the co-sinuses and comparing their evaluated score to a certain threshold. If indeed we have a rectangle, we will normalize it by calculating its average vertical length and horizontal length. Once we have a new base-shape we will repeat the process of shape matching against the atlas.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*w6ssn2kp2EVQBLC4uZm2Mw.jpeg?raw=true)\n\n---\n\nSo that was the shape detection algorithm in a nutshell. All I did to come up with it was putting the process that goes through my brain in to code, and the result is detailed above. If we would to add another layer to the algorithm to make it more life-like, it would probably be a deep learning algorithm to detect new base-shapes to fill out the atlas. Maybe I will write about it in my next article ;-)\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"10cadefc8134\",\"publishedDate\":1544539655101,\"url\":\"https://medium.com/the-guild/this-is-how-our-brain-detects-shapes-10cadefc8134\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMTowNTo0MiswMTowMM4izraR",
            "node": {
              "title": "Under the hood of React‚Äôs hooks system",
              "body": "## Looking at the implementation and getting to know it inside out\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*pS_DCyF0S1gIjbxt6FAuPg.jpeg?raw=true)\n\nWe‚Äôve all heard about it. The new hook system of React 16.7 has made a lot of noise in the community. We‚Äôve all tried it and tested it, and got really excited about it and its potential. When you think about hooks they‚Äôre kind of magical, somehow React manages your component without even exposing its instance (no use of `this` keyword). So how the heck does React does that?\n\n\nToday I would like to dive into React‚Äôs implementation of hooks so we can understand it better. The problem with magical features is that it‚Äôs harder to debug a problem once it happens, because it‚Äôs backed by a complex stack trace. Thus, by having a deep knowledge regards React‚Äôs new hook system, we would be able to solve issues fairly quick once we encounter them, or even avoid them in the first place.\n\n> _Before I begin I would just like to say that I‚Äôm not a developer/maintainer of React and that my words should be taken with a grain of salt. I did dive very deeply into the implementation of React‚Äôs hooks system, but by all means I can‚Äôt guarantee that this is how React actually works. With that said, I‚Äôve backed my words with proofs and references from React‚Äôs source code, and tried to make my arguments as solid as possible._\n>\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*R-oovJm4IQBLDjZy6DvbBg.png?raw=true \"A rough schematic representation of React‚Äôs hooks system\")\n\n---\n\nFirst of all, let‚Äôs go through the mechanism that ensures that hooks are called within React‚Äôs scope, because you‚Äôd probably know by now that hooks are meaningless if not called in the right context:\n\n# The dispatcher\n\nThe dispatcher is the shared object that contains the hook functions. It will be dynamically allocated or cleaned up based on the rendering phase of ReactDOM, and it will ensure that the user doesn‚Äôt access hooks outside a React component (see [implementation](https://github.com/facebook/react/tree/5f06576f51ece88d846d01abd2ddd575827c6127/packages/react-reconciler/src/ReactFiberDispatcher.js#L24)).\n\n\nThe hooks are enabled/disabled by a flag called `enableHooks` right before we render the root component by simply switching to the right dispatcher; this means that technically we can enable/disable hooks at runtime. React 16.6.X also has the experimental feature implemented, but it‚Äôs actually disabled (see [implementation](https://github.com/facebook/react/tree/5f06576f51ece88d846d01abd2ddd575827c6127/packages/react-reconciler/src/ReactFiberScheduler.js#L1211)).\n\n\nWhen we‚Äôre done performing the rendering work, we nullify the dispatcher and thus preventing hooks from being accidentally used outside ReactDOM‚Äôs rendering cycle. This is a mechanism that will ensure that the user doesn‚Äôt do silly things (see [implementation](https://github.com/facebook/react/tree/5f06576f51ece88d846d01abd2ddd575827c6127/packages/react-reconciler/src/ReactFiberScheduler.js#L1376)).\n\n\nThe dispatcher is resolved in each and every hook call using a function called `resolveDispatcher()`. Like I said earlier, outside the rendering cycle of React this should be meaningless, and React should print the warning message: _‚ÄúHooks can only be called inside the body of a function component‚Äù_ (see [implementation](https://github.com/facebook/react/tree/5f06576f51ece88d846d01abd2ddd575827c6127/packages/react/src/ReactHooks.js#L17)).\n\n\n```javascript\nlet currentDispatcher\nconst dispatcherWithoutHooks = { /* ... */ }\nconst dispatcherWithHooks = { /* ... */ }\n\nfunction resolveDispatcher() {\n  if (currentDispatcher) return currentDispatcher\n  throw Error(\"Hooks can't be called\")\n}\n\nfunction useXXX(...args) {\n  const dispatcher = resolveDispatcher()\n  return dispatcher.useXXX(...args)\n}\n\nfunction renderRoot() {\n  currentDispatcher = enableHooks ? dispatcherWithHooks : dispatcherWithoutHooks\n  performWork()\n  currentDispatcher = null\n}\n```\n\n---\n\nNow that we got that simple encapsulation mechanism covered, I would like us to move to the core of this article ‚Äî the hooks. Right of the bet I‚Äôd like to introduce you to a new concept:\n\n# The hooks queue\n\nBehind the scenes, hooks are represented as nodes which are linked together in their calling order. They‚Äôre represented like so because hooks are not simply created and then left alone. They have a mechanism which allows them to be what they are. A hook has several properties which I would like you to bare in mind before diving into its implementation:\n\n-   Its initial state is created in the initial render.\n-   Its state can be updated on the fly.\n-   React would remember the hook‚Äôs state in future renders.\n-   React would provide you with the right state based on the calling order.\n-   React would know which fiber does this hook belong to.\n\nAccordingly, we need to rethink the way we view the a component‚Äôs state. So far we have thought about it as if it‚Äôs a plain object:\n\n```javascript\n{\n  foo: 'foo',\n  bar: 'bar',\n  baz: 'baz',\n}\n```\n\nBut when dealing with hooks it should be viewed as a queue, where each node represents a single model of the state:\n\n```javascript\n{\n  memoizedState: 'foo',\n  next: {\n    memoizedState: 'bar',\n    next: {\n      memoizedState: 'bar',\n      next: null\n    }\n  }\n}\n```\n\nThe schema of a single hook node can be viewed in the [implementation](https://github.com/facebook/react/tree/5f06576f51ece88d846d01abd2ddd575827c6127/packages/react-reconciler/src/ReactFiberHooks.js#L243). You‚Äôll see that the hook has some additional properties, but the key for understanding how hooks work lies within `memoizedState` and `next`. The rest of the properties are used specifically by the `useReducer()` hook to cache dispatched actions and base states so the reduction process can be repeated as a fallback in various cases:\n\n\n-   `baseState` - The state object that would be given to the reducer.\n\n-   `baseUpdate` - The most recent dispatched action that created the `baseState`.\n\n-   `queue` - A queue of dispatched actions, waiting to go through the reducer.\n\n\nUnfortunately I haven‚Äôt managed to get a good grasp around the reducer hook because I didn‚Äôt manage to reproduce almost any of its edge cases, so I wouldn‚Äôt feel comfortable to elaborate. I will only say that the reducer implementation is so inconsistent that even one of the comments in the [implementation](https://github.com/facebook/react/tree/5f06576f51ece88d846d01abd2ddd575827c6127/packages/react-reconciler/src/ReactFiberHooks.js:381) itself states that ‚Äú(it‚Äôs) not sure if these are the desired semantics‚Äù; so how am I supposed to be sure?!\n\n\nSo back to hooks, before each and every function Component invocation, a function named [`prepareHooks()`](https://github.com/facebook/react/tree/5f06576f51ece88d846d01abd2ddd575827c6127/react-reconciler/src/ReactFiberHooks.js:123) is gonna be called, where the current fiber and its first hook node in the hooks queue are gonna be stored in global variables. This way, any time we call a hook function (`useXXX()`) it would know in which context to run.\n\n\n```javascript\nlet currentlyRenderingFiber\nlet workInProgressQueue\nlet currentHook\n\n// Source: https://github.com/facebook/react/tree/5f06576f51ece88d846d01abd2ddd575827c6127/react-reconciler/src/ReactFiberHooks.js:123\nfunction prepareHooks(recentFiber) {\n  currentlyRenderingFiber = workInProgressFiber\n  currentHook = recentFiber.memoizedState\n}\n\n// Source: https://github.com/facebook/react/tree/5f06576f51ece88d846d01abd2ddd575827c6127/react-reconciler/src/ReactFiberHooks.js:148\nfunction finishHooks() {\n  currentlyRenderingFiber.memoizedState = workInProgressHook\n  currentlyRenderingFiber = null\n  workInProgressHook = null\n  currentHook = null\n}\n\n// Source: https://github.com/facebook/react/tree/5f06576f51ece88d846d01abd2ddd575827c6127/react-reconciler/src/ReactFiberHooks.js:115\nfunction resolveCurrentlyRenderingFiber() {\n  if (currentlyRenderingFiber) return currentlyRenderingFiber\n  throw Error(\"Hooks can't be called\")\n}\n// Source: https://github.com/facebook/react/tree/5f06576f51ece88d846d01abd2ddd575827c6127/react-reconciler/src/ReactFiberHooks.js:267\nfunction createWorkInProgressHook() {\n  workInProgressHook = currentHook ? cloneHook(currentHook) : createNewHook()\n  currentHook = currentHook.next\n  workInProgressHook\n}\n\nfunction useXXX() {\n  const fiber = resolveCurrentlyRenderingFiber()\n  const hook = createWorkInProgressHook()\n  // ...\n}\n\nfunction updateFunctionComponent(recentFiber, workInProgressFiber, Component, props) {\n  prepareHooks(recentFiber, workInProgressFiber)\n  Component(props)\n  finishHooks()\n}\n```\n\nOnce an update has finished, a function named [`finishHooks()`](https://github.com/facebook/react/tree/5f06576f51ece88d846d01abd2ddd575827c6127/react-reconciler/src/ReactFiberHooks.js:148) will be called, where a reference for the first node in the hooks queue will be stored on the rendered fiber in the `memoizedState` property. This means that the hooks queue and their state can be addressed externally:\n\n\n```javascript\nconst ChildComponent = () => {\n  useState('foo')\n  useState('bar')\n  useState('baz')\n\n  return null\n}\n\nconst ParentComponent = () => {\n  const childFiberRef = useRef()\n\n  useEffect(() => {\n    let hookNode = childFiberRef.current.memoizedState\n\n    assert(hookNode.memoizedState, 'foo')\n    hookNode = hooksNode.next\n    assert(hookNode.memoizedState, 'bar')\n    hookNode = hooksNode.next\n    assert(hookNode.memoizedState, 'baz')\n  })\n\n  return (\n    <ChildComponent ref={childFiberRef} />\n  )\n}\n```\n\n---\n\nLet‚Äôs get more specific and talk about individual hooks, starting with the most common of all ‚Äî the state hook:\n\n# State hooks\n\nYou would be surprised to know, but behind the scenes the `useState` hook uses `useReducer` and it simply provides it with a pre-defined reducer handler (see [implementation](https://github.com/facebook/react/blob/5f06576f51ece88d846d01abd2ddd575827c6127/packages/react-reconciler/src/ReactFiberHooks.js#L339)). This means that the results returned by `useState` are actually a reducer state, and an action dispatcher. I would like you to take a look at the reducer handler that the state hook uses:\n\n\n```javascript\nfunction basicStateReducer(state, action) {\n  return typeof action === 'function' ? action(state) : action;\n}\n```\n\nSo as expected, we can provide the action dispatcher with the new state directly; but would you look at that?! We can also provide the dispatcher with _an action function that will receive the old state and return the new one._ TÃ∂Ã∂Ã∂hÃ∂Ã∂Ã∂iÃ∂Ã∂Ã∂sÃ∂Ã∂Ã∂ Ã∂Ã∂Ã∂iÃ∂Ã∂Ã∂sÃ∂Ã∂Ã∂nÃ∂Ã∂Ã∂‚ÄôÃ∂Ã∂Ã∂tÃ∂Ã∂Ã∂ Ã∂Ã∂Ã∂dÃ∂Ã∂Ã∂oÃ∂Ã∂Ã∂cÃ∂Ã∂Ã∂uÃ∂Ã∂Ã∂mÃ∂Ã∂Ã∂eÃ∂Ã∂Ã∂nÃ∂Ã∂Ã∂tÃ∂Ã∂Ã∂eÃ∂Ã∂Ã∂dÃ∂Ã∂Ã∂ Ã∂Ã∂Ã∂aÃ∂Ã∂Ã∂nÃ∂Ã∂Ã∂yÃ∂Ã∂Ã∂wÃ∂Ã∂Ã∂hÃ∂Ã∂Ã∂eÃ∂Ã∂Ã∂rÃ∂Ã∂Ã∂eÃ∂Ã∂Ã∂ Ã∂Ã∂Ã∂iÃ∂Ã∂Ã∂nÃ∂Ã∂Ã∂ Ã∂Ã∂Ã∂tÃ∂Ã∂Ã∂hÃ∂Ã∂Ã∂eÃ∂Ã∂Ã∂ Ã∂Ã∂Ã∂[oÃ∂Ã∂Ã∂fÃ∂Ã∂Ã∂fÃ∂Ã∂Ã∂iÃ∂Ã∂Ã∂cÃ∂Ã∂Ã∂iÃ∂Ã∂Ã∂aÃ∂Ã∂Ã∂lÃ∂Ã∂Ã∂ Ã∂Ã∂Ã∂RÃ∂Ã∂Ã∂eÃ∂Ã∂Ã∂aÃ∂Ã∂Ã∂cÃ∂Ã∂Ã∂tÃ∂Ã∂Ã∂ Ã∂Ã∂Ã∂dÃ∂Ã∂Ã∂oÃ∂Ã∂Ã∂cÃ∂Ã∂Ã∂uÃ∂Ã∂Ã∂mÃ∂Ã∂Ã∂eÃ∂Ã∂Ã∂nÃ∂Ã∂Ã∂tÃ∂Ã∂Ã∂aÃ∂Ã∂Ã∂tÃ∂Ã∂Ã∂iÃ∂Ã∂Ã∂oÃ∂Ã∂Ã∂nÃ∂Ã∂Ã∂](https://reactjs.org/docs/hooks-reference.html#functional-updates) Ã∂Ã∂Ã∂(Ã∂Ã∂Ã∂aÃ∂Ã∂Ã∂sÃ∂Ã∂Ã∂ Ã∂Ã∂Ã∂fÃ∂Ã∂Ã∂oÃ∂Ã∂Ã∂rÃ∂Ã∂Ã∂ Ã∂Ã∂Ã∂tÃ∂Ã∂Ã∂hÃ∂Ã∂Ã∂eÃ∂Ã∂Ã∂ Ã∂Ã∂Ã∂tÃ∂Ã∂Ã∂iÃ∂Ã∂Ã∂mÃ∂Ã∂Ã∂eÃ∂Ã∂Ã∂ Ã∂Ã∂Ã∂tÃ∂Ã∂Ã∂hÃ∂Ã∂Ã∂iÃ∂Ã∂Ã∂sÃ∂Ã∂Ã∂ Ã∂Ã∂Ã∂aÃ∂Ã∂Ã∂rÃ∂Ã∂Ã∂tÃ∂Ã∂Ã∂iÃ∂Ã∂Ã∂cÃ∂Ã∂Ã∂lÃ∂Ã∂Ã∂eÃ∂Ã∂Ã∂ Ã∂Ã∂Ã∂wÃ∂Ã∂Ã∂aÃ∂Ã∂Ã∂sÃ∂Ã∂Ã∂ Ã∂Ã∂Ã∂wÃ∂Ã∂Ã∂rÃ∂Ã∂Ã∂iÃ∂Ã∂Ã∂tÃ∂Ã∂Ã∂tÃ∂Ã∂Ã∂eÃ∂Ã∂Ã∂nÃ∂Ã∂Ã∂)Ã∂Ã∂Ã∂ Ã∂Ã∂Ã∂aÃ∂Ã∂Ã∂nÃ∂Ã∂Ã∂dÃ∂Ã∂Ã∂ Ã∂Ã∂Ã∂ Ã∂tÃ∂hÃ∂aÃ∂tÃ∂‚ÄôÃ∂sÃ∂ Ã∂aÃ∂ Ã∂pÃ∂iÃ∂tÃ∂yÃ∂ Ã∂bÃ∂eÃ∂cÃ∂aÃ∂uÃ∂sÃ∂eÃ∂ Ã∂iÃ∂tÃ∂‚ÄôÃ∂sÃ∂ Ã∂eÃ∂xÃ∂tÃ∂rÃ∂eÃ∂mÃ∂eÃ∂lÃ∂yÃ∂ Ã∂uÃ∂sÃ∂eÃ∂fÃ∂uÃ∂lÃ∂!Ã∂ This means that when you send the state setter down the component tree you can run mutations against the current state of the parent component, without passing it as a different prop. For example:\n\n\n```javascript\nconst ParentComponent = () => {\n  const [name, setName] = useState()\n  \n  return (\n    <ChildComponent toUpperCase={setName} />\n  )\n}\n\nconst ChildComponent = (props) => {\n  useEffect(() => {\n    props.toUpperCase((state) => state.toUpperCase())\n  }, [true])\n  \n  return null\n}\n```\n\n---\n\nLastly, effect hooks ‚Äî which made a major impact on a component‚Äôs life cycle and how it works:\n\n# Effect hooks\n\nEffect hooks behave slightly differently and has an additional layer of logic that I would like to explain. Again, there are things I would like you to bare in mind regards the properties of the effect hooks before I dive into the implementation:\n\n-   They‚Äôre created during render time, but they run _after_ painting.\n\n-   If given so, they‚Äôll be destroyed right before the next painting.\n-   They‚Äôre called in their definition order.\n\n> _Note that I‚Äôm using the ‚Äúpainting‚Äù term and not ‚Äúrendering‚Äù. These two are different things, and I‚Äôve seen many speakers in the recent [React Conf](https://conf.reactjs.org/) use the wrong term! Even in the official [React docs](https://reactjs.org/docs/hooks-reference.html#useeffect) they say ‚Äúafter the render is committed to the screen‚Äù, which is kind of like ‚Äúpainting‚Äù. The render method just creates the fiber node but doesn‚Äôt paint anything yet._\n>\n\nAccordingly, there should be another an additional queue that should hold these effects and should be addressed after painting. Generally speaking, a fiber holds a queue which contains effect nodes. Each effect is of a different type and should be addressed at its appropriate phase:\n\n-   Invoke instances of `getSnapshotBeforeUpdate()` before mutation (see [implementation](https://github.com/facebook/react/tree/5f06576f51ece88d846d01abd2ddd575827c6127/packages/react-reconciler/src/ReactFiberScheduler.js#L646)).\n\n-   Perform all the host insertions, updates, deletions and ref unmounts (see [implementation](https://github.com/facebook/react/tree/5f06576f51ece88d846d01abd2ddd575827c6127/packages/react-reconciler/src/ReactFiberScheduler.js#L687)).\n\n-   Perform all life-cycles and ref callbacks. Life-cycles happen as a separate pass so that all placements, updates, and deletions in the entire tree have already been invoked. This pass also triggers any renderer-specific initial effects (see [implementation](https://github.com/facebook/react/tree/5f06576f51ece88d846d01abd2ddd575827c6127/packages/react-reconciler/src/ReactFiberScheduler.js#L732)).\n\n-   Effects which were scheduled by the `useEffect()` hook - which are also known as ‚Äúpassive effects‚Äù based on the [implementation](https://github.com/facebook/react/tree/5f06576f51ece88d846d01abd2ddd575827c6127/packages/react-reconciler/src/ReactFiberScheduler.js#L779) (maybe we should start using this term within the React community?!).\n\n\nWhen it comes to the hook effects, they should be stored on the fiber in a property called `updateQueue`, and each effect node should have the following schema (see [implementation](https://github.com/facebook/react/tree/5f06576f51ece88d846d01abd2ddd575827c6127/packages/react-reconciler/src/ReactFiberHooks.js#L477)):\n\n\n-   `tag` - A binary number which will dictate the behavior of the effect (I will elaborate soon).\n\n-   `create` - The callback that should be ran _after_ painting.\n\n-   `destroy` - The callback returned from `create()` that should be ran _before_ the initial render.\n\n-   `inputs` - A set of values that will determine whether the effect should be destroyed and recreated.\n\n-   `next` - A reference to the next effect which was defined in the function Component.\n\n\nBesides the `tag` property, the other properties are pretty straight forward and easy to understand. If you‚Äôve studied hooks well, you‚Äôd know that React provides you with a couple of special effect hooks: `useMutationEffect()` and `useLayoutEffect()`. These two effects internally use `useEffect()`, which essentially mean that they create an effect node, but they do so using a different tag value.\n\n\nThe tag is composed out of a combination of binary values (see [implementation](https://github.com/facebook/react/tree/5f06576f51ece88d846d01abd2ddd575827c6127/packages/react-reconciler/src/ReactHookEffectTags.js)):\n\n\n```javascript\nconst NoEffect = /*             */ 0b00000000;\nconst UnmountSnapshot = /*      */ 0b00000010;\nconst UnmountMutation = /*      */ 0b00000100;\nconst MountMutation = /*        */ 0b00001000;\nconst UnmountLayout = /*        */ 0b00010000;\nconst MountLayout = /*          */ 0b00100000;\nconst MountPassive = /*         */ 0b01000000;\nconst UnmountPassive = /*       */ 0b10000000;\n```\n\nThe most common use cases for these binary values would be using a pipeline (`|`) and add the bits as is to a single value. Then we can check whether a tag implements a certain behavior or not using an ampersand (`&`). If the result is non-zero, it means that the tag implements the specified behavior.\n\n\n```javascript\nconst effectTag = MountPassive | UnmountPassive\nassert(effectTag, 0b11000000)\nassert(effectTag & MountPassive, 0b10000000)\n```\n\nHere are the supported hook effect types by React along with their tags (see [implementation](https://github.com/facebook/react/tree/5f06576f51ece88d846d01abd2ddd575827c6127/packages/react-reconciler/src/ReactFiberHooks.js:520)):\n\n\n-   Default effect ‚Äî `UnmountPassive | MountPassive`.\n\n-   Mutation effect ‚Äî `UnmountSnapshot | MountMutation`.\n\n-   Layout effect ‚Äî `UnmountMutation | MountLayout`.\n\n\nAnd here‚Äôs how React checks for behavior implementation (see [implementation](https://github.com/facebook/react/tree/5f06576f51ece88d846d01abd2ddd575827c6127/packages/react-reconciler/src/ReactFiberCommitWork.js#L309)):\n\n\n```javascript\nif ((effect.tag & unmountTag) !== NoHookEffect) {\n  // Unmount\n}\nif ((effect.tag & mountTag) !== NoHookEffect) {\n  // Mount\n}\n```\n\nSo, based on what we‚Äôve just learned regards effect hooks, we can actually inject an effect to a certain fiber externally:\n\n```javascript\nfunction injectEffect(fiber) {\n  const lastEffect = fiber.updateQueue.lastEffect\n\n  const destroyEffect = () => {\n    console.log('on destroy')\n  }\n\n  const createEffect = () => {\n    console.log('on create')\n\n    return destroy\n  }\n\n  const injectedEffect = {\n    tag: 0b11000000,\n    next: lastEffect.next,\n    create: createEffect,\n    destroy: destroyEffect,\n    inputs: [createEffect],\n  }\n\n  lastEffect.next = injectedEffect\n}\n\nconst ParentComponent = (\n  <ChildComponent ref={injectEffect} />\n)\n```\n\n---\n\nSo that was it! What was your biggest takeout from this article? How are you gonna use this new knowledge in your React apps? Would love to see interesting comments!\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"eb59638c9dba\",\"publishedDate\":1542809736324,\"url\":\"https://medium.com/the-guild/under-the-hood-of-reacts-hooks-system-eb59638c9dba\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMTowNToxNiswMTowMM4izrW_",
            "node": {
              "title": "Implementing a runtime version of JSX",
              "body": "## Learning how to think like a JSX parser and building an AST\n\nJSX is one of the most commonly used syntax extensions out there. Originally JSX was parsed via a [Facebook fork of Esprima](https://github.com/facebookarchive/esprima) ‚Äî a JavaScript syntax parser developed by jQuery. As it gained momentum, [Acorn](https://github.com/acornjs/acorn) took things to their hands and decided to make their own version of the parser which ended up being 1.5‚Äì2x faster than Esprima-fb, and is now being used by officially Babel.\n\n\nIt definitely went through an evolution, but regardless of its phase, all parsers had a similar output ‚Äî which is an AST. Once we have an AST representation of the JSX code, interpretation is extremely easy.\n\nToday we‚Äôre gonna understand how a JSX parser thinks by implementing one of our own. Unlike Babel, rather than compiling, we‚Äôre gonna evaluate the nodes in the AST according to their types, which means that we will be able to use JSX during runtime.\n\n---\n\nBelow is an example of the final product:\n\n```javascript\nclass Hello extends React.Component {\n  render() {\n    return jsx `<div>Hello ${this.props.name}</div>`\n  }\n}\n\nReactDOM.render(\n  jsx `<${Hello} name=\"World\" />`,\n  document.getElementById('container')\n)\n```\n\nBefore we go ahead and rush to implementing the parser let‚Äôs understand what we‚Äôre aiming for. JSX simply takes an HTML-like syntax and transforms it into nested `React.createElement()` calls. What makes JSX unique is that we can use string interpolation within our HTML templates, so we can provide it with data which doesn‚Äôt necessarily has to be serialized, things like functions, arrays, or objects.\n\n\nSo given the following code:\n\n```jsx\nconst el = (props) => (\n  <div onClick={props.onClick}>\n    <Icon src={props.icon} /><span>{props.text}</span>\n  </div>\n)\n```\n\nWe should get the following output once compiling it with Babel:\n\n```javascript\nconst el = (props) => (\n  React.createElement(\n    \"div\",\n    { onClick: props.onClick },\n    React.createElement(Icon, { src: props.icon }),\n    React.createElement(\n      \"span\",\n      null,\n      props.text\n    )\n  )\n)\n```\n\nJust aquick reminder ‚Äî the compiled result should be used internally by ReactDOM to differentiate changes in the virtual DOM and then render them. This is something which is React specific and has nothing to do with JSX, so at this point we have achieved our goal.\n\nEssentially there are 3 things we should figure out when parsing a JSX code:\n\n-   The name / component of the React element.\n-   The props of the React element.\n-   The children of the React element, for each this process should repeat itself recursively.\n\nAs I mentioned earlier, it would be best if we could break down the code into nodes first and represent it as an AST. Looking at the input of the example above, we can roughly visualize how we would pluck the nodes from the code:\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*AqTHDuxX5NNCI3iLycVfxA.png?raw=true \"Analyzing the JSX code.\")\n\nAnd to put things simple, here‚Äôs a schematic representation of the analysis above:\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*i8h2MocLHni8mTuPaakwBQ.png?raw=true \"A schematic representation of the analysis.\")\n\nAccordingly, we‚Äôre gonna have 3 types of nodes:\n\n-   Element node.\n-   Props node.\n-   Value node.\n\nLet‚Äôs decide that each node has a base schema with the following properties:\n\n-   node.type ‚Äî which will represent the type name of the node, e.g. `element`, `props` and `value`. Based on the node type we can also determine that additional properties that the node‚Äôs gonna carry. In our parser, each node type should have the following additional properties:\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*dgAy6Zbj6ttfNqgppWIjug.png?raw=true \"Node type schemas.\")\n\n-   node.length ‚Äîwhich represents the length of the sub-string in the code that the node occupies. This will help us trim the code string as we go with the parsing process so we can always focus on relevant parts of the string for the current node:\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*PeiZnuBTKfLlDiaL24dgHw.png?raw=true \"Any time we parse a small part of the string, we slice the part we‚Äôve just parsed.\")\n\nIn the function that we‚Äôre gonna build we‚Äôll be taking advantage of ES6‚Äôs tagged templates. Tagged templates are string literals which can be processed by a custom handler according to our needs (see [MDN docs](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals#Tagged_templates)).\n\n\nSo essentially the signature of our function should look like this:\n\n```javascript\nconst jsx = (splits, ...values) => {\n  // ...\n}\n```\n\nSince we‚Äôre gonna heavily rely on regular expression, it will be much easier to deal with a consistent string, so we can unleash the regexp full potential. For now let‚Äôs focus on the string part without the literal, and parse regular HTML string. Once we have that logic, we can implement string interpolation handling on top of it.\n\n## Starting with the core ‚Äî an HTML parser\n\nAs I already mentioned, our AST will be consisted of 3 node types, which means that we will have to create an ENUM that will contain the values `element`, `props` and `value`. This way the node types won't be hardcoded and patching the code can be very easy:\n\n\n```diff\n@@ -0,0 +1,5 @@\n+‚îä ‚îä1‚îäconst types = {\n+‚îä ‚îä2‚îä  element: 'element',\n+‚îä ‚îä3‚îä  value: 'value',\n+‚îä ‚îä4‚îä  props: 'props',\n+‚îä ‚îä5‚îä}üö´‚Üµ\n```\n\nSince we had 3 node types, it means that for each of them we should have a dedicated parsing function:\n\n```diff\n@@ -2,4 +2,40 @@\n ‚îä 2‚îä 2‚îä  element: 'element',\n ‚îä 3‚îä 3‚îä  value: 'value',\n ‚îä 4‚îä 4‚îä  props: 'props',\n-‚îä 5‚îä  ‚îä}üö´‚Üµ\n+‚îä  ‚îä 5‚îä}\n+‚îä  ‚îä 6‚îä\n+‚îä  ‚îä 7‚îäconst parseElement = (str) => {\n+‚îä  ‚îä 8‚îä  let match\n+‚îä  ‚îä 9‚îä  let length\n+‚îä  ‚îä10‚îä\n+‚îä  ‚îä11‚îä  const node = {\n+‚îä  ‚îä12‚îä    type: types.element,\n+‚îä  ‚îä13‚îä    props: parseProps(''),\n+‚îä  ‚îä14‚îä    children: [],\n+‚îä  ‚îä15‚îä    length: 0,\n+‚îä  ‚îä16‚îä    name: '',\n+‚îä  ‚îä17‚îä  }\n+‚îä  ‚îä18‚îä\n+‚îä  ‚îä19‚îä  return node\n+‚îä  ‚îä20‚îä}\n+‚îä  ‚îä21‚îä\n+‚îä  ‚îä22‚îäconst parseProps = (str) => {\n+‚îä  ‚îä23‚îä  let match\n+‚îä  ‚îä24‚îä  let length\n+‚îä  ‚îä25‚îä\n+‚îä  ‚îä26‚îä  const node = {\n+‚îä  ‚îä27‚îä    type: types.props,\n+‚îä  ‚îä28‚îä    length: 0,\n+‚îä  ‚îä29‚îä    props: {},\n+‚îä  ‚îä30‚îä  }\n+‚îä  ‚îä31‚îä\n+‚îä  ‚îä32‚îä  return node\n+‚îä  ‚îä33‚îä}\n+‚îä  ‚îä34‚îä\n+‚îä  ‚îä35‚îäconst parseValue = (str) => {\n+‚îä  ‚îä36‚îä  return {\n+‚îä  ‚îä37‚îä    type: types.value,\n+‚îä  ‚îä38‚îä    length: str.length,\n+‚îä  ‚îä39‚îä    value: str.trim(),\n+‚îä  ‚îä40‚îä  }\n+‚îä  ‚îä41‚îä}\n```\n\nEach function creates the basic node type and returns it. Note that at the begnning of the scope of each function I‚Äôve defined a couple of variables:\n\n-   `let match` - which will be used to store regular expression matches on the fly.\n\n-   `let length` - which will be used to store the length of the match so we can trim the JSX code string right after and accumulate it in `node.length`.\n\n\nFor now the `parseValue()` function is pretty straight forward and just returns a node which wraps the given string.\n\n\nWe will begin with the implementation of the element node and we will branch out to other nodes as we go. First we will try to figure out the name of the element. If an element tag opener was not found, we will assume that the current part of the code is a value:\n\n```diff\n@@ -16,6 +16,19 @@\n ‚îä16‚îä16‚îä    name: '',\n ‚îä17‚îä17‚îä  }\n ‚îä18‚îä18‚îä\n+‚îä  ‚îä19‚îä  match = str.match(/<(\\w+)/)\n+‚îä  ‚îä20‚îä\n+‚îä  ‚îä21‚îä  if (!match) {\n+‚îä  ‚îä22‚îä    str = str.split('<')[0]\n+‚îä  ‚îä23‚îä\n+‚îä  ‚îä24‚îä    return parseValue(str)\n+‚îä  ‚îä25‚îä  }\n+‚îä  ‚îä26‚îä\n+‚îä  ‚îä27‚îä  node.name = match[1]\n+‚îä  ‚îä28‚îä  length = match.index + match[0].length\n+‚îä  ‚îä29‚îä  str = str.slice(length)\n+‚îä  ‚îä30‚îä  node.length += length\n+‚îä  ‚îä31‚îä\n ‚îä19‚îä32‚îä  return node\n ‚îä20‚îä33‚îä}\n```\n\nUp next, we need to parse the props. To make things more efficient, we will need to first find the tag closer so we can provide the `parseProps()` method the relevant part of the string:\n\n\n```diff\n@@ -29,6 +29,15 @@\n ‚îä29‚îä29‚îä  str = str.slice(length)\n ‚îä30‚îä30‚îä  node.length += length\n ‚îä31‚îä31‚îä\n+‚îä  ‚îä32‚îä  match = str.match(/>/)\n+‚îä  ‚îä33‚îä\n+‚îä  ‚îä34‚îä  if (!match) return node\n+‚îä  ‚îä35‚îä\n+‚îä  ‚îä36‚îä  node.props = parseProps(str.slice(0, match.index), values)\n+‚îä  ‚îä37‚îä  length = node.props.length\n+‚îä  ‚îä38‚îä  str = str.slice(length)\n+‚îä  ‚îä39‚îä  node.length += length\n+‚îä  ‚îä40‚îä\n ‚îä32‚îä41‚îä  return node\n ‚îä33‚îä42‚îä}\n```\n\nNow that we‚Äôve plucked the right substring, we can go ahead and implement the `parseProps()` function logic:\n\n\n```diff\n@@ -51,6 +51,27 @@\n ‚îä51‚îä51‚îä    props: {},\n ‚îä52‚îä52‚îä  }\n ‚îä53‚îä53‚îä\n+‚îä  ‚îä54‚îä  const matchNextProp = () => {\n+‚îä  ‚îä55‚îä    match =\n+‚îä  ‚îä56‚îä      str.match(/ *\\w+=\"(?:.*[^\\\\]\")?/) ||\n+‚îä  ‚îä57‚îä      str.match(/ *\\w+/)\n+‚îä  ‚îä58‚îä  }\n+‚îä  ‚îä59‚îä\n+‚îä  ‚îä60‚îä  matchNextProp()\n+‚îä  ‚îä61‚îä\n+‚îä  ‚îä62‚îä  while (match) {\n+‚îä  ‚îä63‚îä    const propStr = match[0]\n+‚îä  ‚îä64‚îä    let [key, ...value] = propStr.split('=')\n+‚îä  ‚îä65‚îä    node.length += propStr.length\n+‚îä  ‚îä66‚îä    key = key.trim()\n+‚îä  ‚îä67‚îä    value = value.join('=')\n+‚îä  ‚îä68‚îä    value = value ? value.slice(1, -1) : true\n+‚îä  ‚îä69‚îä    node.props[key] = value\n+‚îä  ‚îä70‚îä    str = str.slice(0, match.index) + str.slice(match.index + propStr.length)\n+‚îä  ‚îä71‚îä\n+‚îä  ‚îä72‚îä    matchNextProp()\n+‚îä  ‚îä73‚îä  }\n+‚îä  ‚îä74‚îä\n ‚îä54‚îä75‚îä  return node\n ‚îä55‚îä76‚îä}\n```\n\nThe logic is pretty straight forward ‚Äî we iterate through the string, and each time we try match the next key->value pair. Once a pair wasn‚Äôt found, we return the node with the accumulated props. Note that providing only an attribute with no value is also a valid syntax which will set its value to `true` by default, thus the `/ *\\w+/` regexp. Let's proceed where we left of with the element parsing implementation.\n\n\nWe need to figure out whether the current element is self closing or not. If it is, we will return the node, and otherwise we will continue to parsing its children:\n\n```diff\n@@ -38,6 +38,22 @@\n ‚îä38‚îä38‚îä  str = str.slice(length)\n ‚îä39‚îä39‚îä  node.length += length\n ‚îä40‚îä40‚îä\n+‚îä  ‚îä41‚îä  match = str.match(/^ *\\/ *>/)\n+‚îä  ‚îä42‚îä\n+‚îä  ‚îä43‚îä  if (match) {\n+‚îä  ‚îä44‚îä    node.length += match.index + match[0].length\n+‚îä  ‚îä45‚îä\n+‚îä  ‚îä46‚îä    return node\n+‚îä  ‚îä47‚îä  }\n+‚îä  ‚îä48‚îä\n+‚îä  ‚îä49‚îä  match = str.match(/>/)\n+‚îä  ‚îä50‚îä\n+‚îä  ‚îä51‚îä  if (!match) return node\n+‚îä  ‚îä52‚îä\n+‚îä  ‚îä53‚îä  length = match.index + 1\n+‚îä  ‚îä54‚îä  str = str.slice(length)\n+‚îä  ‚îä55‚îä  node.length += length\n+‚îä  ‚îä56‚îä\n ‚îä41‚îä57‚îä  return node\n ‚îä42‚îä58‚îä}\n```\n\nAccordingly, we‚Äôre gonna implement the children parsing logic:\n\n```diff\n@@ -54,6 +54,16 @@\n ‚îä54‚îä54‚îä  str = str.slice(length)\n ‚îä55‚îä55‚îä  node.length += length\n ‚îä56‚îä56‚îä\n+‚îä  ‚îä57‚îä  let child = parseElement(str)\n+‚îä  ‚îä58‚îä\n+‚îä  ‚îä59‚îä  while (child.type === types.element || child.value) {\n+‚îä  ‚îä60‚îä    length = child.length\n+‚îä  ‚îä61‚îä    str = str.slice(length)\n+‚îä  ‚îä62‚îä    node.length += length\n+‚îä  ‚îä63‚îä    node.children.push(child)\n+‚îä  ‚îä64‚îä    child = parseElement(str)\n+‚îä  ‚îä65‚îä  }\n+‚îä  ‚îä66‚îä\n ‚îä57‚îä67‚îä  return node\n ‚îä58‚îä68‚îä}\n```\n\nChildren parsing is recursive. We keep calling the `parseElement()` method for the current substring until there's no more match. Once we've gone through all the children, we can finish the process by finding the closing tag:\n\n\n```diff\n@@ -64,6 +64,12 @@\n ‚îä64‚îä64‚îä    child = parseElement(str)\n ‚îä65‚îä65‚îä  }\n ‚îä66‚îä66‚îä\n+‚îä  ‚îä67‚îä  match = str.match(new RegExp(`</${node.name}>`))\n+‚îä  ‚îä68‚îä\n+‚îä  ‚îä69‚îä  if (!match) return node\n+‚îä  ‚îä70‚îä\n+‚îä  ‚îä71‚îä  node.length += match.index + match[0].length\n+‚îä  ‚îä72‚îä\n ‚îä67‚îä73‚îä  return node\n ‚îä68‚îä74‚îä}\n```\n\nThe HTML parsing part is finished! Now we can call the `parseElement()` for any given HTML string and we should get a JSON output which represents an AST, like the following:\n\n\n```\n{\n  \"type\": \"element\",\n  \"props\": {\n    \"type\": \"props\",\n    \"length\": 20,\n    \"props\": {\n      \"onclick\": \"onclick()\"\n    }\n  },\n  \"children\": [\n    {\n      \"type\": \"element\",\n      \"props\": {\n        \"type\": \"props\",\n        \"length\": 15,\n        \"props\": {\n          \"src\": \"icon.svg\"\n        }\n      },\n      \"children\": [],\n      \"length\": 18,\n      \"name\": \"img\"\n    },\n    {\n      \"type\": \"element\",\n      \"props\": {\n        \"type\": \"props\",\n        \"length\": 0,\n        \"props\": {}\n      },\n      \"children\": [\n        {\n          \"type\": \"value\",\n          \"length\": 4,\n          \"value\": \"text\"\n        }\n      ],\n      \"length\": 12,\n      \"name\": \"span\"\n    }\n  ],\n  \"length\": 74,\n  \"name\": \"div\"\n}\n```\n\n## Leveling up ‚Äî string interpolation\n\nNow we‚Äôre gonna add string interpolation on top of the HTML string parsing logic. Since we still wanna use the power of regexp at its full potential, we‚Äôre gonna assume that the given string would be a template with placeholders, where each of them should be replaced with a value. That would be the easiest and most efficient way, rather than accepting an array of string splits.\n\n```\n[\n  \"<__jsxPlaceholder>Hello __jsxPlaceholder</__jsxPlaceholder>\",\n  [MyComponent, \"World\", MyComponent]\n]\n```\n\nAccordingly, we will update the parsing functions‚Äô signature and their calls, and we will define a placeholder constant:\n\n```diff\n@@ -1,16 +1,18 @@\n+‚îä  ‚îä 1‚îäconst placeholder = `__jsxPlaceholder${Date.now()}`\n+‚îä  ‚îä 2‚îä\n ‚îä 1‚îä 3‚îäconst types = {\n ‚îä 2‚îä 4‚îä  element: 'element',\n ‚îä 3‚îä 5‚îä  value: 'value',\n ‚îä 4‚îä 6‚îä  props: 'props',\n ‚îä 5‚îä 7‚îä}\n ‚îä 6‚îä 8‚îä\n-‚îä 7‚îä  ‚îäconst parseElement = (str) => {\n+‚îä  ‚îä 9‚îäconst parseElement = (str, values) => {\n ‚îä 8‚îä10‚îä  let match\n ‚îä 9‚îä11‚îä  let length\n ‚îä10‚îä12‚îä\n ‚îä11‚îä13‚îä  const node = {\n ‚îä12‚îä14‚îä    type: types.element,\n-‚îä13‚îä  ‚îä    props: parseProps(''),\n+‚îä  ‚îä15‚îä    props: parseProps('', []),\n ‚îä14‚îä16‚îä    children: [],\n ‚îä15‚îä17‚îä    length: 0,\n ‚îä16‚îä18‚îä    name: '',\n@@ -21,7 +23,7 @@\n ‚îä21‚îä23‚îä  if (!match) {\n ‚îä22‚îä24‚îä    str = str.split('<')[0]\n ‚îä23‚îä25‚îä\n-‚îä24‚îä  ‚îä    return parseValue(str)\n+‚îä  ‚îä26‚îä    return parseValue(str, values)\n ‚îä25‚îä27‚îä  }\n ‚îä26‚îä28‚îä\n ‚îä27‚îä29‚îä  node.name = match[1]\n@@ -54,14 +56,14 @@\n ‚îä54‚îä56‚îä  str = str.slice(length)\n ‚îä55‚îä57‚îä  node.length += length\n ‚îä56‚îä58‚îä\n-‚îä57‚îä  ‚îä  let child = parseElement(str)\n+‚îä  ‚îä59‚îä  let child = parseElement(str, values)\n ‚îä58‚îä60‚îä\n ‚îä59‚îä61‚îä  while (child.type === types.element || child.value) {\n ‚îä60‚îä62‚îä    length = child.length\n ‚îä61‚îä63‚îä    str = str.slice(length)\n ‚îä62‚îä64‚îä    node.length += length\n ‚îä63‚îä65‚îä    node.children.push(child)\n-‚îä64‚îä  ‚îä    child = parseElement(str)\n+‚îä  ‚îä66‚îä    child = parseElement(str, values)\n ‚îä65‚îä67‚îä  }\n ‚îä66‚îä68‚îä\n ‚îä67‚îä69‚îä  match = str.match(new RegExp(`</${node.name}>`))\n@@ -73,7 +75,7 @@\n ‚îä73‚îä75‚îä  return node\n ‚îä74‚îä76‚îä}\n ‚îä75‚îä77‚îä\n-‚îä76‚îä  ‚îäconst parseProps = (str) => {\n+‚îä  ‚îä78‚îäconst parseProps = (str, values) => {\n ‚îä77‚îä79‚îä  let match\n ‚îä78‚îä80‚îä  let length\n ‚îä79‚îä81‚îä\n@@ -107,7 +109,7 @@\n ‚îä107‚îä109‚îä  return node\n ‚îä108‚îä110‚îä}\n ‚îä109‚îä111‚îä\n-‚îä110‚îä   ‚îäconst parseValue = (str) => {\n+‚îä   ‚îä112‚îäconst parseValue = (str, values) => {\n ‚îä111‚îä113‚îä  return {\n ‚îä112‚îä114‚îä    type: types.value,\n ‚îä113‚îä115‚îä    length: str.length,\n```\n\nNote how I used the `Date.now()` function to define a postfix for the placeholder. This we can be sure that the same value won't be given by the user as a string (possible, very unlikely). Now we will go through each parsing function and we'll make sure that it knows how to deal with placeholders correctly. We will start with the `parseElement()` function.\n\n\nWe will add an additional property to the node called: `node.tag`. The tag property is the component that will be used to create the React element. It can either be a string or a React.Component. If `node.name` is a placeholder, we will be taking the next value in the given values stack:\n\n\n```diff\n@@ -27,6 +27,7 @@\n ‚îä27‚îä27‚îä  }\n ‚îä28‚îä28‚îä\n ‚îä29‚îä29‚îä  node.name = match[1]\n+‚îä  ‚îä30‚îä  node.tag = node.name === placeholder ? values.shift() : node.name\n ‚îä30‚îä31‚îä  length = match.index + match[0].length\n ‚îä31‚îä32‚îä  str = str.slice(length)\n ‚îä32‚îä33‚îä  node.length += length\n@@ -72,6 +73,12 @@\n ‚îä72‚îä73‚îä\n ‚îä73‚îä74‚îä  node.length += match.index + match[0].length\n ‚îä74‚îä75‚îä\n+‚îä  ‚îä76‚îä  if (node.name === placeholder) {\n+‚îä  ‚îä77‚îä    const value = values.shift()\n+‚îä  ‚îä78‚îä\n+‚îä  ‚îä79‚îä    if (value !== node.tag) return node\n+‚îä  ‚îä80‚îä  }\n+‚îä  ‚îä81‚îä\n ‚îä75‚îä82‚îä  return node\n ‚îä76‚îä83‚îä}\n```\n\nWe also made sure that the closing tag matches the opening tag. I‚Äôve decided to ‚Äúswallow‚Äù errors rather than throwing them for the sake of simplicity, but generally speaking it would make a lot of sense to implement error throws within the parsing functions.\n\nUp next would be the props node. This is fairly simple, we‚Äôre only gonna add an additional regexp to the array of matchers, and that regexp will check for placeholders. If a placeholder was detected, we‚Äôre gonna replace it with the next value in the values stack:\n\n```diff\n@@ -95,6 +95,7 @@\n ‚îä 95‚îä 95‚îä  const matchNextProp = () => {\n ‚îä 96‚îä 96‚îä    match =\n ‚îä 97‚îä 97‚îä      str.match(/ *\\w+=\"(?:.*[^\\\\]\")?/) ||\n+‚îä   ‚îä 98‚îä      str.match(new RegExp(` *\\\\w+=${placeholder}`)) ||\n ‚îä 98‚îä 99‚îä      str.match(/ *\\w+/)\n ‚îä 99‚îä100‚îä  }\n ‚îä100‚îä101‚îä\n@@ -106,7 +107,9 @@\n ‚îä106‚îä107‚îä    node.length += propStr.length\n ‚îä107‚îä108‚îä    key = key.trim()\n ‚îä108‚îä109‚îä    value = value.join('=')\n-‚îä109‚îä   ‚îä    value = value ? value.slice(1, -1) : true\n+‚îä   ‚îä110‚îä    value =\n+‚îä   ‚îä111‚îä      value === placeholder ? values.shift() :\n+‚îä   ‚îä112‚îä      value ? value.slice(1, -1) : true\n ‚îä110‚îä113‚îä    node.props[key] = value\n ‚îä111‚îä114‚îä    str = str.slice(0, match.index) + str.slice(match.index + propStr.length)\n```\n\nLast but not least, would be the value node. This is the most complex to handle out of the 3 nodes, since it requires us to split the input string and create a dedicated value node out of each split. So now, instead of returning a single node value, we will return an array of them. Accordingly, we will also be changing the name of the function from `parseValue()` to `parseValues()`:\n\n\n```diff\n@@ -23,7 +23,7 @@\n ‚îä23‚îä23‚îä  if (!match) {\n ‚îä24‚îä24‚îä    str = str.split('<')[0]\n ‚îä25‚îä25‚îä\n-‚îä26‚îä  ‚îä    return parseValue(str, values)\n+‚îä  ‚îä26‚îä    return parseValues(str, values)\n ‚îä27‚îä27‚îä  }\n ‚îä28‚îä28‚îä\n ‚îä29‚îä29‚îä  node.name = match[1]\n@@ -57,14 +57,26 @@\n ‚îä57‚îä57‚îä  str = str.slice(length)\n ‚îä58‚îä58‚îä  node.length += length\n ‚îä59‚îä59‚îä\n-‚îä60‚îä  ‚îä  let child = parseElement(str, values)\n+‚îä  ‚îä60‚îä  let children = []\n ‚îä61‚îä61‚îä\n-‚îä62‚îä  ‚îä  while (child.type === types.element || child.value) {\n-‚îä63‚îä  ‚îä    length = child.length\n-‚îä64‚îä  ‚îä    str = str.slice(length)\n-‚îä65‚îä  ‚îä    node.length += length\n-‚îä66‚îä  ‚îä    node.children.push(child)\n-‚îä67‚îä  ‚îä    child = parseElement(str, values)\n+‚îä  ‚îä62‚îä  const parseNextChildren = () => {\n+‚îä  ‚îä63‚îä    children = [].concat(parseElement(str, values))\n+‚îä  ‚îä64‚îä  }\n+‚îä  ‚îä65‚îä\n+‚îä  ‚îä66‚îä  parseNextChildren()\n+‚îä  ‚îä67‚îä\n+‚îä  ‚îä68‚îä  while (children.length) {\n+‚îä  ‚îä69‚îä    children.forEach((child) => {\n+‚îä  ‚îä70‚îä      length = child.length\n+‚îä  ‚îä71‚îä      str = str.slice(length)\n+‚îä  ‚îä72‚îä      node.length += length\n+‚îä  ‚îä73‚îä\n+‚îä  ‚îä74‚îä      if (child.type !== types.value || child.value) {\n+‚îä  ‚îä75‚îä        node.children.push(child)\n+‚îä  ‚îä76‚îä      }\n+‚îä  ‚îä77‚îä    })\n+‚îä  ‚îä78‚îä\n+‚îä  ‚îä79‚îä    parseNextChildren()\n ‚îä68‚îä80‚îä  }\n ‚îä69‚îä81‚îä\n ‚îä70‚îä82‚îä  match = str.match(new RegExp(`</${node.name}>`))\n@@ -119,10 +131,40 @@\n ‚îä119‚îä131‚îä  return node\n ‚îä120‚îä132‚îä}\n ‚îä121‚îä133‚îä\n-‚îä122‚îä   ‚îäconst parseValue = (str, values) => {\n-‚îä123‚îä   ‚îä  return {\n-‚îä124‚îä   ‚îä    type: types.value,\n-‚îä125‚îä   ‚îä    length: str.length,\n-‚îä126‚îä   ‚îä    value: str.trim(),\n-‚îä127‚îä   ‚îä  }\n+‚îä   ‚îä134‚îäconst parseValues = (str, values) => {\n+‚îä   ‚îä135‚îä  const nodes = []\n+‚îä   ‚îä136‚îä\n+‚îä   ‚îä137‚îä  str.split(placeholder).forEach((split, index, splits) => {\n+‚îä   ‚îä138‚îä    let value\n+‚îä   ‚îä139‚îä    let length\n+‚îä   ‚îä140‚îä\n+‚îä   ‚îä141‚îä    value = split\n+‚îä   ‚îä142‚îä    length = split.length\n+‚îä   ‚îä143‚îä    str = str.slice(length)\n+‚îä   ‚îä144‚îä\n+‚îä   ‚îä145‚îä    if (length) {\n+‚îä   ‚îä146‚îä      nodes.push({\n+‚îä   ‚îä147‚îä        type: types.value,\n+‚îä   ‚îä148‚îä        length,\n+‚îä   ‚îä149‚îä        value,\n+‚îä   ‚îä150‚îä      })\n+‚îä   ‚îä151‚îä    }\n+‚îä   ‚îä152‚îä\n+‚îä   ‚îä153‚îä    if (index === splits.length - 1) return\n+‚îä   ‚îä154‚îä\n+‚îä   ‚îä155‚îä    value = values.pop()\n+‚îä   ‚îä156‚îä    length = placeholder.length\n+‚îä   ‚îä157‚îä\n+‚îä   ‚îä158‚îä    if (typeof value === 'string') {\n+‚îä   ‚îä159‚îä      value = value.trim()\n+‚îä   ‚îä160‚îä    }\n+‚îä   ‚îä161‚îä\n+‚îä   ‚îä162‚îä    nodes.push({\n+‚îä   ‚îä163‚îä      type: types.value,\n+‚îä   ‚îä164‚îä      length,\n+‚îä   ‚îä165‚îä      value,\n+‚îä   ‚îä166‚îä    })\n+‚îä   ‚îä167‚îä  })\n+‚îä   ‚îä168‚îä\n+‚îä   ‚îä169‚îä  return nodes\n ‚îä128‚îä170‚îä}\n```\n\nThe reason why I‚Äôve decided to return an array of nodes and not a singe node which contains an array of values, just like the props node, is because it matches the signature of `React.createElement()` perfectly. The values will be passed as children with a spread operator (`...`), and you should see further this tutorial how this well it fits.\n\n\nNote that we‚Äôve also changed the way we accumulate children in the `parseElement()` function. Since `parseValues()`returns an array now, and not a single node, we flatten it using an empty array concatenation (`[].concat()`), and we only push the children whose contents are not empty.\n\n\n## **The grand finale ‚Äî execution**\n\n\nAt this point we should have a function which can transform a JSX code into an AST, including string interpolation. The only thing which is left to do now is build a function which will recursively create React elements out of the nodes in the tree.\n\nThe main function of the module should be called with a template tag. If you went through the previous step, you should know that a consistent string has an advantage over an array of splits of strings, since we can unleash the full potential of a regexp with ease. Accordingly, we will take all the given splits and join them with the `placeholder` constant.\n\n\n```\n['<', '> Hello ', '</', '>'] -> '<__jsxPlaceholder>Hello __jsxPlaceholder</__jsxPlaceholder>'\n```\n\nOnce we join the string we can create React elements recursively:\n\n```diff\n@@ -1,3 +1,5 @@\n+‚îä ‚îä1‚îäimport React from 'react'\n+‚îä ‚îä2‚îä\n ‚îä1‚îä3‚îäconst placeholder = `__jsxPlaceholder${Date.now()}`\n ‚îä2‚îä4‚îä\n ‚îä3‚îä5‚îäconst types = {\n@@ -6,6 +8,24 @@\n ‚îä 6‚îä 8‚îä  props: 'props',\n ‚îä 7‚îä 9‚îä}\n ‚îä 8‚îä10‚îä\n+‚îä  ‚îä11‚îäexport const jsx = (splits, ...values) => {\n+‚îä  ‚îä12‚îä  const root = parseElement(splits.join(placeholder), values)\n+‚îä  ‚îä13‚îä\n+‚îä  ‚îä14‚îä  return createReactElement(root)\n+‚îä  ‚îä15‚îä}\n+‚îä  ‚îä16‚îä\n+‚îä  ‚îä17‚îäconst createReactElement = (node) => {\n+‚îä  ‚îä18‚îä  if (node.type === types.value) {\n+‚îä  ‚îä19‚îä    return node.value\n+‚îä  ‚îä20‚îä  }\n+‚îä  ‚îä21‚îä\n+‚îä  ‚îä22‚îä  return React.createElement(\n+‚îä  ‚îä23‚îä    node.tag,\n+‚îä  ‚îä24‚îä    node.props.props,\n+‚îä  ‚îä25‚îä    ...node.children.map(createReactElement),\n+‚îä  ‚îä26‚îä  )\n+‚îä  ‚îä27‚îä}\n+‚îä  ‚îä28‚îä\n ‚îä 9‚îä29‚îäconst parseElement = (str, values) => {\n ‚îä10‚îä30‚îä  let match\n ‚îä11‚îä31‚îä  let length\n@@ -168,3 +188,5 @@\n ‚îä168‚îä188‚îä\n ‚îä169‚îä189‚îä  return nodes\n ‚îä170‚îä190‚îä}\n+‚îä   ‚îä191‚îä\n+‚îä   ‚îä192‚îäexport default jsx\n```\n\nNote that if a node of value type is being iterated, we will just return the raw string, otherwise we will try to address its `node.children` property which doesn't exist.\n\n\n---\n\nOur JSX runtime function is now ready to use!\n\nIf you wonder how did I structure this tutorial so nicely with steps and beautiful diffs ‚Äî check out [tortilla.academy](https://tortilla.academy/) by [Uri Goldshtein](https://medium.com/@urigo).\n\n\nLastly, you can view the source code at the official [Github repository](https://github.com/DAB0mB/jsx-runtime) or you can download a Node.JS package using NPM:\n\n\n```\n$ npm install jsx-runtime\n```\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"78e004bf432e\",\"publishedDate\":1542049983211,\"url\":\"https://medium.com/the-guild/implementing-a-runtime-version-of-jsx-78e004bf432e\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMTowNDozOCswMTowMM4izrSV",
            "node": {
              "title": "Recursive React tree component implementation made easy",
              "body": "## The challenges that I‚Äôve faced and how I solved them\n\nWhen I was building [tortilla.acedemy‚Äôs diff page](https://tortilla.academy/tutorial/chatty/version/2-0-0/diff/3-0-0), I was looking to have a tree view that could represent a hierarchy of files, just like Windows‚Äô classic navigation tree. Since it was all about showing a git-diff, I also wanted to have small annotations next to each file, which will tell us whether it was added, removed, or deleted. There are definitely existing for that out there in the echo system, like [Storybook‚Äôs tree beard](https://github.com/storybooks/react-treebeard), but I‚Äôve decided to implement something that will work just the way I want right out of the box, because who knows, maybe someone else will need it one day.\n\n\nThis is how I wanted my tree‚Äôs API to look like:\n\n```javascript\nimport React from 'react'\nimport FSRoot from 'react-fs-tree'\n\nconst FSTree = () => (\n  <FSRoot childNodes={[\n    { name: 'file' },\n    { name: 'added file', mode: 'a' },\n    { name: 'deleted file', mode: 'd' },\n    { name: 'modified file', mode: 'm' },\n    { name: 'folder', opened: true, childNodes: [\n      { name: 'foo' },\n      { name: 'bar', selected: true },\n      { name: 'baz' },\n    ] },\n  ]} />\n)\n\nexport default FSTree\n```\n\nDuring my implementation of that tree I‚Äôve faced some pretty interesting challenges, and I have thought to write an article about it and share some of my insights; so let‚Äôs cut to the chase.\n\n---\n\n# Architecture\n\nMy tree is made out of 3 internal components:\n\n-   **FSRoot** _(see [FSRoot.js](https://github.com/DAB0mB/react-fs-tree/blob/fc0a0b3b2042e312d4238e0660c161f7744dd732/src/index.js))_‚Äî This is where the tree starts to grow from. It‚Äôs a container that encapsulates internal props which are redundant to the user (like props.rootNode, props.parentNode, etc) and exposes only the relevant parts (like props.childNodes, props.onSelect, etc). It also contains a tag which rules that are relevant nested components.</x-turndown>\n\n-   **FSBranch** _(see [FSBranch.js](https://github.com/DAB0mB/react-fs-tree/blob/fc0a0b3b2042e312d4238e0660c161f7744dd732/src/FSBranch.js))_ ‚Äî A branch contains the list that will iterate through the nodes. The branch is what will give the tree the staircase effect and will get further away from the edge as we go deeper. Any time we reveal the contents of a node with child nodes, a new nested branch should be created.\n\n-   **FSNode** _(see [FSNode.js](https://github.com/DAB0mB/react-fs-tree/blob/fc0a0b3b2042e312d4238e0660c161f7744dd732/src/FSNode.js))_ ‚Äî The node itself. It will present the given node‚Äôs metadata: its name, its mode (added, deleted or modified), and its children. This node is also used as a controller to directly control the node‚Äôs metadata and update the view right after. More information about that further this article.\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*EPgXgphjIBkBrEae8YZ4sw.png?raw=true \"A relational diagram of the tree\")\n\nThe recursion pattern in the diagram above is very clear to see. Programmatically speaking, this causes a problematic situation where each module is dependent on one another. So before FSNode.js was even loaded, we import it in FSBranch.js which will result in an undefined module.\n\n```javascript\n/* FSBranch.js - will be loaded first */\nimport React from 'react'\nimport FSNode from './FSNode'\n\n// implementation...\n\nexport default FSBranch\n\n/* FSNode.js - will be loaded second */\nimport React from 'react'\n// The following will be undefined since it's the caller module and was yet to be loaded\nimport FSBranch from './FSBranch'\n\n// implementation...\n\nexport default FSNode\n```\n\nThere are two ways to solve this problem:\n\n-   Switching to CommonJS and move the require() to the bottom of the first dependent module ‚Äî which I‚Äôm not gonna get into. It doesn‚Äôt look elegant and it doesn‚Äôt work with some versions of Webpack; during the bundling process all the require() declarations might automatically move to the top of the module which will force-cause the issue again.\n-   Having a third module which will export the dependent modules and will be used at the next event loop ‚Äî some might find this an anti pattern but I like it because we don‚Äôt have to switch to CommonJS and it‚Äôs highly compatible with Webpack‚Äôs strategy.\n\nThe following code snippet demonstrates the second preferred way of solving recursive dependency conflict:\n\n```javascript\n/* module.js */\nexport const exports = {}\nexport default { exports }\n\n/* FSBranch.js */\nimport React from 'react'\nimport { exports } from './module'\n\nclass FSBranch extends React.Component {\n  render() {\n    return <exports.FSNode />\n  }\n}\n\nexports.FSBranch = FSBranch\n\n/* FSNode.js */\nimport React from 'react'\nimport { exports } from './module'\n\nclass FSNode extends React.Component {\n  render() {\n    return <exports.FSBranch />\n  }\n}\n\nexports.FSNode = FSNode\n```\n\n# Style\n\nThere are two methods to implement the staircase effect:\n\n-   Using a floating tree ‚Äî where each branch has a constant left-margin and completely floats.\n-   Using a padded tree ‚Äî where each branch doesn‚Äôt move further away but has an incremental padding.\n\nA floating tree makes complete sense. It nicely vertically aligns the nodes within it based on the deepness level we‚Äôre currently at. The deeper we go the further away we‚Äôll get from the left edge, which will result in this nice staircase effect.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*Wl8C7MS_EWCmThP9eEGeig.png?raw=true \"A floating tree\")\n\nHowever, as you can see in the illustrated tree, when selecting a node it will not be fully stretched to the left, as it completely floats with the branch. The solutions for that would be a padded tree.\n\nUnlike the floating tree, each branch in the padded tree would fully stretch to the left, and the deeper we go the more we gonna increase the pad between the current branch and the left edge. This way the nodes will still be vertically aligned like a staircase, but now when we select them, the highlight would appear all across the container. It‚Äôs less intuitive and slightly harder to implement, but it does the job.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*KsRLZ1qLuW8Rdakm_8HG7w.png?raw=true \"A padded tree\")\n\nProgrammatically speaking, this would require us to pass a counter that will indicate how deep the current branch is (n), and multiply it by a constant value for each of its nodes (x) (See [implementation](https://github.com/DAB0mB/react-fs-tree/blob/475c394c51dca52dda205dd1ceaba2ede679609b/src/fs-node.js#L263)).\n\n\n# Event Handling\n\nOne of the things that I was looking to have in my tree was an easy way to update it, for example, if one node was selected, deselected the previous one, so selection can be unique. There are many ways that this could be achieved, the most naive one would be updating one of the node‚Äôs data and then resetting the state of the tree from its root.\n\nThere‚Äôs nothing necessarily bad with that solution and it‚Äôs actually a great pattern, however, if not implemented or used correctly, this can cause the entire DOM tree to be re-rendered, which is completely unnecessary. Instead, why not just use the node‚Äôs component as a controller?\n\nYou heard me right. Directly grabbing the reference from the React.Component‚Äôs callback and use the methods on its prototype. Sounds tricky, but it works fast and efficiently (see [implementation](https://github.com/DAB0mB/react-fs-tree/blob/475c394c51dca52dda205dd1ceaba2ede679609b/src/fs-node.js#L146)).\n\n\n```javascript\nfunction onSelect(node) {\n  // A React.Component is used directly as a controller\n  assert(node instanceof React.Component)\n  assert(node instanceof FSNode)\n\n  if (this.state.selectedNode) {\n    this.state.selectedNode.deselect()\n  }\n\n  this.setState({\n    selectedNode: node\n  })\n}\n\nfunction onDeselect() {\n  this.setState({\n    selectedNode: null\n  })\n}\n```\n\nOne thing to note is that since the controllers are hard-wired to the view, hypothetically speaking we wouldn‚Äôt be able to have any controllers for child nodes of a node that is not revealed (`node.opened === false`). I‚Äôve managed to bypass this issue by using the React.Component‚Äôs constructor directly. This is perfectly legal and no error is thrown, unless used irresponsibly to render something, which completely doesn‚Äôt make sense (`new FSNode(props)`; see [implementation](https://github.com/DAB0mB/react-fs-tree/blob/475c394c51dca52dda205dd1ceaba2ede679609b/src/fs-node.js#L330)).\n\n\n# **Final Words**\n\n\nA program can be written in many ways. I know that my way of implementing a tree view can be very distinct, but since all trees should be based around recursion, you can take a lot from what I‚Äôve learnt.\n\nBelow is the final result of the tree that I‚Äôve created. Feel free to visit its [Github page](https://github.com/DAB0mB/react-fs-tree) or grab a copy using NPM.\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*k6kq7XS-u9KHiHkie6YwuQ.png?raw=true \"$ npm install react-fs-tree\")\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"466dfce1a008\",\"publishedDate\":1541405658024,\"url\":\"https://medium.com/the-guild/recursive-react-tree-component-implementation-made-easy-466dfce1a008\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMTowNDoxNSswMTowMM4izrPp",
            "node": {
              "title": "Getting to know React DOM‚Äôs event handling system inside out",
              "body": "It all started when I‚Äôve tried to redirect submitted React event handlers into another DOM element. I won‚Äôt get into details regarding the use case, but what I did was fairly logical: I‚Äôve redefined the `addEventListener()` method on the DOM element‚Äôs instance, hoping to capture the submitted arguments and do as I wish with them. Unfortunately, it didn‚Äôt work‚Ä¶\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*BlIFSCqAqGdsqKUx?raw=true)\n\nHow come?! How could it be that React handles events without calling the `addEventListener()` method? After all, it has proven itself to work, across many many applications.\n\n\nTrue, but it‚Äôs not what you think. First I would like you to take a snapshot of ReactDOM‚Äôs implementation. It actually has a comment which explains the entire event handling system:\n\n```\nSummary of `ReactBrowserEventEmitter` event handling:\n```\n\n```\n  - Top-level delegation is used to trap most native browser events. This may only occur in the main thread and is the responsibility of ReactDOMEventListener, which is injected and can therefore support pluggable event sources. This is the only work that occurs in the main thread.\n```\n\n```\n  - We normalize and de-duplicate events to account for browser quirks. This may be done in the worker thread.\n```\n\n```\n  - Forward these native events (with the associated top-level type used to trap it) to `EventPluginHub`, which in turn will ask plugins if they want to extract any synthetic events.\n```\n\n```\n  - The `EventPluginHub` will then process each event by annotating them with \"dispatches\", a sequence of listeners and IDs that care about that event.\n```\n\n```\n  - The `EventPluginHub` then dispatches the events.\n```\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*LFM3qo55AbDsmPPLhX9rRA.png?raw=true)\n\n> **_Source:_** _[src/events/ReactBrowserEventEmitter.js:32](https://github.com/facebook/react/blob/b87aabdfe1b7461e7331abb3601d9e6bb27544bc/packages/react-dom/src/events/ReactBrowserEventEmitter.js#L32)_\n>\n\nAt the beginning this is what I saw:\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*ZLL8JTaj3N3-vD0_.jpg?raw=true)\n\nBut after debugging a little, going through the stack trace and some of React‚Äôs documentation, things are much clearer now. Let‚Äôs break it down then, and try to make things simpler.\n\n```\nTop-level delegation is used to trap most native browser events. This may only occur in the main thread and is the responsibility of\nReactDOMEventListener, which is injected and can therefore support\npluggable event sources. This is the only work that occurs in the main thread.\n```\n\nReact uses a single event listener per single event type to invoke all submitted handlers within the virtual DOM. For example, given the following React component:\n\n```javascript\nconst ExampleComponent = () => (\n  <div onClick={onClick}>\n    <div onClick={onClick} />\n  </div>\n)\n```\n\nWe will have a single event listener registered on the native DOM for the `click` event. By running the `getEventListeners()` method which is available on Chrome dev-tools, we would get the following result:\n\n\n```\n{click: Array(1)}\n```\n\nEach event-type listener will be ensured per single render cycle, so if we were to define additional event handlers of `keydown`type, we would get the following output:\n\n\n```\n{click: Array(1), keydown: Array(1)}\n```\n\n> **_Source:_** _[packages/react-dom/src/client/ReactDOMComponent.js:225](https://github.com/facebook/react/blob/8a8d973d3cc5623676a84f87af66ef9259c3937c/packages/react-dom/src/client/ReactDOMComponent.js#L225)_\n>\n\n```\nWe normalize and de-duplicate events to account for browser quirks. This may be done in the worker thread.\n```\n\nFor each and every browser, regardless of its implementation, we will have consistent event arguments, as React normalizes them. Whether we use the latest Chrome browser or IE8, the `click` event arguments will look like so:\n\n\n-   **boolean** altKey\n\n-   **number** button\n\n-   **number** buttons\n\n-   **number** clientX\n\n-   **number** clientY\n\n-   **boolean** ctrlKey\n\n-   **boolean** getModifierState(key)\n\n-   **boolean** metaKey\n\n-   **number** pageX\n\n-   **number** pageY\n\n-   **DOMEventTarget** relatedTarget\n\n-   **number** screenX\n\n-   **number** screenY\n\n-   **boolean** shiftKey\n\n\n> **_Docs:_** _[events:supported-events](https://reactjs.org/docs/events.html#supported-events) **Source:** [packages/react-dom/src/events/SimpleEventPlugin.js:259](https://github.com/facebook/react/blob/master/packages/react-dom/src/events/SimpleEventPlugin.js#L259)_\n>\n\nSince React is registering a single event listener per multiple handlers, it would need to re-dispatch the event for each and every handler.\n\n> **_Source:_** _[EventPluginHub.js:168](https://github.com/facebook/react/blob/b87aabdfe1b7461e7331abb3601d9e6bb27544bc/packages/events/EventPluginHub.js#L168)_\n>\n\n```\nForward these native events (with the associated top-level type used to trap it) to `EventPluginHub`, which in turn will ask plugins if they want to extract any synthetic events.\n```\n\nThe `EventPluginHub` is a very central component in React‚Äôs event handling system. This is what unifies all event plug-ins into a single place, and will redirect dispatched events to each and every one of them. Each plug-in is responsible for extracting and handling different event types, for example, we have the `SimpleEventPlugin` will handle events which are likely to be implemented across most browsers like mouse events and key presses ([source](https://github.com/facebook/react/blob/master/packages/react-dom/src/events/SelectEventPlugin.js)); we also have the `ChangeEventPlugin`which will handle the very famous `onChange` event ([source](https://github.com/facebook/react/blob/master/packages/react-dom/src/events/ChangeEventPlugin.js)).\n\n\n> **_Source:_** _[packages/events/EventPluginHub.js:168](https://github.com/facebook/react/blob/b87aabdfe1b7461e7331abb3601d9e6bb27544bc/packages/events/EventPluginHub.js#L168)_\n>\n\nSynthetic events are React‚Äôs normalized event arguments which ensures that there‚Äôs consistency across all browsers, and are being generated by the plug-ins. Note that synthetic events are being pooled! Which means that the same object instance is used in multiple handlers, only it is being reset with new properties before each and every invocation and then disposed:\n\n```javascript\nfunction onClick(event) {\n  console.log(event); // => nullified object.\n  console.log(event.type); // => \"click\"\n  const eventType = event.type; // => \"click\"\n  setTimeout(function() {\n    console.log(event.type); // => null\n    console.log(eventType); // => \"click\"\n  }, 0);\n  // Won't work. this.state.clickEvent will only contain null values.\n  this.setState({clickEvent: event});\n  // You can still export event properties.\n  this.setState({eventType: event.type});\n}\n```\n\n> **_Docs:_** _[events:event-pooling](https://reactjs.org/docs/events.html#event-pooling) **Source:** [packages/react-dom/src/events/SimpleEventPlugin.js:322](https://github.com/facebook/react/blob/master/packages/react-dom/src/events/SimpleEventPlugin.js#L322)_\n>\n\n```\nThe `EventPluginHub` will then process each event by annotating them with \"dispatches\", a sequence of listeners and IDs that care about that event.\n```\n\nAs mentioned, each and every event can have multiple handlers, even though each of them is actually being listened once by the real DOM. Accordingly, the relevant ‚Äúdispatches‚Äù which consist of event handlers and their corresponding fiber nodes (nodes in the virtual DOM tree) need to be accumulated for future use.\n\n> **_Source:_** _[packages/events/EventPropagators.js:90](https://github.com/facebook/react/blob/b87aabdfe1b7461e7331abb3601d9e6bb27544bc/packages/events/EventPropagators.js#L90)_\n>\n\n```\nThe `EventPluginHub` then dispatches the events.\n```\n\nThe plug-in hub goes through the accumulated information and dispatches the events, thus invoking the submitted event handlers.\n\n> **_Source:_** _[packages/events/EventPluginUtils.js:77](https://github.com/facebook/react/blob/b87aabdfe1b7461e7331abb3601d9e6bb27544bc/packages/events/EventPluginUtils.js#L77)_\n>\n\nSo that‚Äôs how that events handling system works in a nutshell. There are few things I would like you to note:\n\n-   Top level event listeners which are registered to the main DOM (`window.document`) can also be registered to other DOMs, depends on where application container‚Äôs at. For example, if the container is adopted by an `iframe`, then the `iframe`‚Äòs DOM will be the main event listener; it can also be a document fragment, a shadow DOM, etc. It‚Äôs important that you‚Äôd be aware of that and know that there‚Äôs a slight limitation the events‚Äô propagation.\n\n-   React re-dispatches the events in two phases: one for capturing and the other for bubbling, just like how the native DOM does.\n-   The event handling which is done for React Native **is different** than React DOM‚Äôs and you shouldn‚Äôt confuse between the two! React is just a library that produces a virtual representation of the view that we would like to render, and React DOM/Native are the bridge between React and the environment that we‚Äôre using. **This article is relevant for React DOM only!**\n\n\nAt the end of the day you‚Äôll still be able to use React, with or without this information, but I think that a vastly used library such as React deserves more attention, especially if you wanna step up your game.\n\nSo getting back to what brought me to write this article, if I wanted to redirect the registered by React, all I had to do was redefining the `addEventListener()` for the DOM, and not the corresponding Node. Of course, overwriting a native method is NOT something that should be done and it‚Äôs a very bad practice (\\*cough cough\\* Zone.js), but I won‚Äôt get into my specific use case as this is a topic for another article.\n\n\n**Update:** (November 21st, 2018)\n\n\nFor those who liked this article and how I analyze React‚Äôs implementation, I recommend you to read my article about [React Hooks and how they work under the hood](https://medium.com/the-guild/under-the-hood-of-reacts-hooks-system-eb59638c9dba).\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"378c44d2a5d0\",\"publishedDate\":1540195197007,\"url\":\"https://medium.com/the-guild/getting-to-know-react-doms-event-handling-system-inside-out-378c44d2a5d0\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMTowMzo1MyswMTowMM4izrNB",
            "node": {
              "title": "This is how I build Babel plug-ins",
              "body": "[https://youtu.be/67DmVvjAdJU](https://youtu.be/67DmVvjAdJU \"The basics of AOT compilers and how to write Babel plug-ins Similar information can be found in an article that I published on Medium: https\\://medium.com/the-guild/this-is-how-i-build-babel-plug-ins-b0a13dcd0352 links: AST explorer: https\\://astexplorer.net/ Babel docs: https\\://babeljs.io/docs/en/ Babel plug-in handbook: https\\://github.com/jamiebuilds/babel-handbook/blob/master/translations/en/plugin-handbook.md example plug-in I: https\\://github.com/DAB0mB/babel-plugin-scoped-styled-components example plug-in II: https\\://github.com/DAB0mB/babel-plugin-react-persist Social media: Follow me on GitHub: https\\://github.com/DAB0mB Twitter: https\\://twitter.com/eytan_manor Medium: https\\://medium.com/@eytanmanor\")\n\nThe idea of writing such article popped into my mind while working on my [Webflow/React transpiler](https://github.com/DAB0mB/Appfairy). All I wanted to do was to take a JS code string and transform it in such way that globals won‚Äôt be redefined if already so:\n\n\n```javascript\n/* In */\n\nfoo = 'foo'\n\n/* Out */\n\nif (typeof window.foo === 'undefined') window.foo = 'foo'\n\n```\n\nAt the beginning I thought I could do that with some help from a regular expression; but boy was I wrong.\n\nA regular expression is simply not enough because it ignores the concept of scoped variables completely and works on a string as if it was a plain text. To determine a global variable, what we need to ask ourselves is: Is this variable already declared in the current scope or one of its parent scopes?\n\nThe way to go with such question would be breaking down the code into nodes, where each node represents a part in our code and all the nodes are connected with each other in a relational manner. This whole node formation is called AST ‚Äî abstract syntax tree, which can be used to easily lookup scopes and variables and other elements which are related to our code.\n\nAn example AST may look like so:\n\n```javascript\nfunction foo(x) {\n    if (x > 10) {\n        var a = 2;\n        return a * x;\n    }\n\n    return x + 10;\n}\n```\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*WmUiQJ4b0f2XaEzdKH6uLg.png?raw=true)\n\n> _Example taken from [Lachezar Nickolov‚Äôs article](https://blog.sessionstack.com/how-javascript-works-parsing-abstract-syntax-trees-asts-5-tips-on-how-to-minimize-parse-time-abfcf7e8a0c8) about JS ASTs._\n>\n\nObviously, breaking down our code into nodes is not a walk in the park. Luckily, we have a tool called Babel which already does that.\n\n# Babel to the rescue\n\nBabel is a project which originally started to transform the latest es20XX syntax into es5 syntax for better browser compatibility. As the Ecmascript committee keeps updating the standards of the Ecmascript language, plug-ins provide an excellent and maintainable solution to easily update the Babel compiler‚Äôs behavior.\n\nBabel is made out of numerous components which work together to bring the latest Ecmascript syntax to life. Specifically the code transformation flow works with the following components and following relations:\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*cW9IvHMO5fBRNbjw2NW44Q.png?raw=true)\n\n-   The parser parses the code string into a data representational structure called AST (abstract syntax tree) using [`@babel/parser`](http://github.com/babel/babel/tree/master/packages/babel-parser).\n\n-   The AST is being manipulated by pre-defined plug-ins which use[`@babel/traverse`](http://github.com/babel/babel/tree/master/packages/babel-traverse).\n\n-   The AST is being transformed back into code using [`@babel/generator`](http://github.com/babel/babel/tree/master/packages/babel-generator).\n\n\nNow you have a better understanding of Babel and you can actually understand what‚Äôs happening when you build a plug-in; and speaking of which, how do we do that?\n\n# Building and using a Babel plug-in\n\nFirst of all I would like us to understand Babel‚Äôs generated AST as this is essential for building the plug-in, because the plug-in‚Äôs gonna manipulate the AST and therefore we need to understand it. If you‚Äôll go to [astexplorer.net](https://dillinger.io/astexplorer.net) you‚Äôll find an amazing compiler that will transform code into AST. Let‚Äôs take the code `foo = \"foo\"` as an example. The generated AST should look like so:\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*OePZ4BDz56c9WZHeW8FnUQ.png?raw=true)\n\nAs you can see, each node in the tree represents a part of the code, and it‚Äôs recursive. The assignment expression `foo = \"foo\"` uses the operator `=`, the operand on the left is an identifier named `foo` and the operand on the right is a literal with the value `\"foo\"`. So that‚Äôs how it goes, each part of the code can be presented as a node which is made out of other nodes, each node has a type and additional properties based on its type.\n\n\nNow let‚Äôs say that we would like to change the value `\"foo\"` to `\"bar\"`, hypothetically speaking what we will have to do would be grab the corresponding literal node and change its value from `\"foo\"`, to `\"bar\"`. Let‚Äôs take this simple example and turn it into a plug-in.\n\n\nI‚Äôve prepared a quick template project that you can use to quickly write plug-ins and test them by transforming them. The project can be downloaded by cloning [this repository](https://github.com/DAB0mB/babel-plugin-tester). The project contains the following files:\n\n\n-   `in.js` - includes the input code that we would like to transform.\n\n-   `out.js` - includes the output of the code we‚Äôve just transformed.\n\n-   `transform.js` - takes the code in `in.js`, transforms it, and writes the new code to `out.js`.\n\n-   `plugin.js` - the transformation plug-in that will be applied throughout transformation.\n\n\nTo implement our plug-in, copy the following content and paste it in the `in.js` file:\n\n\n```\nfoo = \"foo\"\n```\n\nand the following content to the `transform.js` file:\n\n\n```javascript\nmodule.exports = () => {\n  return {\n    visitor: {\n      AssignmentExpression(path) {\n        if (\n          path.node.left.type === 'Identifier' &&\n          path.node.left.name === 'foo' &&\n          path.node.right.type === 'Literal' &&\n          path.node.right.value === 'foo'\n        ) {\n          path.node.right.value = 'bar'\n        }\n      }\n    }\n  }\n}\n```\n\nTo initiate the transformation, simply run `$ node transform.js`. Now open the `out.js` file and you should see the following content:\n\n\n```\nfoo = \"bar\"\n```\n\nThe `visitor` property is where the actual manipulation of the AST should be done. It walks through the tree and runs the handlers for each specified node type. In our case, whenever the visitor has encountered a node of type `AssignmentExpression` node, it will replace the right operand with `\"bar\"` in case we assign the the `\"foo\"` value to `foo`. We can add a manipulation handler for any node type that we want, it can be `AssignmentExpression`, `Identifier`, `Literal`, or even `Program`, which is the root node of the AST.\n\n\nSo going back to the main purpose of for which we gathered, I‚Äôll first provide you with a reminder:\n\n```javascript\n/* In */\n\nfoo = 'foo'\n\n/* Out */\n\nif (typeof window.foo === 'undefined') window.foo = 'foo'\n\n```\n\nWe will first take all global assignments and turn it into member assignment expressions of `window` to prevent confusions and potential misunderstandings. I like to start by first exploring the desired AST output:\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*7c1LFZ4-dRPaqMTVBR-DHg.png?raw=true)\n\nAnd then writing the plug-in itself accordingly:\n\n```javascript\nmodule.exports = ({ types: t }) => {\n  return {\n    visitor: {\n      AssignmentExpression(path) {\n        if (\n          path.node.left.type === 'Identifier' &&\n          !path.scope.hasBinding(path.node.left.name)\n        ) {\n          path.node.left = t.memberExpression(t.identifier('window'), t.identifier(path.node.left.name))\n        }\n      }\n    }\n  }\n}\n```\n\nI will now introduce you to 2 new concepts that I haven‚Äôt mention before but are being used in the plug-in above:\n\n-   The `types` object is a Lodash-esque utility library for AST nodes. It contains methods for building, validating, and converting AST nodes. It‚Äôs useful for cleaning up AST logic with well thought out utility methods. Its methods should all start be equivalent to camel cased node types. All types are defined in [`@babel/types`](http://github.com/babel/babel/tree/master/packages/babel-types), and further more, I recommend you to look at the source code as you build the plug-in in order to define the desired node creators‚Äô signatures, since most of it is not documented. More information regards `types` can be found [here](http://github.com/jamiebuilds/babel-handbook/blob/master/translations/en/plugin-handbook.md#babel-types).\n\n-   Just like the `types` object, the `scope` object contains utilities which are related to the current node‚Äôs scope. It can check whether a variable is defined or not, generate unique variable IDs, or rename variables. In the plug-in above, we used the `hasBinding()` method to check whether the identifier has a corresponding declared variable or not by climbing up the AST. More information regards `scope` can be found [here](http://github.com/jamiebuilds/babel-handbook/blob/master/translations/en/plugin-handbook.md#scope).\n\n\nNow we will add the missing peace to the puzzle which is transforming assignment expressions into conditional assignment expressions. So we wanna turn this code:\n\n```\nwindow.foo = 'foo'\n```\n\nInto this code:\n\n```\nif (typeof window.foo === 'undefined') window.foo = 'foo'\n```\n\nIf you‚Äôll investigate that code‚Äôs AST you‚Äôll see that we‚Äôre dealing with 3 new node types:\n\n-   UnaryExpression ‚Äî `typeof window.foo`\n\n-   BinaryExpression ‚Äî `... === 'undefined'`\n\n-   IfStatement ‚Äî `if (...)`\n\n\nNotice how each node is composed out of the one above it. Accordingly, we will update our plug-in. We will keep the old logic, where we turn global variables into members of `window`, and on top of that, we will make it conditional with the `IfStatement`:\n\n\n```javascript\nmodule.exports = ({ types: t }) => {\n  return {\n    visitor: {\n      AssignmentExpression(path) {\n        if (\n          path.node.left.type === 'Identifier' &&\n          !path.scope.hasBinding(path.node.left.name)\n        ) {\n          path.node.left = t.memberExpression(t.identifier('window'), t.identifier(path.node.left.name))\n        }\n        if (\n          path.node.left.type == 'MemberExpression' &&\n          path.node.left.object.name == 'window'\n        ) {\n          const typeofNode = t.unaryExpression('typeof', path.node.left)\n          const isNodeUndefined = t.binaryExpression('===', typeofNode, t.stringLiteral('undefined'))\n          const ifNodeUndefined = t.ifStatement(isNodeUndefined, t.expressionStatement(path.node))\n\n          path.replaceWith(ifNodeUndefined)\n          path.skip()\n        }\n      }\n    }\n  }\n}\n```\n\nSo basically what we do here is checking whether we deal with a `window` member assignment expression, and if so we will create the conditional statement and replace it with the current node. Few notes:\n\n\n-   Without getting fancy with the explenation, I‚Äôve created a nested `ExpressionStatement` inside the `IfStatement` simply because this is what is expected of me, according to the AST.\n\n-   I‚Äôve used the `replaceWith` method to replace the current node with the newly created one. More about manipulation methods like `replaceWith` be found [here](https://dillinger.io/github.com/jamiebuilds/babel-handbook/blob/master/translations/en/plugin-handbook.md#manipulation).\n\n-   Normally the `AssignmentExpression` handler should be called again, because technically I‚Äôve created a new node of that type when we called the `replaceWith` method, but since I don‚Äôt wanna run another traversal for newly created nodes, I‚Äôve called the `skip` method, otherwise I would have had an infinite recursion. More about visiting methods like `skip` can be found [here](https://github.com/jamiebuilds/babel-handbook/blob/master/translations/en/plugin-handbook.md#manipulation).\n\n\nSo there you go, by now the plug-in should be complete. It‚Äôs not the most complex plug-in out there but it‚Äôs definitely a good example for this intro that will give you a good basis for further plug-ins that you‚Äôll build down the road.\n\nAs a recap, whenever you forget for any reason how a plug-in works, go through this article. As you work on the plug-in itself, investigate through the desired AST outcome at [astexplorer.net](http://astexplorer.net) and for API docs I recommend you to work with this wonderful [handbook](http://github.com/jamiebuilds/babel-handbook/blob/master/translations/en/plugin-handbook.md).\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"b0a13dcd0352\",\"publishedDate\":1538994729668,\"url\":\"https://medium.com/the-guild/this-is-how-i-build-babel-plug-ins-b0a13dcd0352\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMTowMzoyMiswMTowMM4izrJc",
            "node": {
              "title": "Getting to know Node‚Äôs child_process module",
              "body": "## How to call git, cpp, sh, etc, from a Node.JS script\n\nNode.JS is one of the most powerful platforms for managing resources in our computer and has became more and more popular over the years ever since it was released. As much as it‚Äôs great, and with all the love and respect that I have for it, Node.JS alone is not enough.\n\nDespite NPM‚Äôs evolved ecosystem there are more tools out there which exist outside of it for a longer time, thus they do what they do better than any Node.JS package; such as opencv ‚Äî an open source computer vision utility library which was developed for C++, Python, and Java (not for Node.JS).\n\nIn addition, Node.JS exists for a very general purpose while some tools exist solely for a single purpose; such as git ‚Äî which exists for the purpose of version controlling.\n\nAccordingly, I‚Äôve decided to write an article about Node‚Äôs child_process module ‚Äî a utility module which provides you with functions that can create and manage other processes.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*kPek5-1mNCLi91X0BAA8VQ.png?raw=true)\n\nAs you probably know, our typical OS has different processes running in the background. Each process is being managed by a single-core of our CPU and will run a series of calculations each time it is being ticked. As such, we can‚Äôt take full advantage of our CPU using a single process, we would need a number of processes that is at least equal to the number of cores in our CPU. In addition, each process might be responsible for running a series of calculations of different logic, which will give the end user a better control over the CPU‚Äôs behavior.\n\nAccordingly, if until this very day you‚Äôve been writing Node scripts which don‚Äôt involve any reference to processes at all, you might have been doing it wrong, because you‚Äôve been limiting yourself to a single core, let alone to a single process. Node‚Äôs `child_process` module exists to solve exactly that; it will provide you with utility functions that will provide you with the ability so spawn processes from the main process you‚Äôre currently at.\n\n\nWhy is this module called `child_process` and not just `process`? First of all, not to confuse with the main process instance `global.process`, and second, the child process is derived from the main process, which means that both can communicate - the main process will hold streams for the child process‚Äôs std types and they will both share an `ipc` channel (‚ÄúInter Process Communication‚Äù channel; more on that further this article).\n\n\n# The child_process API\n\nThe `child_process` module provides us with utility functions whose logics are stacked on top of one another. The most basic function is `spawn()`:\n\n\n```javascript\nconst { spawn } = require('child_process')\n\nspawn('git', ['log'])\n```\n\n> _Docs: [spawn](https://nodejs.org/api/child_process.html#child_process_child_process_spawn_command_args_options)_\n>\n\nThe `spawn` function will spawn a new process of `git log` type. The first argument of the function represents a path for an executable file that should start the process, and the second argument is an arguments vector that will be given to the executable. The returned process object will hold a property for each std type represented as a Stream: `.stdin` - WriteStream, `.stout` - ReadStream and finally `.stderr` - ReadStream. Accordingly, if we would like to run `git log` through a Node process and print it to the console we would do something like the following:\n\n\n```javascript\nconst { spawn } = require('child_process')\n\nspawn('git', ['log']).stdout.pipe(process.stdout)\n```\n\nOr if we will take advantage of the last options argument, we could do the following:\n\n```javascript\nconst { spawn } = require('child_process')\n\nspawn('git', ['log'], {\n  stdio: 'inherit' // Will use process .stdout, .stdin, .stderr\n})\n```\n\n> _Note that every `child_process` function will also have a ‚Äúsync‚Äù version of it (e.g. `spawnSync()`), but assuming that you‚Äôre already familiar with synchronous and asynchronous functions in Node, I‚Äôm gonna skip that for the sake of simplicity._\n>\n\nThe next function on the list would be the `execFile()`. As implied, it will execute a given file path, just like `spawn()`does. The difference between the 2 though, is that unlike `spawn()` which returns a bunch of streams, `execFile()` will parse the streams and will return the result directly as a string:\n\n\n```javascript\nconst { execFile } = require('child_process')\n\nexecFile('git', ['log'], (err, out) => {\n  if (err) {\n    console.error(err)\n  }\n  else {\n    console.log(out)\n  }\n})\n```\n\n> _Docs: [execFile](https://nodejs.org/api/child_process.html#child_process_child_process_execfile_file_args_options_callback)_\n>\n\nHere‚Äôs a snapshot of Node‚Äôs source code that proves that `execFile()` is directly dependent on `spawn()`:\n\n\n```javascript\nexports.execFile = function execFile(file /* , args, options, callback */) {\n  // ...\n  var child = spawn(file, args, {\n    cwd: options.cwd,\n    env: options.env,\n    gid: options.gid,\n    uid: options.uid,\n    shell: options.shell,\n    windowsHide: options.windowsHide !== false,\n    windowsVerbatimArguments: !!options.windowsVerbatimArguments\n  });\n  // ...\n}\n```\n\n> _Source: [lib/child_process.js](https://github.com/nodejs/node/tree/master/lib/child_process.js#L170)_\n>\n\nAs `bash` is vastly used as the command line shell, Node provided us with a function that will span an instance of `bash` and execute the given command line. This function is called `exec()` and it returns the stdout as a string, just like `execFile()`does:\n\n\n```javascript\nconst { exec } = require('child_process')\n\n// Will print all commit messages which include foo\nexec('git log --format=\"%s\" | grep foo', (err, out) => {\n  if (err) {\n    console.error(err)\n  }\n  else {\n    console.log(out)\n  }\n})\n```\n\n> _Docs: [exec](https://nodejs.org/api/child_process.html#child_process_child_process_exec_command_options_callback)_\n>\n\nHere‚Äôs a snapshot of Node‚Äôs source code that proves that `exec()` is directly dependent on `execFile()`, which makes it indirectly dependent on `spawn()`\n\n\n```javascript\nexports.exec = function exec(/* command , options, callback */) {\n  const opts = normalizeExecArgs.apply(null, arguments);\n  return exports.execFile(opts.file,\n                          opts.options,\n                          opts.callback);\n};\n```\n\n> _Source: [lib/child_process.js](https://github.com/nodejs/node/blob/v8.12.0/lib/child_process.js#L141)_\n>\n\nIn other words, the core of `exec()` can be implemented like so:\n\n\n```javascript\nconst { execFile } = require('child_process')\n\nexports.exec = (command, options, callback) => {\n  return execFile(`bash`, ['-c', command], options, callback)\n}\n```\n\nOften times, we would just spawn another Node process which would execute another script file, thus, Node has provided us with a function that is bound to Node‚Äôs executable file path, called `fork():`\n\n\n```javascript\nconst { fork } = require('child_process')\n\nfork('./script/path.js')\n```\n\n> _Docs: [fork](https://nodejs.org/api/child_process.html#child_process_child_process_fork_modulepath_args_options)_\n>\n\nWhat‚Äôs nice about this method is that it will open a communication channel between the main process and the child process (known as `ipc` - Inter Process Communication), so we can be notified regards the child process‚Äôs status and act accordingly:\n\n\n```javascript\n/* Parent process script */\nconst { fork } = require('child_process');\nconst n = fork(`${__dirname}/child.js`);\n\nn.on('message', (m) => {\n  console.log('PARENT got message:', m);\n});\n\n// Causes the child to print: CHILD got message: { hello: 'world' }\nn.send({ hello: 'world' });\n\n\n/* Child process script - child.js */\n\nprocess.on('message', (m) => {\n  console.log('CHILD got message:', m);\n});\n\n// Causes the parent to print: PARENT got message: { foo: 'bar', baz: null }\nprocess.send({ foo: 'bar', baz: NaN });\n```\n\n> _Source: [lib/child_process.js](https://github.com/nodejs/node/tree/master/lib/child_process.js#L57)_\n>\n\nNow back to what I‚Äôve said at the beginning of this article. Each process uses a single core of our CPU, hence, in-order for our Node script to take full advantage of our CPU we would need to run multiple instances of Node, each one would have its own process. But how do we manage the work distributed between the core?! Luckily, the OS does that for us, so by calling the `fork()` method we actually distribute the work on different cores.\n\n\nFollowing this principle, a common use-case would be distributing the work of the script that we‚Äôre currently at. So rather than calling the `fork()` method with the current script file path, we can just use the `cluster` module, which is directly related to `child_process` because of the reason I‚Äôve just mentioned, and call the `cluster.fork()` method:\n\n\n```javascript\nconst cluster = require('cluster');\n\nif (cluster.isMaster) {\n  const n = cluster.fork(`${__dirname}/child.js`);\n  n.on('message', (m) => {\n    console.log('PARENT got message:', m);\n  });\n  // Causes the child to print: CHILD got message: { hello: 'world' }\n  n.send({ hello: 'world' });\n}\n\nif (cluster.isWorker) {\n  process.on('message', (m) => {\n    console.log('CHILD got message:', m);\n  });\n  // Causes the parent to print: PARENT got message: { foo: 'bar', baz: null }\n  process.send({ foo: 'bar', baz: NaN });\n}\n```\n\n> _Docs: [cluster](https://nodejs.org/api/cluster.html)_\n>\n\nAs you can probably notice, the `cluster` API has some extra logic in addition to a regular `process`, but at its core it‚Äôs just another process which was created by `child_process`. To prove that, let‚Äôs take a look at a snapshot taken from Node‚Äôs source code:\n\n\n```javascript\nfunction createWorkerProcess(id, env) {\n  // ...\n  return fork(cluster.settings.exec, cluster.settings.args, {\n    cwd: cluster.settings.cwd,\n    env: workerEnv,\n    silent: cluster.settings.silent,\n    windowsHide: cluster.settings.windowsHide,\n    execArgv: execArgv,\n    stdio: cluster.settings.stdio,\n    gid: cluster.settings.gid,\n    uid: cluster.settings.uid\n  });\n}\n```\n\n> _Source: [lib/internal/cluster/master.js](https://github.com/nodejs/node/blob/v8.12.0/lib/internal/cluster/master.js#L101)_\n>\n\nAs you can see, the cluster is directly dependent on the `fork()` method, and if we‚Äôll take a look at the `fork()` method implementation we‚Äôll see that it directly depends on the `spawn()` method:\n\n\n```javascript\nexports.fork = function fork(modulePath /* , args, options */) {\n  // ...\n  return spawn(options.execPath, args, options);\n};\n```\n\n> _Source: [lib/child_process.js](https://github.com/nodejs/node/blob/v8.12.0/lib/child_process.js#L104)_\n>\n\nSo eventually, it all comes down to the `spawn()` method; everything that node provides us with which is related to processes is just a wrap around it.\n\n\nThere‚Äôs definitely more digging to do when it comes to the world of processes, in relation to Node‚Äôs internals and outside of it in relation to the OS. But after reading this you can make a practical use of one of Node‚Äôs greatest features and unleash its full potential. Keep on reading the docs and investigating because it can definitely elevate your backed skills, and if you have any further questions or topics that you would like me to write about (in the JavaScript world) do tell.\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"8ed63038f3fa\",\"publishedDate\":1538044855318,\"url\":\"https://medium.com/the-guild/getting-to-know-nodes-child-process-module-8ed63038f3fa\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMTowMzowOCswMTowMM4izrHu",
            "node": {
              "title": "How to create a React app out of a Webflow project",
              "body": "_tl;dr: It can be transpiled with a single command._\n\n\nAs a freelancer I get to work with designers many times. Not once and not twice I have stumbled upon [Webflow](https://webflow.com/) ‚Äî a web design studio, where the designer can assmble all his assets into responsive demonstrable webpages. These webpages look neat and responsive and can be downloaded as HTML/CSS files along with their scripts, images and fonts.\n\n\nAt a glance, this can ease the process of getting an app done; after all we‚Äôre provided with a working website, so surely binding some logic to it with React shouldn‚Äôt be too complicated, right? All we need to do is take the HTML, put under a `render()`method of of a `React.Component`, and `import` its corresponding style with an external CSS file. Well, this is nothing but a walk in the park.\n\n\nWhen Webflow was first presented to me by a client of mine, I assumed the above. He showed me his website, which looked quiet complete, and we‚Äôve proceeded to composing a plan sheet, with all the desired behavioral features of the future application and a matching price for each of that feature. I was quiet happy with our deal.\n\nOn the next morning, I‚Äôve received an email by my client‚Äôs designer with all the exported assets by Webflow. When I looked around expecting to find the optimal starting point to go with it, my world collapsed.\n\nThe HTML files were big and massive, with lots of duplicated parts in it, the CSS was just a one big global style sheet with all the rules (that were very generic), and the images just had random machine generated names. When I started to tear it apart into React components, I‚Äôve called my client after few hours of trial and canceled the plan; since the budget was limited and I wasn‚Äôt willing to spend so much time on a project with a very little value in return.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*U_GfqaDPrEX8cD7x.jpg?raw=true)\n\n> _Above: A Webflow page whose HTML file can be found [here](https://gist.github.com/DAB0mB/1979ac9cfa5fbe52e6375d80841200ae). Credit: [campaignkit.co](https://www.campaignkit.co/)._\n>\n>\n> ### ‚ÄúWhat shall I do then?!‚Äù ‚Äî A React developer\n\n---\n\n# Introducing Appfairy\n\nAppfairy is a CLI tool which can be easily installed using NPM and can integrate Webflow into a React application with a single command.\n\nTo get started, first install `appfairy` globally:\n\n\n```\n$ sudo npm install appfairy -g\n```\n\nNow let‚Äôs think of what React components should exist in our application besides the main pages. Once we identify them we should select their corresponding element in the Webflow project and set a new attribute; the key‚Äôs gonna be `af-el` (Appfairy element) and the value should be set to the name of the component e.g. `consult-form`:\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*mSriYEAcT8cB1gAQ.jpg?raw=true)\n\n> _Above: Selecting the element and setting its attribute_\n>\n\nAt this point we‚Äôre one step away from generating a functional `ConsultForm` React component; But before proceeding to the next step I would like to explain an important principle regards Appfairy‚Äôs generated code‚Äôs design pattern.\n\n\nSince Webflow‚Äôs code is machine generated and for the most part is not optimal, we might encounter potential maintenance issues for 2 main reasons:\n\n-   The target element we would like to update / attach event listeners to is hard to identify due to complexity of the HTML tree.\n-   When updating the design, we should also update our code by re-identifying the target elements and reattaching the React logic into them, e.g. mapping functions and event handlers like `onClick()`.\n\n\nTo solve that problem, Appfairy takes on an old school approach where we separate the component into a view and a controller, where we treat the view as a black-box and don‚Äôt touch it while the controller is controlling what‚Äôs going on in there; it would tell the view what to render, when to render, and how to render.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*ME0a5Q8gazTmqYcP.jpg?raw=true)\n\nIn the picture above we have a schematic description which shows the view/controller flow. In a brief, the controller holds elements which are proxies to the real elements, so whatever we pass to the proxy will be forwarded automatically to the real element. A proxy and an element can be matched based on the socket name (`af-sock`), which opens an interfacing point to the view by any given controller.\n\n\nSo back to our ConsultantForm in our Webflow project example, let‚Äôs think which elements should be bound to a certain logic. Generally speaking, a form has several input fields and a submit button, which will submit the data received by the inputs, therefore we would probably apply logic to these elements in our React controller components. Accordingly, we will define socket attributes to each of the elements with distinct names:\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*QpTeFHeu0_b7eYNI.jpg?raw=true)\n\nOur Webflow project is now ready for migration! To do so, we will first need to create a directory named `.appfairy` in the root of our project:\n\n\n```\n$ mkdir .appfairy\n```\n\nThis directory is used by Appfairy as an input for the CLI function, which means that we will need to export our project and extract the generated zip file‚Äôs content into the directory we‚Äôve just created:\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*3tAtYXQ2a9Gjmwru.jpg?raw=true)\n\n```\n$ unzip ~/Downloads/project.webflow.zip -d .appfairy\n```\n\n> _Above: Exporting the project and unzipping it to `.appfairy` dir_\n>\n\nAll is left to do now is to run `appfairy` and our Webflow React components will be created and ready to use!\n\n\n```\n$ appfairy\n```\n\nAs a result a message will be printed to the terminal signifying that a new git commit has been created with modifications which consist of the following:\n\n```\nüóÅ public (public assets which should be served by our app's server)\n   üóÄ images\n   üóÄ fonts\n   üóÄ css\nüóÅ src\n   üóÄ scripts (scripts that should be imported in index.js)\n   üóÄ styles (css files that should be imported in index.js)\n   üóÄ views (contains ConsultFormView - further explanation below)\n```\n\nThe reason for the modifications to be laid out this way is because `create-react-app` (which is the most common app starter for React) uses this folders structure. The output can be mapped differently using a config file - more details about that can be found in the official [README.md](http://readme.md/) file over [here](https://github.com/DAB0mB/Appfairy).\n\n\nNon of these files should be edited or removed and should only be managed by the `appfairy` command, so whenever we update the Webflow project we should simply repeat the recent process and the files should updated accordingly.\n\n\nIf you‚Äôll take a look at the `views` folder you‚Äôll see that it contains a file named `ConsultFormView.js`. As I already mentioned, Appfairy‚Äôs design pattern consists of a view and a controller, therefore the exported ConsultFormView component needs to be bound to a controller.\n\n\nTo define a controller simply create a new file named `ConsultFormController.js` under the `controllers` folder where the corresponding controller‚Äôs gonna be exported as a React component. The controller should contain proxies to the original elements and each proxy should forward the necessary props. Rather than giving further explanation I would like to give you an example of a possible implementation of a ConsultFormController:\n\n\n```javascript\nimport React from 'react'\nimport ConsultFormView from '../views/ConsultFormView'\n\nclass ConsultFormController extends React.Component {\n  state = {}\n\n  render() {\n    return (\n      <ConsultFormView>\n        <name onChange={this.setName} />\n        <phone onChange={this.setPhone} />\n        <email onChange={this.setEmail} />\n        <description onChange={this.setDescription} />\n        <submit onClick={this.submit} />\n      </ConsultFormView>\n    )\n  }\n\n  setName = (e) => {\n    this.setState({\n      name: e.target.value\n    })\n  }\n  setPhone = (e) => {\n    this.setState({\n      phone: e.target.value\n    })\n  }\n\n  setEmail = (e) => {\n    this.setState({\n      email: e.target.value\n    })\n  }\n\n  setDescription = (e) => {\n    this.setState({\n      description: e.target.value\n    })\n  }\n\n  submit = () => {\n    alert(`\n      ${this.name}\n      ${this.phone}\n      ${this.email}\n      ${this.description}\n    `)\n  }\n}\n\nexport default ConsultFormController\n```\n\nThat‚Äôs it! Now you can just import the controller and use it anywhere and anytime you want, without having to deal with the hustle of maintaining a complex machine generated Webflow code; and any time you update the design just update your code using the `appfairy` command.\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*jCE2BBPMnd7LI769.gif?raw=true)\n\n> _Above: An example usage of an Appfairy generated React component_\n>\n\nReferences:\n\n-   The full app‚Äôs source code can be [found here](https://github.com/DAB0mB/Appfairy/tree/master/examples/prefetch).\n\n-   For an in-depth tutorial check out [this video](https://youtu.be/6hJe6pZld0o).\n\n-   API docs can be found in [the official Github repo](https://github.com/DAB0mB/Appfairy).\n\n\nHave fun designing/coding üôÇ\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"309b696a0533\",\"publishedDate\":1536294312895,\"url\":\"https://medium.com/the-guild/how-to-create-a-react-app-out-of-a-webflow-project-309b696a0533\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMTowMjoyNyswMTowMM4izrCY",
            "node": {
              "title": "git rebase (not) --interactive",
              "body": "_tl;dr: How to build a Node.JS script to re-write history. pre-requisites: Familiarity with git rebase --interacitve._\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*2ArsqHco6GT-ZYSi?raw=true)\n\nOnce upon a time, there was a [Whatsapp clone tutorial](https://github.com/Urigo/whatsapp-textrepo-angularcli-express) was born. Since then it has been through different incantations, but they all shared a common principle ‚Äî the tutorial used git as a version control.\n\n\nWhat‚Äôs special about this tutorial is its commits history ‚Äî every commit represents a step in the tutorial; this way it‚Äôs very easy to navigate through it and reference a specific part of it.\n\nFor the end user it was all cakes and ale, but maintenance was hell. To put things simple, imagine you had the following git-log:\n\n```\nStep 100: description of step 100th\n.\n.\n.\nStep 3: description of third step\nStep 2: description of second step\nStep 1: description of first step\n```\n\nNow let‚Äôs say that you would like to remove step 2. The only solution for that would be using a git-rebase --interactive starting step 2 and save the following file:\n\n```\nreword xxxxxxx Step 100: description of step 100th\n.\n.\n.\nreword xxxxxxx Step 3: description of third step\n```\n\nThis means that the editor process would have to be opened and closed 98 times (100 - 3 included), each time it does so we would manually have to change step n to step (n + 1). Do you understand now why it was a maintenance hell? I‚Äôll save the explanation for myself.\n\nThe obvious question is ‚Äî what if a script could do that for me? Followed by ‚Äî how can I implement such a script?\n\nFollowing that, I have wandered across git‚Äôs documentation and Stack Overflow and have found an answer. Here‚Äôs the method which starts the editing process written in git-rebase--interactive.sh, a file in git‚Äôs implementation:\n\n```shell\ngit_sequence_editor () {\n\tif test -z \"$GIT_SEQUENCE_EDITOR\"\n\tthen\n\t\tGIT_SEQUENCE_EDITOR=\"$(git config sequence.editor)\"\n\t\tif [ -z \"$GIT_SEQUENCE_EDITOR\" ]\n\t\tthen\n\t\t\tGIT_SEQUENCE_EDITOR=\"$(git var GIT_EDITOR)\" || return $?\n\t\tfi\n\tfi\n\n\teval \"$GIT_SEQUENCE_EDITOR\" '\"$@\"'\n}\n```\n\nAs you can see (or not), git looks for the editor‚Äôs file path in a global var named `GIT_SEQUENCE_EDITOR` and executes it with all the given arguments. Without getting into more of the implementation, knowing `nano` and `vim` which are the most commonly used git-editors, the first argument that their process accepts the edited file‚Äôs path, which makes total sense.\n\n\nBUT! Why does the `GIT_SEQUENCE_EDITOR` environment variable has to reference an actual text editor? What if we set that to reference Node.JS‚Äôs executable? Aha! JACKPOT!\n\n\nNow, hypothetically instead of opening `nano` or `vim` and editing the file manually we can run whatever manipulation we want on the file using a script and then once the process exists with no errors (code 0) git will just proceed with the rebase as usual.\n\n\nUsing this principle, here‚Äôs a cool script that will remove a range of commits from the middle of the commits-stack:\n\n```javascript\n#!/usr/bin/env node\nconst execa = require('execa')\nconst fs = require('fs')\nconst tmp = require('tmp')\n\n// Main\n{\n  const [anchor, amount = 1] = process.argv.slice(-2).map(Number)\n\n  gitRebaseInteractive(anchor, function (operations, amount) {\n    operations = operations\n      // Replace comments\n      .replace(/#.*/g, '')\n      // Each line would be a cell\n      .split('\\n')\n      // Get rid of empty lines\n      .filter(Boolean)\n\n    // Commits we would like to drop\n    const dropOperations = operations\n      .slice(0, amount)\n      .map(operation => operation.replace('pick', 'drop'))\n\n    // Commits we would like to pick\n    const pickOperations = operations.slice(amount)\n\n    // Composing final rebase file\n    return []\n      .concat(dropOperations)\n      .concat(pickOperations)\n      .join('\\n')\n\n  }, [amount])\n\n  console.log(`Removed ${amount} commits starting ${anchor}`)\n}\n\n// Runs a git-rebase-interactive in a non interactive manner by providing a script\n// which will handle things automatically\nfunction gitRebaseInteractive(head, fn, args) {\n  execa.sync('git', ['rebase', '-i', head], {\n    env: {\n      GIT_SEQUENCE_EDITOR: gitEdit(fn, args)\n    }\n  })\n}\n\n// Evaluates a script in a new process which should edit a git file.\n// The input of the provided function should be the contents of the file and the output\n// should be the new contents of the file\nfunction gitEdit(fn, args) {\n  args = args.map(arg => `'${arg}'`).join(', ')\n\n  const body = fn.toString()\n    .replace(/\\\\/g, '\\\\\\\\')\n    .replace(/`/g, '\\\\`')\n\n  const scriptFile = tmp.fileSync({ unsafeCleanup: true })\n\n  fs.writeFileSync(scriptFile.name, `\n    const fs = require('fs')\n\n    const file = process.argv[process.argv.length - 1]\n    let content = fs.readFileSync(file).toString()\n    content = new Function(\\`return (${body}).apply(this, arguments)\\`)(content, ${args})\n    fs.writeFileSync(file, content)\n    fs.unlinkSync('${scriptFile.name}')\n  `)\n\n  return `node ${scriptFile.name}`\n}\n```\n\nUsing the code snippet above we can take an initial step towards solving the problem presented at the beginning of this article by simply running `$ git-remove.js` \\[where `anchor` represents a git object and `amount` represents the amount of commits that we would like to remove].\n\n\nSure, we still need to figure out which step we would like to remove by its index, and we need to take care of automatic rewording, but at least now you have the idea behind such method where you can solve problems like these as well as far more complex ones, with a little bit of creativity.\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"68c4b88c5a6f\",\"publishedDate\":1535971072737,\"url\":\"https://medium.com/@eytanmanor/git-rebase-not-interactive-68c4b88c5a6f\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMTowMjoxOCswMTowMM4izrBM",
            "node": {
              "title": "NodeJS Advanced ‚Äî How to create a native add-on using C++",
              "body": "In this tutorial we gonna go through the basics on how to write a native add-on to NodeJS using C++, one of the platform‚Äôs most powerful capabilities of which most web/JS developers now a days are not even familiar with.\n\nFor somewhat there is a vacuum which got created around C++ in the recent years, people are so scared from a low-level back-end programming, why should they even deal with memory allocation dilemmas when there are all these interpretation languages like Python, Ruby, and JavaScript who can do that for us? Well folks, once you will realize that all these single web-page application third-party libraries and frameworks are all recycled and repetitive, and you will start doing some real shit by optimizing some heavy-ass machine algorithms, you will realize that performance is critic, a title which doesn‚Äôt really suit NodeJS, with all the love and respect. So why do I even bother making this tutorial? Because people are unaware of many features in the programming world, and the beauty of algorithmics. And why am I even approaching NodeJS developers? Because they have the biggest, most-popular community of all, they have a lot to learn, but they are very open minded, and that‚Äôs the most important thing. You don‚Äôt have to be a C++ developer not at all, but if I can at least catch a small part of your attention I will be overwhelmed.\n\nWe will create a very small and simple module which calculates the distance between two dots, it can do it either synchronously or asynchronously. The algorithm for calculating the distance between a given `pointA` and `pointB` in a 2D [Cartesian coordinate system](https://en.wikipedia.org/wiki/Cartesian_coordinate_system) looks like this:\n\n\n```\n‚àö[(pointAX - pointBX)^2 + (pointAY - pointBY)^2]\n```\n\nProbably not too complicated, kicks me back to the glamorous days in high-school. If put in JavaScript it should take around 10 seconds right? Well in a native NodeJS add-on it should be a bit longer. Of-course when it comes to small logics you shouldn‚Äôt make too much effort, because it will consume more power only converting all JS objects into C++ native structures. But imagine you would like to run a [blob-detection](https://en.wikipedia.org/wiki/Blob_detection) algorithm and you would like to calculate the [center of mass](https://en.wikipedia.org/wiki/Center_of_mass) of multiple blobs, in C++ it would be much faster, especially when using [shaders](https://en.wikipedia.org/wiki/Shader). Anyways that‚Äôs not the point of this tutorial, the point is that you will be provided with the necessary tools so next time if you would like to write some heavy logic, you will know how to do it.\n\n\nWe will start with a brief introduction for Google‚Äôs [v8 engine](https://en.wikipedia.org/wiki/V8_(JavaScript_engine)) and some practical examples on how to use it, this will help us getting start, and then we will write our add-on. Let‚Äôs begin then shall we?\n\n\n---\n\n# Introduction to v8\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*AC2NN-3b7sIXmtyT.png?raw=true)\n\nThe v8 JavaScript Engine is an open source JavaScript engine developed by The [Chromium Project](https://www.chromium.org/) for the [Google Chrome web browser](https://www.google.com/chrome/). It is intended to be used both in a browser and as a standalone high-performance engine that can be integrated into independent projects like [Couchbase](http://www.couchbase.com/), [MongoDB](https://www.mongodb.com/) and [Node.js](https://nodejs.org/). There lots of benchmarks out there but I will not bore you with diagrams, we all know that that this engine has proven itself to be worthy and it is being used world-widely and probably for a good reason.\n\n\n> _‚ÄúAmbition is a dream with a v8 engine‚Äù -Elvis Presley._\n>\n\nIf you‚Äôre a JavaScript developer you must be familiar with the event-loop and the scoping system of v8, so it‚Äôs a good thing that you understand the concept, but you never got to actually look at its source code and explicitly use it. A detailed documentation for v8‚Äôs different API versions is available [here](https://v8docs.nodesource.com/). I assume that you don‚Äôt bother reading any of my references that I provide along this tutorial (As a lazy blog-reader myself), I will post here that first thing you gonna see once you enter v8‚Äôs documentation web-site:\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*8N8p0fg0MCipBfyW.jpg?raw=true)\n\nThroughout history v8 have changed a lot and it wore many forms. As a result, add-ons are not usable across different versions of the platform since each one supports a different API, which will break our process during run-time. In NodeJS team they came up with a very convenient solution called [Nan](https://github.com/nodejs/nan). Nan stands for ‚ÄúNative Abstractions for NodeJS‚Äù and is basically a header file filled with macro and utility goodness for making add-on development for NodeJS easier across all versions of v8, without inspecting `NODE_MODULE_VERSION` macro all the time. In this tutorial I'm gonna refer both of them as if they are bundled in a single framework.\n\n\nEventually JavaScript is just a rehash of v8, everything you know so far is still valid but it uses a different idiom. To prevent some misconceptions, here are some important points regards JavaScript‚Äôs equivalents which I think you should follow:\n\n## Scopes and Variables\n\nIn v8 a scope is referred as `Isolate` (`v8::Isolate`) and a variable is referred as `Local` (`v8::Local`). A local is a pointer to an object. All v8 objects are accessed using locals, they are necessary because of the way the v8 garbage collector works. An isolate can be thought of as a container for any number of locals. When you've finished with your locals, instead of deleting each one individually you can simply delete their scope.\n\n\n**JavaScript**\n\n\n```\nlet obj = {\n  foo: 'foo',\n  bar: 'bar',\n  baz: 'baz'\n};\n```\n\n```\nconsole.log(obj.foo);\nconsole.log(obj.bar);\nconsole.log(obj.baz);\n```\n\n**C++**\n\n\n```\nusing Nan::New;\nusing std::cendl;\nusing std::cout;\nusing v8::Local;\nusing v8::Object;\nusing v8::String;\n```\n\n```\nLocal<Object> obj = New<Object>();\n```\n\n```\nobj->Set(New<String>(\"foo\").ToLocalChecked(), New<String>(\"foo\").ToLocalChecked());\nobj->Set(New<String>(\"bar\").ToLocalChecked(), New<String>(\"bar\").ToLocalChecked());\nobj->Set(New<String>(\"baz\").ToLocalChecked(), New<String>(\"baz\").ToLocalChecked());\n```\n\n```\ncout << obj->Get(New<String>(\"foo\").ToLocalChecked()) << cendl;\ncout << obj->Get(New<String>(\"bar\").ToLocalChecked()) << cendl;\ncout << obj->Get(New<String>(\"baz\").ToLocalChecked()) << cendl;\n```\n\n## Asynchronous Callbacks\n\nAsynchronous logic can be implemented using the `AsyncWorker` (`Nan::AsyncWorker`) and invoked by `AsyncQueueWorker` (`Nan::AsyncQueueWorker`). Thanks to these two you can have much of the annoying asynchronous queuing and handling taken care of for you. It can even store arbitrary V8 objects for you and have them persist while the asynchronous work is in progress.\n\n\n**JavaScript**\n\n\n```\nsetImmediate(() => {\n  callback(null, 'result');\n});\n```\n\n**C++**\n\n\n```\nusing Nan::AsyncQueueWorker;\nusing Nan::AsyncWorker;\nusing Nan::HandleScope;\nusing Nan::New;\nusing Nan::Null;\nusing std::string;\nusing v8::Local;\nusing v8::String;\n```\n\n```\nclass ResultWorker : AsyncWorker {\n private:\n  string* result\n```\n\n```\n public:\n  ResultWorker(Callback* callback) : AsyncWorker(callback) {}\n```\n\n```\n  ~ResultDistance() {\n    delete result;\n  }\n```\n\n```\n  // Executed inside the worker-thread.\n  // It is not safe to access V8, or V8 data structures\n  // here, so everything we need for input and output\n  // should go on 'this'.\n  void Execute () {\n    result = new string(\"result\");\n  }\n```\n\n```\n  // Executed when the async work is complete.\n  // This function will be run inside the main event loop\n  // so it is safe to use V8 again.\n  void HandleOKCallback () {\n    HandleScope scope;\n```\n\n```\n    Local<Value> argv[] = {\n      Null(),\n      New<String>(result).ToLocalChecked()\n    };\n```\n\n```\n    callback->Call(2, argv);\n  }\n};\n```\n\n```\nAsyncQueueWorker(new ResultWorker(callback));\n```\n\n## Modules Registration and Methods Definition\n\nv8 and Nan provide us with some handy macros (`NODE_MODULE`, `NAN_MODULE_INIT`, `NAN_METHOD` and `NODE_SET_METHOD`) which will help us register a new NodeJS module and define its methods. This might be confusing for some, since we can't see the function's signature it would appear as if variables are just being magically created in the stack, but once the macros are being pre-processed they will just turn into ordinary functions. In the example below I commented the original signature so you can have more clew on what's going on.\n\n\n**JavaScript**\n\n\n```\nexports.fn = (a, b) => a + b;\n```\n\n**C++**\n\n\n```\nusing Nan::To;\nusing v8::Local;\nusing v8::Object;\n```\n\n```\n// void Fn(FunctionCallbackInfo<Value>& info)\nNAN_METHOD(Fn) {\n  double a = To<double>(info[0]).FromJust();\n  double b = To<double>(info[1]).FromJust();\n```\n\n```\n  info.GetReturnValue().Set(a + b);\n}\n```\n\n```\n// void Init(Local<Object> target)\nNAN_MODULE_INIT(Init) {\n  NODE_SET_METHOD(target, Fn);\n}\n```\n\n```\n// First argument would be the entry file's name\nNODE_MODULE(addon, Init);\n```\n\nAs you can see when dealing with v8 explicitly is a time consuming process which requires you to do lots of extra-work. With that said, keep in mind that only a small portion of your code is gonna interact with the engine since the core logic should be written using native C++ and other third-party libraries. You always need to find the right balance. Always make sure that your add-on doesn‚Äôt require too much data to be passed otherwise the conversion process is gonna be hard and inefficient, and think twice before you choose this approach for the sake of simplicity. Overall the estimated optimization should be around 150% and up, depends on the task, first check your JavaScript code snippet, check for unnecessary logic and optimize it, and if you‚Äôre really sure that it is fully optimized and you‚Äôre still striving for more performance, _only then_ move to C++.\n\n\nSo far I went through the very basics which will help you create this bridge between the two platforms. The v8 lacks of detailed documentation, tutorials and examples. [Nan](https://github.com/nodejs/nan) however is a bit more documented IMHO, so when I approach the API documentation I would start from there, and if I didn‚Äôt find anything useful I would look at v8‚Äôs [latest API docs](https://v8docs.nodesource.com/). It‚Äôs not a hard material to learn but it‚Äôs different so it might be a bit challenging for some, but remember, practice practice practice.\n\n\nSpeaking of practice, let‚Äôs move on to the next step where we gonna implement our first add-on for distance calculation between two points.\n\n---\n\n# Creating the add-on\n\nIn this step we will base our development process on the TDD methodology, so you will have a chance to look at the final target API that we desire. We will start by writing a test file:\n\n## [Add test file](https://github.com/DAB0mB/node-distance-addon/commit/823f652)\n\n\n**Added .npmignore**\n\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n+‚îä ‚îä1‚îätest.jsüö´‚Üµ\n```\n\n**Added test.js**\n\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n+‚îä  ‚îä 1‚îäconst Distance = require('.');\n+‚îä  ‚îä 2‚îä\n+‚îä  ‚îä 3‚îälet result;\n+‚îä  ‚îä 4‚îälet pointA = { x: 0, y: 0 };\n+‚îä  ‚îä 5‚îälet pointB = { x: 3, y: 4 };\n+‚îä  ‚îä 6‚îä\n+‚îä  ‚îä 7‚îäresult = Distance.calculate.sync(pointA, pointB);\n+‚îä  ‚îä 8‚îä\n+‚îä  ‚îä 9‚îäif (result !== 5) throw Error(\n+‚îä  ‚îä10‚îä  '#Sync: Result expected to equal 5 but instead got ' + result\n+‚îä  ‚îä11‚îä);\n+‚îä  ‚îä12‚îä\n+‚îä  ‚îä13‚îäconsole.log('sync calculation passed');\n+‚îä  ‚îä14‚îä\n+‚îä  ‚îä15‚îäresult = Distance.calculate.async(pointA, pointB, (err, result) => {\n+‚îä  ‚îä16‚îä  if (err) throw err;\n+‚îä  ‚îä17‚îä\n+‚îä  ‚îä18‚îä  if (result !== 5) throw Error(\n+‚îä  ‚îä19‚îä    '#Async: Result expected to equal 5 but instead got ' + result\n+‚îä  ‚îä20‚îä  );\n+‚îä  ‚îä21‚îä\n+‚îä  ‚îä22‚îä  console.log('async calculation passed');\n+‚îä  ‚îä23‚îä});üö´‚Üµ\n```\n\nAnd the following NPM script should execute it:\n\n## [Add npm test script](https://github.com/DAB0mB/node-distance-addon/commit/35b20fd)\n\n\n**Changed package.json**\n\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n ‚îä 6‚îä 6‚îä  \"repository\": {\n ‚îä 7‚îä 7‚îä    \"type\": \"git\",\n ‚îä 8‚îä 8‚îä    \"url\": \"https://github.com/DAB0mB/node-distance-addon.git\"\n+‚îä  ‚îä 9‚îä  },\n+‚îä  ‚îä10‚îä  \"scripts\": {\n+‚îä  ‚îä11‚îä    \"test\": \"node test\"\n ‚îä 9‚îä12‚îä  }\n ‚îä10‚îä13‚îä}\n```\n\nLike I said in the introduction, it‚Äôs a simple module which can calculate the distance between 2 given points. `calculate.sync` can do it synchronously and `calculate.async` can do it asynchronously. Now that you got the idea we will start configuring our add-on.\n\n\nThe first thing you‚Äôll need to do is to make sure that you have `node-gyp` installed:\n\n\n```\n$ sudo npm install -g node-gyp\n```\n\n`node-gyp` is also dependent on many other packages, so before you go any further please take a look at the official installation instructions in their [README.md file](https://github.com/nodejs/node-gyp).\n\n\nAssuming that you have installed everything properly, we will now need to create a `binding.gyp` file:\n\n\n## [Create ‚Äòbinding.gyp‚Äô file](https://github.com/DAB0mB/node-distance-addon/commit/ff44399)\n\n\n**Added binding.gyp**\n\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n+‚îä  ‚îä 1‚îä{\n+‚îä  ‚îä 2‚îä  \"targets\": [\n+‚îä  ‚îä 3‚îä    {\n+‚îä  ‚îä 4‚îä      \"target_name\": \"distance\",\n+‚îä  ‚îä 5‚îä      \"sources\": [\n+‚îä  ‚îä 6‚îä        \"src/distance.cc\"\n+‚îä  ‚îä 7‚îä      ],\n+‚îä  ‚îä 8‚îä      \"include_dirs\": [\"<!(node -e \\\"require('nan')\\\")\"]\n+‚îä  ‚îä 9‚îä    }\n+‚îä  ‚îä10‚îä  ]\n+‚îä  ‚îä11‚îä}üö´‚Üµ\n```\n\nGYP stands for ‚ÄòGenerate Your Project‚Äô and was created by the Chromium team as a configuration file for building native projects. The configuration show above should be a good template for any future add-on you‚Äôre looking to develop. Let‚Äôs take a deeper look at it:\n\n-   `target_name` - Specifies the output dir of our add-on, in which case it should be `build/Release/distance`.\n\n-   `sources` - Should include all the cpp files that are associated with you add-on.\n\n-   `include_dirs` - Additional dirs that should be included when building the add-on. If you'll run the given script in the terminal you'll get the node-module path for Nan, a library which we're interested in during the build process.\n\n\nMore information about GYP configuration can be found [here](https://gyp.gsrc.io/docs/UserDocumentation.md).\n\n\nBe sure to also add the specified flag to the `package.json` which basically says 'Hey, I have a GYP file which should be taken into consideration as well':\n\n\n## [Create ‚Äòbinding.gyp‚Äô file](https://github.com/DAB0mB/node-distance-addon/commit/ff44399)\n\n\n**Changed package.json**\n\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n ‚îä 7‚îä 7‚îä    \"type\": \"git\",\n ‚îä 8‚îä 8‚îä    \"url\": \"https://github.com/DAB0mB/node-distance-addon.git\"\n ‚îä 9‚îä 9‚îä  },\n+‚îä  ‚îä10‚îä  \"gypfile\": true,\n ‚îä10‚îä11‚îä  \"scripts\": {\n ‚îä11‚îä12‚îä    \"test\": \"node test\"\n ‚îä12‚îä13‚îä  }\n```\n\nNow we will add the following NPM scripts so whenever we run `npm run build` our project will be built:\n\n\n## [Add npm build scripts](https://github.com/DAB0mB/node-distance-addon/commit/a9a8815)\n\n\n**Changed .gitignore**\n\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n+‚îä ‚îä1‚îäbuild\n ‚îä1‚îä2‚îänode_modulesüö´‚Üµ\n```\n\n**Changed package.json**\n\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n ‚îä 9‚îä 9‚îä  },\n ‚îä10‚îä10‚îä  \"gypfile\": true,\n ‚îä11‚îä11‚îä  \"scripts\": {\n+‚îä  ‚îä12‚îä    \"pre-publish\": \"npm run build\",\n+‚îä  ‚îä13‚îä    \"build\": \"node-gyp rebuild\",\n+‚îä  ‚îä14‚îä    \"test\": \"npm run build && node test\"\n ‚îä13‚îä15‚îä  }\n ‚îä14‚îä16‚îä}\n```\n\nThe only thing left to do before jumping into implementation would be installing Nan:\n\n```\n$ npm install nan --save\n```\n\nThe basis for build process is set. We will create the entry file for our add-on:\n\n## [Create add-on entry file](https://github.com/DAB0mB/node-distance-addon/commit/793e892)\n\n\n**Added src/distance.cc**\n\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n+‚îä ‚îä1‚îä#include <nan.h>\n+‚îä ‚îä2‚îä#include <v8.h>\n+‚îä ‚îä3‚îä\n+‚îä ‚îä4‚îäNAN_MODULE_INIT(Init) {\n+‚îä ‚îä5‚îä\n+‚îä ‚îä6‚îä}\n+‚îä ‚îä7‚îä\n+‚îä ‚îä8‚îäNODE_MODULE(distance, Init)üö´‚Üµ\n```\n\nEvery add-on should start with these two macro calls. They are both compiled into a piece of code which will register our module with ease. The `NODE_MODULE` macro template accepts the name of the target as the first argument (That one we set as `target_name` in the GYP file, remember?) and the initialization method for our module. The `NAN_MODULE_INIT`generates a function with the given name. It accepts `target` as the first argument which is equivalent to NodeJS's `exports`. Now we will create our first method stub for a synchronous distance calculation:\n\n\n## [Create ‚ÄòCalculateSync‚Äô method stub](https://github.com/DAB0mB/node-distance-addon/commit/90e3c72)\n\n\n**Changed src/distance.cc**\n\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n ‚îä 1‚îä 1‚îä#include <nan.h>\n ‚îä 2‚îä 2‚îä#include <v8.h>\n ‚îä 3‚îä 3‚îä\n+‚îä  ‚îä 4‚îäNAN_METHOD(CalculateSync) {\n+‚îä  ‚îä 5‚îä\n+‚îä  ‚îä 6‚îä}\n ‚îä 5‚îä 7‚îä\n+‚îä  ‚îä 8‚îäNAN_MODULE_INIT(Init) {\n+‚îä  ‚îä 9‚îä  NAN_EXPORT(target, CalculateSync);\n ‚îä 6‚îä10‚îä}\n ‚îä 7‚îä11‚îä\n ‚îä 8‚îä12‚îäNODE_MODULE(distance, Init)üö´‚Üµ\n```\n\nWe exported the `CalculateSync` by using the `NAN_EXPORT` macro, and we used `NAN_METHOD` to define a new node-valid function. It accepts `info` as the first argument and it is the same as JavaScript's `arguments` vector. We already know which arguments this function should accept, that's why I followed TDD methodology from the first place:\n\n\n## [Destructure arguments vector](https://github.com/DAB0mB/node-distance-addon/commit/ee1d560)\n\n\n**Changed src/distance.cc**\n\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n ‚îä 1‚îä 1‚îä#include <nan.h>\n ‚îä 2‚îä 2‚îä#include <v8.h>\n ‚îä 3‚îä 3‚îä\n+‚îä  ‚îä 4‚îäusing Nan::To;\n+‚îä  ‚îä 5‚îäusing v8::Local;\n+‚îä  ‚îä 6‚îäusing v8::Object;\n ‚îä 5‚îä 7‚îä\n+‚îä  ‚îä 8‚îäNAN_METHOD(CalculateSync) {\n+‚îä  ‚îä 9‚îä  Local<Object> js_pointA = To<Object>(info[0]).ToLocalChecked();\n+‚îä  ‚îä10‚îä  Local<Object> js_pointB = To<Object>(info[1]).ToLocalChecked();\n ‚îä 6‚îä11‚îä}\n ‚îä 7‚îä12‚îä\n ‚îä 8‚îä13‚îäNAN_MODULE_INIT(Init) {\n```\n\nWe use the `To()` function to convert the first argument into the desired type, and then we call the method `ToLocalChecked()`. This method is simply going to convert the result into v8's Local, unless the argument is undefined, in which case an error is going to be thrown. I like to prefix JS object with a `js_` so I know with what kind variable I'm dealing with. We should have two points containing `x` and `y` fields. Let's try to extract them out of the arguments vector and convert them into native C++ structures:\n\n\n## [Convert JS objects to native C++ structures](https://github.com/DAB0mB/node-distance-addon/commit/81998eb)\n\n\n**Changed src/distance.cc**\n\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n ‚îä 1‚îä 1‚îä#include <nan.h>\n ‚îä 2‚îä 2‚îä#include <v8.h>\n ‚îä 3‚îä 3‚îä\n+‚îä  ‚îä 4‚îäusing Nan::New;\n ‚îä 4‚îä 5‚îäusing Nan::To;\n ‚îä 5‚îä 6‚îäusing v8::Local;\n ‚îä 6‚îä 7‚îäusing v8::Object;\n+‚îä  ‚îä 8‚îäusing v8::String;\n+‚îä  ‚îä 9‚îä\n+‚îä  ‚îä10‚îästruct Point {\n+‚îä  ‚îä11‚îä  double x;\n+‚îä  ‚îä12‚îä  double y;\n+‚îä  ‚îä13‚îä};\n ‚îä 7‚îä14‚îä\n ‚îä 8‚îä15‚îäNAN_METHOD(CalculateSync) {\n ‚îä 9‚îä16‚îä  Local<Object> js_pointA = To<Object>(info[0]).ToLocalChecked();\n ‚îä10‚îä17‚îä  Local<Object> js_pointB = To<Object>(info[1]).ToLocalChecked();\n+‚îä  ‚îä18‚îä\n+‚îä  ‚îä19‚îä  Point* pointA = new Point();\n+‚îä  ‚îä20‚îä  pointA->x = To<double>(js_pointA->Get(New<String>(\"x\").ToLocalChecked())).FromJust();\n+‚îä  ‚îä21‚îä  pointA->y = To<double>(js_pointA->Get(New<String>(\"y\").ToLocalChecked())).FromJust();\n+‚îä  ‚îä22‚îä\n+‚îä  ‚îä23‚îä  Point* pointB = new Point();\n+‚îä  ‚îä24‚îä  pointB->x = To<double>(js_pointB->Get(New<String>(\"x\").ToLocalChecked())).FromJust();\n+‚îä  ‚îä25‚îä  pointB->y = To<double>(js_pointB->Get(New<String>(\"y\").ToLocalChecked())).FromJust();\n ‚îä11‚îä26‚îä}\n ‚îä12‚îä27‚îä\n ‚îä13‚îä28‚îäNAN_MODULE_INIT(Init) {\n```\n\nThen again we convert the `To()` function to convert the result into the desired data-type, only this time it's a primitive, so we use `FromJust()` instead of `ToLocalChecked()`. Note that v8 only uses double precision rather than a floating point. We can fetch properties from a given JS object with ease using the `Get()` method. Pay attention to use the `->` rather than a period because remember, a Local is actually a pointer! It is not the actual object.\n\n\nNow all is left to do is defining the return value. Keep in mind that the value should be returned through v8‚Äôs current scope, not natively, so using the `return` keyword would be useless. The return value can actually be defined through the provided `info` argument, like this:\n\n\n## [Add return value to ‚ÄòCalculateSync‚Äô method](https://github.com/DAB0mB/node-distance-addon/commit/1d6a7f6)\n\n\n**Changed src/distance.cc**\n\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n ‚îä23‚îä23‚îä  Point* pointB = new Point();\n ‚îä24‚îä24‚îä  pointB->x = To<double>(js_pointB->Get(New<String>(\"x\").ToLocalChecked())).FromJust();\n ‚îä25‚îä25‚îä  pointB->y = To<double>(js_pointB->Get(New<String>(\"y\").ToLocalChecked())).FromJust();\n+‚îä  ‚îä26‚îä\n+‚îä  ‚îä27‚îä  info.GetReturnValue().Set(CalculateDistance(pointA, pointB));\n ‚îä26‚îä28‚îä}\n ‚îä27‚îä29‚îä\n ‚îä28‚îä30‚îäNAN_MODULE_INIT(Init) {\n```\n\nAnd of-course it requires us to add the core distance calculation method:\n\n## [Add core distance calculation method](https://github.com/DAB0mB/node-distance-addon/commit/5af3b3d)\n\n\n**Changed src/distance.cc**\n\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n+‚îä  ‚îä 1‚îä#include <cstdlib>\n+‚îä  ‚îä 2‚îä#include <cmath>\n ‚îä 1‚îä 3‚îä#include <nan.h>\n ‚îä 2‚îä 4‚îä#include <v8.h>\n ‚îä 3‚îä 5‚îä\n ‚îä 4‚îä 6‚îäusing Nan::New;\n ‚îä 5‚îä 7‚îäusing Nan::To;\n+‚îä  ‚îä 8‚îäusing std::pow;\n+‚îä  ‚îä 9‚îäusing std::sqrt;\n ‚îä 6‚îä10‚îäusing v8::Local;\n ‚îä 7‚îä11‚îäusing v8::Object;\n ‚îä 8‚îä12‚îäusing v8::String;\n```\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n ‚îä12‚îä16‚îä  double y;\n ‚îä13‚îä17‚îä};\n ‚îä14‚îä18‚îä\n+‚îä  ‚îä19‚îädouble CalculateDistance(Point* pointA, Point* pointB) {\n+‚îä  ‚îä20‚îä  return sqrt(pow(pointA->x - pointB->x, 2) + pow(pointA->y - pointB->y, 2));\n+‚îä  ‚îä21‚îä}\n+‚îä  ‚îä22‚îä\n ‚îä15‚îä23‚îäNAN_METHOD(CalculateSync) {\n ‚îä16‚îä24‚îä  Local<Object> js_pointA = To<Object>(info[0]).ToLocalChecked();\n ‚îä17‚îä25‚îä  Local<Object> js_pointB = To<Object>(info[1]).ToLocalChecked();\n```\n\nThis is it for the synchronous calculation. Now we will add an async version of it. We will start by creating a method with everything we learned so far until the point where we have to return the result:\n\n## [Create ‚ÄòCalculateAsync‚Äô method with basic deconstructuring](https://github.com/DAB0mB/node-distance-addon/commit/2711bf5)\n\n\n**Changed src/distance.cc**\n\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n ‚îä35‚îä35‚îä  info.GetReturnValue().Set(CalculateDistance(pointA, pointB));\n ‚îä36‚îä36‚îä}\n ‚îä37‚îä37‚îä\n+‚îä  ‚îä38‚îäNAN_METHOD(CalculateAsync) {\n+‚îä  ‚îä39‚îä  Local<Object> js_pointA = To<Object>(info[0]).ToLocalChecked();\n+‚îä  ‚îä40‚îä  Local<Object> js_pointB = To<Object>(info[1]).ToLocalChecked();\n+‚îä  ‚îä41‚îä\n+‚îä  ‚îä42‚îä  Point* pointA = new Point();\n+‚îä  ‚îä43‚îä  pointA->x = To<double>(js_pointA->Get(New<String>(\"x\").ToLocalChecked())).FromJust();\n+‚îä  ‚îä44‚îä  pointA->y = To<double>(js_pointA->Get(New<String>(\"y\").ToLocalChecked())).FromJust();\n+‚îä  ‚îä45‚îä\n+‚îä  ‚îä46‚îä  Point* pointB = new Point();\n+‚îä  ‚îä47‚îä  pointB->x = To<double>(js_pointB->Get(New<String>(\"x\").ToLocalChecked())).FromJust();\n+‚îä  ‚îä48‚îä  pointB->y = To<double>(js_pointB->Get(New<String>(\"y\").ToLocalChecked())).FromJust();\n+‚îä  ‚îä49‚îä}\n+‚îä  ‚îä50‚îä\n ‚îä38‚îä51‚îäNAN_MODULE_INIT(Init) {\n ‚îä39‚îä52‚îä  NAN_EXPORT(target, CalculateSync);\n+‚îä  ‚îä53‚îä  NAN_EXPORT(target, CalculateAsync);\n ‚îä40‚îä54‚îä}\n ‚îä41‚îä55‚îä\n ‚îä42‚îä56‚îäNODE_MODULE(distance, Init)üö´‚Üµ\n```\n\nHere‚Äôs the different part. We don‚Äôt wanna simply return the value, we want to make the calculations in parallel with the event loop, and once we‚Äôre finished we will interact with it once again. In our model there are two threads. The first thread is the event loop thread, and the second thread will be a worker thread managed by Nan, the library supports asynchronous I/O in NodeJS. Let‚Äôs start implementing and I will give some more explanations as we go further:\n\n## [Queue distance worker](https://github.com/DAB0mB/node-distance-addon/commit/34f4a5d)\n\n\n**Changed src/distance.cc**\n\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n ‚îä 3‚îä 3‚îä#include <nan.h>\n ‚îä 4‚îä 4‚îä#include <v8.h>\n ‚îä 5‚îä 5‚îä\n+‚îä  ‚îä 6‚îäusing Nan::AsyncQueueWorker;\n+‚îä  ‚îä 7‚îäusing Nan::AsyncWorker;\n+‚îä  ‚îä 8‚îäusing Nan::Callback;\n ‚îä 6‚îä 9‚îäusing Nan::New;\n ‚îä 7‚îä10‚îäusing Nan::To;\n ‚îä 8‚îä11‚îäusing std::pow;\n ‚îä 9‚îä12‚îäusing std::sqrt;\n+‚îä  ‚îä13‚îäusing v8::Function;\n ‚îä10‚îä14‚îäusing v8::Local;\n ‚îä11‚îä15‚îäusing v8::Object;\n ‚îä12‚îä16‚îäusing v8::String;\n```\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n ‚îä38‚îä42‚îäNAN_METHOD(CalculateAsync) {\n ‚îä39‚îä43‚îä  Local<Object> js_pointA = To<Object>(info[0]).ToLocalChecked();\n ‚îä40‚îä44‚îä  Local<Object> js_pointB = To<Object>(info[1]).ToLocalChecked();\n+‚îä  ‚îä45‚îä  Callback* callback = new Callback(info[2].As<Function>());\n ‚îä41‚îä46‚îä\n ‚îä42‚îä47‚îä  Point* pointA = new Point();\n ‚îä43‚îä48‚îä  pointA->x = To<double>(js_pointA->Get(New<String>(\"x\").ToLocalChecked())).FromJust();\n```\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n ‚îä46‚îä51‚îä  Point* pointB = new Point();\n ‚îä47‚îä52‚îä  pointB->x = To<double>(js_pointB->Get(New<String>(\"x\").ToLocalChecked())).FromJust();\n ‚îä48‚îä53‚îä  pointB->y = To<double>(js_pointB->Get(New<String>(\"y\").ToLocalChecked())).FromJust();\n+‚îä  ‚îä54‚îä\n+‚îä  ‚îä55‚îä  AsyncQueueWorker(new DistanceWorker(callback, pointA, pointB));\n ‚îä49‚îä56‚îä}\n ‚îä50‚îä57‚îä\n ‚îä51‚îä58‚îäNAN_MODULE_INIT(Init) {\n```\n\nHere we fetch the third argument which is the callback. We wrap it with Nan‚Äôs Callback, which will make sure it is not garbage collected once the scope is being deleted, we want it to keep living until it‚Äôs not relevant. At the bottom of the method, instead of returning a value explicitly, we queue our `DistanceWorker` into the workers queue. On that note, let's implement the DistanceWorker:\n\n\n## [Create ‚ÄòDistanceWorker‚Äô with a constructor and a deconstructor](https://github.com/DAB0mB/node-distance-addon/commit/8bbd87f)\n\n\n**Changed src/distance.cc**\n\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n ‚îä24‚îä24‚îä  return sqrt(pow(pointA->x - pointB->x, 2) + pow(pointA->y - pointB->y, 2));\n ‚îä25‚îä25‚îä}\n ‚îä26‚îä26‚îä\n+‚îä  ‚îä27‚îäclass DistanceWorker : public AsyncWorker {\n+‚îä  ‚îä28‚îä private:\n+‚îä  ‚îä29‚îä  Point* pointA;\n+‚îä  ‚îä30‚îä  Point* pointB;\n+‚îä  ‚îä31‚îä\n+‚îä  ‚îä32‚îä public:\n+‚îä  ‚îä33‚îä  DistanceWorker(Callback* callback, Point* pointA, Point* pointB) :\n+‚îä  ‚îä34‚îä    AsyncWorker(callback), pointA(pointA), pointB(pointB) {}\n+‚îä  ‚îä35‚îä\n+‚îä  ‚îä36‚îä  ~DistanceWorker() {\n+‚îä  ‚îä37‚îä    delete pointA;\n+‚îä  ‚îä38‚îä    delete pointB;\n+‚îä  ‚îä39‚îä  }\n+‚îä  ‚îä40‚îä\n+‚îä  ‚îä41‚îä  void Execute () {\n+‚îä  ‚îä42‚îä\n+‚îä  ‚îä43‚îä  }\n+‚îä  ‚îä44‚îä\n+‚îä  ‚îä45‚îä  void HandleOKCallback () {\n+‚îä  ‚îä46‚îä\n+‚îä  ‚îä47‚îä  }\n+‚îä  ‚îä48‚îä};\n+‚îä  ‚îä49‚îä\n ‚îä27‚îä50‚îäNAN_METHOD(CalculateSync) {\n ‚îä28‚îä51‚îä  Local<Object> js_pointA = To<Object>(info[0]).ToLocalChecked();\n ‚îä29‚îä52‚îä  Local<Object> js_pointB = To<Object>(info[1]).ToLocalChecked();\n```\n\n`AsyncWorker` is an abstract class that you can subclass to have much of the annoying asynchronous queuing and handling taken care of for you. It can even store arbitrary v8 objects for you and have them persist while the asynchronous work is in progress. The `execute()` method is being executed inside the worker-thread. It is not safe to access V8, or V8 data structures there, so everything we need for input and output should go on 'this'. The `HandleOKCallback()` method is executed when the async work is complete. This function will be run inside the main event loop so it is safe to use v8 again. Let's implement the core distance calculation on the worker thread:\n\n\n## [Execute distance calculation](https://github.com/DAB0mB/node-distance-addon/commit/9cd18e8)\n\n\n**Changed src/distance.cc**\n\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n ‚îä26‚îä26‚îä\n ‚îä27‚îä27‚îäclass DistanceWorker : public AsyncWorker {\n ‚îä28‚îä28‚îä private:\n+‚îä  ‚îä29‚îä  double distance;\n ‚îä29‚îä30‚îä  Point* pointA;\n ‚îä30‚îä31‚îä  Point* pointB;\n ‚îä31‚îä32‚îä\n```\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n ‚îä39‚îä40‚îä  }\n ‚îä40‚îä41‚îä\n ‚îä41‚îä42‚îä  void Execute () {\n+‚îä  ‚îä43‚îä    distance = CalculateDistance(pointA, pointB);\n ‚îä43‚îä44‚îä  }\n ‚îä44‚îä45‚îä\n ‚îä45‚îä46‚îä  void HandleOKCallback () {\n```\n\nAnd handle a successful invocation once the calculation is finished:\n\n## [Handle successful invokation](https://github.com/DAB0mB/node-distance-addon/commit/8dd60ff)\n\n\n**Changed src/distance.cc**\n\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n ‚îä 6‚îä 6‚îäusing Nan::AsyncQueueWorker;\n ‚îä 7‚îä 7‚îäusing Nan::AsyncWorker;\n ‚îä 8‚îä 8‚îäusing Nan::Callback;\n+‚îä  ‚îä 9‚îäusing Nan::HandleScope;\n ‚îä 9‚îä10‚îäusing Nan::New;\n+‚îä  ‚îä11‚îäusing Nan::Null;\n ‚îä10‚îä12‚îäusing Nan::To;\n ‚îä11‚îä13‚îäusing std::pow;\n ‚îä12‚îä14‚îäusing std::sqrt;\n ‚îä13‚îä15‚îäusing v8::Function;\n ‚îä14‚îä16‚îäusing v8::Local;\n+‚îä  ‚îä17‚îäusing v8::Number;\n ‚îä15‚îä18‚îäusing v8::Object;\n ‚îä16‚îä19‚îäusing v8::String;\n+‚îä  ‚îä20‚îäusing v8::Value;\n ‚îä17‚îä21‚îä\n ‚îä18‚îä22‚îästruct Point {\n ‚îä19‚îä23‚îä  double x;\n```\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n ‚îä44‚îä48‚îä  }\n ‚îä45‚îä49‚îä\n ‚îä46‚îä50‚îä  void HandleOKCallback () {\n+‚îä  ‚îä51‚îä    HandleScope scope;\n ‚îä47‚îä52‚îä\n+‚îä  ‚îä53‚îä    Local<Value> argv[] = {\n+‚îä  ‚îä54‚îä      Null(),\n+‚îä  ‚îä55‚îä      New<Number>(distance)\n+‚îä  ‚îä56‚îä    };\n+‚îä  ‚îä57‚îä\n+‚îä  ‚îä58‚îä    callback->Call(2, argv);\n ‚îä48‚îä59‚îä  }\n ‚îä49‚îä60‚îä};\n```\n\nNormally, when defining a NodeJS method (`NAN_METHOD` macro) a scope will be created for us automatically. In this function's context there is no scope exist, so we will have to create it using the `HandleScope` deceleration (The current scope is stored globally so even though we don't use it explicitly, v8 and Nan know what to do). We also created an arguments vector as the return value, following NodeJS's conventions, the first argument would be the error and the second argument would be the result.\n\n\nThis is it! Finally we will transform the add-on into a nicer looking node-module:\n\n## [Transform add-on into a nicer looking node-module](https://github.com/DAB0mB/node-distance-addon/commit/a250013)\n\n\n**Added index.js**\n\n\n```\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë diff ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n+‚îä ‚îä1‚îäconst Distance = require('./build/Release/distance');\n+‚îä ‚îä2‚îä\n+‚îä ‚îä3‚îäexports.calculate = {\n+‚îä ‚îä4‚îä  sync: Distance.CalculateSync,\n+‚îä ‚îä5‚îä  async: Distance.CalculateAsync\n+‚îä ‚îä6‚îä};üö´‚Üµ\n```\n\nAnd now, let‚Äôs run our small test to see that it works, using the following command:\n\n```\n$ npm run test\n```\n\nIf everything went well, you should have the following messages printed to the terminal:\n\n```\nsync calculation passed\nasync calculation passed\n```\n\n---\n\n# What‚Äôs next?\n\nYou‚Äôve just learned the very basics of how to use C++ within NodeJS. There‚Äôs a lot more to learn when it comes to building an add-on, and I‚Äôm not just talking about learning v8 and Nan‚Äôs API. Think about the possibilities, the C++ community have been developed for years and there are so much great libraries out there that are not necessarily relevant to NodeJS due to its efficiency, like [Boost](http://www.boost.org/), [OpenCV](http://opencv.org/), [CGAL](http://www.cgal.org/) and many more.\n\n\n-   Check out the full project of this tutorial: <https://github.com/DAB0mB/node-distance-addon>\n\n-   Check out this awesome framework for creating tutorials by Urigo, which helped me making this nicely structured tutorial: <https://github.com/Urigo/tortilla>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"588b4f2248cc\",\"publishedDate\":1494261412332,\"url\":\"https://medium.com/the-guild/nodejs-advanced-how-to-create-a-native-add-on-using-c-588b4f2248cc\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDo1NjoxOCswMTowMM4izqSe",
            "node": {
              "title": "GraphQL Scalars 1.0 is out! More Types, Data Integrity and Strict Validations on GraphQL",
              "body": "![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*scQ-ST9kcviAtUPjq1BYEw.gif?raw=true)\n\n# GraphQL Scalars 1.0 is out! More Types, Data Integrity and Strict Validations on GraphQL\n\nThe GraphQL Specification has the`Int`, `Float`, `String`, `Boolean`and `ID` Scalar types by default. Those scalar types help you identify the data and validate it before transferring it between client and server. But you might need more specific scalars for your GraphQL application, to help you better describe and validate your app‚Äôs data.\n\n\n## **Validation using Scalars**\n\n\nFor example, you have a `String` field but you need to validate upcoming or ongoing string data using regular expressions. So you should have this validation on each end; one in the client, the other one in the server and maybe there is another on a source. Instead of duplicating the same logic in different parts of the project, you can use `EmailAddress` scalar type that does the validation inside GraphQL for you.\n\n\n## Serialization and Parsing\n\nThe other benefit of using GraphQL scalar types is parsing and serializing while transferring data. For example, you have `DateTime` data but it is transferred as `String` due to restrictions of JSON, and each time you receive and pass the data, you have to parse the string and create a JavaScript `Date` instance while also serializing it to string before passing it to the client. Instead of having that logic in your implementation, you can just use `DateTime` scalar and you would work with native JavaScript`Date` instances directly like it is one of primitive types such as string, number and boolean.\n\n\n# What‚Äôs New?\n\n[We‚Äôve](http://the-guild.dev) recently [taken over the maintenance](https://medium.com/the-guild/the-guild-is-taking-over-maintenance-of-merge-graphql-schemas-so-lets-talk-about-graphql-schema-46246557a225) of [GraphQL-Scalars](https://github.com/urigo/graphql-scalars) library from the amazing team of OK-Grow!\n\n\nSince then we completely rewrote the library using TypeScript, upgraded all dependencies, closed all the issues and PRs and increased the number of scalars in the package with new scalars like: `BigInt(Long)` , `GUID` , `HexColorCode` , `Hexadecimal` , `IPv4` , `IPv6` , `ISBN` , `MAC` , `JSON` and more. You can see all scalars in the [**README**](https://github.com/Urigo/graphql-scalars#the-types).\n\n\n# Mocking\n\nApollo Server provides mocks built-in scalars such as `Int` , `String` , `Float` , `ID` and `Boolean` . What if you need same thing for our scalars? So, we provide you mocking functions for each scalar in this package. You can add those easily in your server for mocking the schema.\n\n\n```typescript\nimport { ApolloServer } from 'apollo-server';\nimport { makeExecutableSchema } from 'graphql-tools';\n// import all scalars and resolvers\nimport { typeDefs, resolvers, mocks } from 'graphql-scalars';\n// Alternatively, import individual scalars and resolvers\n// import { DateTimeResolver, DateTimeTypeDefinition, DateTimeMock, ... } from \"graphql-scalars\"\n\nconst server = new ApolloServer({\n  typeDefs: [\n    // use spread syntax to add scalar definitions to your schema\n    ...typeDefs,\n    // DateTimeDefinition,\n    // ...\n    // ... other type definitions ...\n  ],\n  resolvers: {\n    // use spread syntax to add scalar resolvers to your resolver map\n    ...resolvers,\n    // DateTimeResolver,\n    // ...\n    // ... remainder of resolver map ...\n  },\n  mocks: {\n    // use spread syntax to add scalar resolvers to your resolver map\n    ...mocks,\n    // DateTimeMock,\n    // ...\n    // ... other mocks ...\n  }\n});\n```\n\n# Special Thanks\n\nThanks to OK-Grow for creating this package, [adriano-di-giovanni](https://github.com/adriano-di-giovanni) for being generous and giving us the [`graphql-scalars`](http://npmjs.com/package/graphql-scalars) name on npm, to [Saeris](https://github.com/Saeris) for letting us to take other scalar implementations from his fork, [stems](https://github.com/stems) for their [`graphql-bigint`](https://github.com/stems/graphql-bigint) package, [abhiaiyer91](https://github.com/abhiaiyer91) for his [`graphql-currency-scalars`](https://github.com/abhiaiyer91/graphql-currency-scalars) package and [taion](https://github.com/taion) for his [`graphql-type-json`](https://github.com/taion/graphql-type-json).\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"972079428fb\",\"publishedDate\":1565273452215,\"url\":\"https://medium.com/the-guild/graphql-scalars-1-0-is-out-more-types-data-integrity-and-strict-validations-on-graphql-972079428fb\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDo1NTo0MyswMTowMM4izqOU",
            "node": {
              "title": "Manage Circular Imports Hell in GraphQL-Modules",
              "body": "![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*GtvTnhPxwZKLWiO1.png?raw=true)\n\nDesigning and building modular GraphQL API may not look straight-forward the first time you start. It is hard to keep a perfect modularity with standalone and encapsulated modules.\n\nIt is really easy to appeal to the circular imports, but that‚Äôs exactly what you shouldn‚Äôt do in any case. You might say while reading this; **_I DON‚ÄôT HAVE ANY WAY OF NOT CREATING CIRCULAR IMPORTS_**!\n\n\nIn a previous versions of GraphQL-Modules, we used to allow users to have circular imports in their GraphQL-Modules applications. However, it created a lot of extra logic which slows down the initial schema generation speed, because we always need to check if there is circular imports between modules.\n\nThen, if GraphQL-Modules found some, it would **merge** all the members of this **circular import** into a one **LARGE MODULE** which was **breaking almost every principle of encapsulation and modularity** we mentioned in previous blog-posts of our GraphQL-Modules series.\n\n\nFinally, we decided to **remove this** support; then **force** people to have **strict modularity** in their projects.\n\n\n[https://medium.com/the-guild/why-is-true-modular-encapsulation-so-important-in-large-scale-graphql-projects-ed1778b03600](https://medium.com/the-guild/why-is-true-modular-encapsulation-so-important-in-large-scale-graphql-projects-ed1778b03600 \"Why is True Modular Encapsulation So Important in Large-Scale GraphQL Projects?\nHow GraphQL Modules helps you encapsulate the different parts of your code, so it will be easier to manage when your‚Ä¶medium.com\")\n\nForcing people out of a way of developing is always hard and we‚Äôve got [questions from you](https://github.com/Urigo/graphql-modules/issues/317) about how to solve some specific issues ‚Äî so in this blog post and new doc section we will help you understand why this was a bad practice and how to migrate from it with different use cases.\n\n\n# The Problem\n\nLet‚Äôs assume we have 3 different entities in our database;\n\n-   User\n-   Post\n-   Comment\n\nThen, if we create three different modules for these three entities;\n\n```graphql\ntype User {\n id: ID\n name: String\n username: String\n email: String\n ## Some other fields\n posts: [Post]\n comments: [Comment]\n}\n```\n\n```graphql\ntype Post {\n id: ID\n title: String\n content: String\n user: User\n comments: [Comment]\n}\n\n```\n\n```graphql\ntype Comment {\n id: ID\n content: String\n user: User\n post: Post\n}\n```\n\nAs you can see above, every module imports other modules; and this creates a circular dependency.\n\nYou might ask if this is the only way to implement modules for these entities; because it looks like there is no point to have different modules for those schemas. Having circular dependency is the same situtation with having a single large module.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*2Yeuig2ffEYQmXY2sQfG5A.gif?raw=true)\n\n# How To Solve\n\nLet‚Äôs see what we have in terms of relationship; - `User` doesn‚Äôt depend on `Post` and `Comment` - `Post` doesn‚Äôt depend on `Comment`.\n\n\n\\- `Comment` depends on `User` and `Post`, because it has `userId` and `postId` fields - `Post` also depends on `User` because it has `userId` field\n\n\nSo let‚Äôs create modules in that way,\n\n```graphql\ntype User {\n¬†id: ID\n¬†name: String\n¬†username: String\n¬†email: String\n¬†## Some other fields\n}\n```\n\n```graphql\ntype Post {\n¬†id: ID\n¬†title: String\n¬†content: String\n¬†user: User\n}\nextend type User {\n¬†posts: [Post]\n}\n```\n\n```graphql\ntype Comment {\n¬†id: ID\n¬†content: String\n¬†user: User\n¬†post: Post\n}\nextend type Post {\n¬†comments: [Comment]\n}\nextend type User {\n¬†comments: [Comment]\n}\n```\n\n> Using this approach, you will have standalone modules; otherwise will create a big module which contains all of them like we used to handle circular deps in this way (**merging all circular imports**).\n>\n\nAlso `extend` says that it needs a main definition from imported modules which makes the connection more readable in terms of entity relations.\n\n\n---\n\n# All posts about GraphQL Modules\n\n1.  [GraphQL Modules ‚Äî Feature based GraphQL Modules at scale](https://medium.com/the-guild/graphql-modules-feature-based-graphql-modules-at-scale-2d7b2b0da6da)\n\n1.  [Why is True Modular Encapsulation So Important in Large-Scale GraphQL Projects?](https://medium.com/the-guild/why-is-true-modular-encapsulation-so-important-in-large-scale-graphql-projects-ed1778b03600)\n\n1.  [Why did we implement our own Dependency Injection library for GraphQL-Modules?](https://medium.com/p/f25a234a9762)\n\n1.  [Scoped Providers in GraphQL-Modules Dependency Injection](https://medium.com/p/949cd2588e0)\n\n1.  [Writing a GraphQL TypeScript project w/ GraphQL-Modules and GraphQL-Code-Generator](https://medium.com/the-guild/writing-strict-typed-graphql-typescript-project-w-graphql-modules-and-graphql-code-generator-c22f6caa17b8)\n\n1.  [Authentication and Authorization in GraphQL (and how GraphQL-Modules can help)](https://medium.com/the-guild/authentication-and-authorization-in-graphql-and-how-graphql-modules-can-help-fadc1ee5b0c2)\n\n1.  [Authentication with AccountsJS & GraphQL Modules](https://medium.com/the-guild/authentication-with-accountsjs-graphql-modules-e0fb9799a9da)\n\n1.  [Manage Circular Imports Hell with GraphQL-Modules](https://medium.com/the-guild/manage-circular-imports-hell-with-graphql-modules-4b1611dee781)\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"4b1611dee781\",\"publishedDate\":1552925179308,\"url\":\"https://medium.com/the-guild/manage-circular-imports-hell-with-graphql-modules-4b1611dee781\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDo1NToxOSswMTowMM4izqLQ",
            "node": {
              "title": "Stencil-Apollo ‚Äî Stencil meets GraphQL",
              "body": "## Stencil-Apollo lets you easily use GraphQL in Web Components.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*xZX1mXJNgpz-QIGkXXAKBQ.png?raw=true)\n\n**GraphQL** is everywhere! Together with **Typescript** it is one of those technologies **everyone wants to get their hands on** in 2019.\n\n\nWhen using GraphQL on the client, the most popular library is the powerful Apollo Client. Today, [Apollo](https://github.com/apollographql/apollo-client) currently has an official support for leading Web Frameworks like React and Angular.\n\n\nBut what if you don‚Äôt have to use those frameworks to create a really powerful and performant apps? Or what if you want to expose Web Components with shared logic like GraphQL data fetching to developers who use different frameworks?\n\n# Web Components and GraphQL\n\nThat‚Äôs where [Stencil](https://stenciljs.com) come in. It‚Äôs a Web Components compiler that combines some of the best features from Angular, React and Vue to create web applications or re-usable platform agnostic UI libraries based on Web Components.\n\n\nBut what if you want to use GraphQL in your Stencil projects or expose that power to your Web Components users?\n\n# The solution!\n\nToday, I am happy to announce the release of a new open source library\n\n> ### [stencil-apollo](https://github.com/ardatan/stencil-apollo)\n>\n\nNow it is much easier to use StencilJS and create GraphQL-based applications. **Stencil-Apollo has the same functionalities as its React sibling** React-Apollo, and the usage is really simple.\n\n\n```tsx\n<apollo-query query={\n  gql`\n      query allPosts {\n      posts {\n        title\n        votes\n      }\n      }            \n    `              \n  }\n  renderer={\n    ({ data, loading }) => {\n      if (loading) return 'Loading...';\n      return (\n        <ul>\n          {data.posts.map(post => (\n            <li>\n              {post.title}\n              ({post.votes} votes)\n            </li>\n          ))}\n        </ul>\n      );\n    }\n  } />\n```\n\n# Stencil and Apollo\n\nBecause [Stencil-Apollo](https://github.com/ardatan/stencil-apollo) uses Apollo-Client, you‚Äôre still able to take advantage of **an entire ecosystem of Apollo Links and Cache implementations**.\n\n\n> ### Everything in Stencil-Apollo is based on Web Components\n\nThere are exactly 4 of them:\n\n-   `apollo-provider` defines an Apollo-Client so other [Stencil-Apollo](https://github.com/ardatan/stencil-apollo) components can use it (same as React-Apollo‚Äôs `ApolloProvider`).\n\n\nAs you know in GraphQL there are three kinds of operations and [Stencil-Apollo](https://github.com/ardatan/stencil-apollo) got all them covered:\n\n\n-   `apollo-query` lets you fetch data\n\n-   `apollo-mutation` is responsible to call mutations\n\n-   `apollo-subscription` handles subscription for you\n\n\nAs you can see, their names are pretty easy to remember!\n\n[Stencil-Apollo](https://github.com/ardatan/stencil-apollo) combines the change detection mechanism of Apollo Client and StencilJS‚Äôs Virtual DOM, like React-Apollo does for React‚Äôs VDOM.\n\n\nTo start using Stencil-Apollo check out our examples and docs:\n\n[https://github.com/ardatan/stencil-apollo/](https://github.com/ardatan/stencil-apollo/ \"ardatan/stencil-apollo\nStencil Apollo Library. Contribute to ardatan/stencil-apollo development by creating an account on GitHub.github.com\")\n\n[Stencil-Apollo](https://github.com/ardatan/stencil-apollo) works quite well with Ionic 4, and we‚Äôre planning to give support for all other frameworks, the same way as Ionic 4 does by using the power of Web Components.\n\n\n# Ready-to-use and strongly typed GraphQL components\n\nThe [GraphQL Code Generator](https://graphql-code-generator.com/) can be used to generate TypeScript typings for both server and client.\n\n\nThis tool also generates strongly typed [React-Apollo components](https://medium.com/the-guild/graphql-code-generator-for-typescript-react-apollo-7b225672588f) and [Apollo-Angular services](https://medium.com/the-guild/apollo-angular-code-generation-7903da1f8559) to improve the development experience. It turns your GraphQL operations into ready to use elements.\n\n\n> ### **Now it also supports Stencil-Apollo!**\n>\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*T_zYxowHjV0tixVvkOhhtg.gif?raw=true \"How Stencil-Apollo works with GraphQL-Code-Generator\")\n\n> [Check out our example](https://github.com/ardatan/stencil-apollo/tree/master/example-with-codegen) with GraphQL-Code-Generator\n>\n\n# WhatsApp PWA Clone using Stencil and Ionic 4\n\nWe‚Äôre also working on an example Stencil PWA project that uses [Stencil-Apollo](https://github.com/ardatan/stencil-apollo) which will be another variation of our [WhatsApp Clone](https://medium.com/the-guild/whatsapp-clone-using-react-hooks-suspense-graphql-apollo-typescript-and-postgresql-de1840c27d21).\n\n\nFollow the process here:\n\n[https://github.com/Urigo/WhatsApp-Clone-Client-React/issues/158](https://github.com/Urigo/WhatsApp-Clone-Client-React/issues/158 \"Another Clone using Stencil & Ionic 4 üöÄ ¬∑ Issue #158 ¬∑ Urigo/WhatsApp-Clone-Client-React\nPure Progressive Web Application Example using Stencil and Ionic 4 with; PWA Support / 100% Lighthouse Audit Result HMR‚Ä¶github.com\")\n\n---\n\n-   [Stencil-Apollo repository](https://github.com/ardatan/stencil-apollo)\n\n-   [Documentation](https://github.com/ardatan/stencil-apollo)\n\n-   [An example of code generation](https://github.com/ardatan/stencil-apollo/tree/master/example-with-codegen)\n\n\n---\n\n> Follow us on **GitHub** and **Medium**, we are planning to release many more posts in the next couple of weeks about what we‚Äôve learned using **GraphQL** in recent years.\n>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"6fec577ee615\",\"publishedDate\":1551888971300,\"url\":\"https://medium.com/the-guild/stencil-apollo-stencil-meets-graphql-6fec577ee615\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDo1NTowMiswMTowMM4izqJI",
            "node": {
              "title": "Scoped Providers in GraphQL-Modules Dependency Injection",
              "body": "![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*K2d-IqITJ1CQS5Z0MiyV-w.png?raw=true \"Understand how scopes work in GraphQL-Modules\")\n\nWe recently released a new version of GraphQL-Modules with a new feature called Scoped Providers in the dependency injection system of GraphQL-Modules.\n\nDependency injection in **GraphQL-Modules** is optional, and you can use it according to your preference. It provides a solution for writing `Provider`s, which are just classes, you can use to write your business-logic, and this way to separate it from your API declaration, reuse it, and communicate between modules easily.\n\n\nThis new feature allows you to define `Provider`s to be used in different scopes;\n\n\n# Application Scope\n\nIf you define a provider in this scope which is default, the provider will be instantiated on application-start and will be same in the entire application and all the following requests. The providers in this scope can be considered as a shared state across all users‚Äô interactions with our application. It‚Äôs basically means that the instance will be treated as [Singleton](https://en.wikipedia.org/wiki/Singleton_pattern).\n\n\nFor example you have a provider called `ExampleApplicationProvider` , then this provider has a counter in it;\n\n\n```typescript\nimport { Injectable, ProviderScope } from '@graphql-modules/di';\n\n@Injectable({\n  scope: ProviderScope.Application\n})\nexport class ExampleApplicationProvider {\n  counter = 0;\n  increment(){\n    counter++;\n    return counter;\n  }\n}\n\n```\n\nAnd let‚Äôs assume that we have a module declaration something like below;\n\n```typescript\nimport { GraphQLModule } from '@graphql-modules/core';\nimport { ExampleApplicationProvider } from './ExampleApplicationProvider';\n\nexport const ExampleModule = new GraphQLModule({\n providers: [\n  ExampleApplicationProvider\n ],\n typeDefs: `\n   type Mutation {\n    increment: Int\n   }\n `,\n resolvers: {\n  Mutation: {\n   increment: (root, args, context) => context.injector.get(ExampleApplicationProvider).increment()\n  }\n }\n});\n\n```\n\nFinally, let‚Äôs try to call the following GraphQL Request in multiple times;\n\n```graphql\nmutation ExampleMutation {\n increment\n}\n\n```\n\nIn first call, you will get `1` , but in the second call you will get `2` . And in every request this value will be incremented; because Application-Scoped Providers are kept in memory until the application is terminated; and the same instance of that provider will be used on each request. Let‚Äôs see other types of providers to understand this one better.\n\n\n# Session Scope\n\nWhen a network request is arriving to your GraphQL-Server, GraphQL-Server calls the context factory of the parent module. The parent module creates a session injector together with instantiating session-scoped providers with that session object which contains the current context, session injector and network request. This session object is passed through module‚Äôs resolvers using module‚Äôs context.\n\nIn other words, providers defined in the session scope are constructed in the beginning of the network request, then kept until the network request is closed. While application-scoped providers is kept during the application runtime, and shared between all the following network requests and resolvers inside of these requests, this type of providers would not be shared between different requests but in resolver calls those belong to same network request.\n\nLet‚Äôs try the same thing in that scope by creating a new provider called `ExampleSessionProvider` .\n\n\n```typescript\nimport { Injectable, ProviderScope } from '@graphql-modules/di';\n\n@Injectable({\n  scope: ProviderScope.Session\n})\nexport class ExampleSessionProvider {\n  counter = 0;\n  increment(){\n    counter++;\n    return counter;\n  }\n}\n\n```\n\nThen change our module declaration to use this provider;\n\n```typescript\nimport { GraphQLModule } from '@graphql-modules/core';\nimport { ExampleSessionProvider } from './ExampleApplicationProvider';\n\nexport const ExampleModule = new GraphQLModule({\n providers: [\n  ExampleSessionProvider\n ],\n typeDefs: `\n   type Mutation {\n    increment: Int\n   }\n `,\n resolvers: {\n  Mutation: {\n   increment: (root, args, context) => context.injector.get(ExampleSessionProvider).increment()\n  }\n }\n});\n\n```\n\nSo at this time, in every mutation call our Session-Scoped Provider‚Äôs increment method will be called and its value will be returned as a result of that mutation.\n\n```graphql\nmutation ExampleMutation {\n increment\n}\n\n```\n\nIn first call, you will get `1` , but in the second call you will get `1` again. But why? Because on each request `ExampleSessionProvider` is instantiated from scratch specifically for that network request which is called session in our DI system. But to see the point of the session scope, let‚Äôs assume we have two more resolvers called `multiply` . First let‚Äôs add another method called `multiply` that takes one argument to be multiplied by our counter value;\n\n\n```typescript\nimport { Injectable, ProviderScope } from '@graphql-modules/di';\n\n@Injectable({\n  scope: ProviderScope.Session\n})\nexport class ExampleSessionProvider {\n  counter = 0;\n  increment(){\n    counter++;\n    return counter;\n  }\n  multiply(times: number){\n    counter = counter * times;\n    return counter;\n  }\n}\n\n```\n\nAfter that, let‚Äôs use this new method in our new resolver;\n\n```typescript\nimport { GraphQLModule } from '@graphql-modules/core';\nimport { ExampleApplicationProvider } from './ExampleApplicationProvider';\n\nexport const ExampleModule = new GraphQLModule({\n providers: [\n  ExampleApplicationProvider\n ],\n typeDefs: `\n   type Mutation {\n    increment: Int\n    multiply(times: Int): Int\n   }\n `,\n resolvers: {\n  Mutation: {\n   increment: (root, args, context) => context.injector.get(ExampleApplicationProvider).increment(),\n   multiply: (root, args, context) => context.injector.get(ExampleApplicationProvider).multiply(args.times)\n  }\n }\n});\n\n```\n\nWhen we call the following GraphQL request,\n\n```graphql\nmutation ExampleMutation {\n increment\n multiply(times: 2)\n}\n\n```\n\nIn first call, the initial counter value `0` will be incremented . Then the result becomes `1` and this value will be returned as a result of `increment` mutation, but on the same request we have `multiply` as well. So the same counter value will be multiplied by `2` , and this value will be returned as a result of `multiply` mutation.\n\n\nSo, on every request the result will be;\n\n```\n{\n increment: 1,\n multiply: 2\n}\n```\n\nBut if the provider is in ApplicationScope, the result will be `[3,6]` in the second call.\n\n\n# Request Scope\n\nIf you have request-scoped providers in your GraphQL Module, these providers are generated in every injection. This means a request-scoped provider is never kept neither application state, nor session state. So, this type of providers works just like [Factory](https://en.wikipedia.org/wiki/Factory_method_pattern). It creates an instance each time you request from the injector.\n\n\nLet‚Äôs assume we do the similar changes for RequestScope. The results will be like below on each request;\n\n```\n{\n  increment: 1,\n  multiply: 0\n}\n```\n\nBecause request-scoped providers are constructed on each `injector.get` call. They are kept in the current function scope, they‚Äôre not kept in any session or DI container. That‚Äôs why, we can consider them `factory` .\n\n\nAs you can see the example and the results above, `ExampleApplicationProvider` is shared between different network requests, while `ExampleSessionProvider` is shared between resolver-calls inside the same network request. But, `ExampleRequestProvider` is only kept in the same resolver call.\n\n\n# New `ModuleSessionInfo` built-in provider\n\n\nLet‚Äôs assume that you have a token required for your authentication process. And this token is probably stored in request header. And GraphQL-Modules provides you access to network request in a built-in provider called **_ModuleSessionInfo_**. This session object is the raw request/response object passed by your HTTP Server. For example, if you‚Äôre using Express, you will get something like `{ req: IncommingMessage, res: Response }` .\n\n\nEvery GraphQL-Module creates a _ModuleSessionInfo_ instance in each network request that contains raw `Session` from the GraphQL Server, `SessionInjector` that contains Session-scoped instances together with Application-scoped ones and `Context` object which is constructed with `contextBuilder` of the module. But, notice that you cannot use this built-in provider.\n\n\n```typescript\n@Injectable({\n    scope: ProviderScope.Session\n})\nclass ExampleSessionScopeProvider {\n  constructor(private moduleSessionInfo: ModuleSessionInfo) {\n     moduleSessionInfo // { session, context, injector }\n  }\n}\n\n@Injectable({\n    scope: ProviderScope.Application\n})\nclass ExampleInvalidApplicationScopeProvider {\n  constructor(private moduleSessionInfo: ModuleSessionInfo) {} // Error: ModuleSessionInfo is not valid provider\n}\n\n@Injectable({\n    scope: ProviderScope.Application\n})\nclass ExampleApplicationScopeProvider implements OnRequest {\n    onRequest(moduleSessionInfo){\n        moduleSessionInfo // { session, context, injector }\n    }\n}\n\n```\n\nAs you can see, you cannot use `ModuleSessionInfo` in Application Scope, because application-scoped providers belong to the whole application, and application-scoped providers are completely independent from the network request.\n\n\nHowever, you can use `onRequest` hook to have `ModuleSessionInfo` in your Application-Scoped provider which is called on each network request.\n\n\n# What‚Äôs next?\n\nWe are constantly trying to improve the set of tools provided by **GraphQL-Modules**, and we welcome you to try it and share your experience and thoughts.\n\n\n# All posts about GraphQL Modules\n\n1.  [GraphQL Modules ‚Äî Feature based GraphQL Modules at scale](https://medium.com/the-guild/graphql-modules-feature-based-graphql-modules-at-scale-2d7b2b0da6da)\n\n1.  [Why is True Modular Encapsulation So Important in Large-Scale GraphQL Projects?](https://medium.com/the-guild/why-is-true-modular-encapsulation-so-important-in-large-scale-graphql-projects-ed1778b03600)\n\n1.  [Why did we implement our own Dependency Injection library for GraphQL-Modules?](https://medium.com/p/f25a234a9762)\n\n1.  [Scoped Providers in GraphQL-Modules Dependency Injection](https://medium.com/p/949cd2588e0)\n\n1.  [Writing a GraphQL TypeScript project w/ GraphQL-Modules and GraphQL-Code-Generator](https://medium.com/the-guild/writing-strict-typed-graphql-typescript-project-w-graphql-modules-and-graphql-code-generator-c22f6caa17b8)\n\n1.  [Authentication and Authorization in GraphQL (and how GraphQL-Modules can help)](https://medium.com/the-guild/authentication-and-authorization-in-graphql-and-how-graphql-modules-can-help-fadc1ee5b0c2)\n\n1.  [Authentication with AccountsJS & GraphQL Modules](https://medium.com/the-guild/authentication-with-accountsjs-graphql-modules-e0fb9799a9da)\n\n1.  [Manage Circular Imports Hell with GraphQL-Modules](https://medium.com/the-guild/manage-circular-imports-hell-with-graphql-modules-4b1611dee781)\n\n\n> _Follow us on [**GitHub**](https://github.com/Urigo/graphql-modules) and [**Medium**](https://medium.com/the-guild), we are planning to release many more posts in the next couple of weeks about what we‚Äôve learned using **GraphQL** in recent years._\n>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"949cd2588e0\",\"publishedDate\":1547219984967,\"url\":\"https://medium.com/the-guild/scoped-providers-in-graphql-modules-dependency-injection-system-949cd2588e0\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDo1NDo0OCswMTowMM4izqHX",
            "node": {
              "title": "Why did we implement our own Dependency Injection library for GraphQL-Modules?",
              "body": "## Why not Inversify/Angular/NestJS?\n\nWhen designing GraphQL Modules, we tried different approaches to encapsulate modules safely. We created a solution where you won‚Äôt need to use Dependency Injection when you start, but after you are getting to a certain scale, you can make use of our separate DI library to ease the separation and make the boundaries stricter, only at the point when it really makes sense and helps you. When you get to that point, DI helps you mostly for ease of mocking providers for testing and encapsulation for less error prone implementation.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*06GIprgOtbPjalU-.png?raw=true)\n\nIn the early stages of GraphQL-Modules, it used to have [**_Inversify_**](https://github.com/inversify/InversifyJS) internally for Dependency Injection in GraphQL-Modules. [**_Inversify_**](http://inversify.io/) is a platform-agnostic Dependency Injection library written in JavaScript. Unfortunately, **_Inversify_** didn‚Äôt fit our needs for modular DI (Dependency Injection) due to some critical reasons that we‚Äôll expand on this article.\n\n\nThat‚Äôs why, we implemented our own platform-agnostic Dependency Injection library called `_@graphql-modules/di_` which is independent from `_@graphql-modules/core_`, and it can be used by itself.\n\n\nIt supports factory, class and value providers that can have _Symbol_, _string_, _number_, _function_ and _object_ tokens in a `_provide_` definition, and it can address constructable classes, factory functions and constant values as injected values. It has some features that are similar to [Angular‚Äôs Dependency Injection](https://angular.io/guide/dependency-injection) that is mentioned in their documentation. In this article we‚Äôll explain the similarities and differences between those solutions.\n\n\n**Let‚Äôs start with the principles we wanted to have in our DI logic, and we will finish with the comparisons with Angular and NestJS.**\n\n\n# Encapsulation\n\nWhile we were still using **_Inversify_**, we used to have a single `GraphQLApp` top module. Regular GraphQL Modules cannot import each other, but can be imported by that `GraphQLApp` object. Also these modules didn‚Äôt have an **_encapsulation_**, because all the **_providers_**, **_schemas_** and **_resolvers_** were getting concatenated without any **_encapsulation_**. After that, we decided to provide complete Modular approach, and make everything module. Now Each module has its own injector, valid schema and context which is independent from its parent modules. Also, each module is constructed by using the imported modules‚Äô DI containers, schema contents and context builders.\n\n\nIf you want to know more about **_encapsulation_** see the blog post about it;\n\n\n[https://medium.com/p/ed1778b03600](https://medium.com/p/ed1778b03600 \"Why is True Modular Encapsulation So Important in Large-Scale GraphQL Projects?\nShort answer is for the changes in the future large modifications; let me give an example for the scenario you would‚Ä¶medium.com\")\n\nFor example, if you have a **_DatabaseModule_** in your application that has to be shared across the whole application, and it needs to take a custom provider that will be defined by the user. What you will do in those DI implementations is to create a provider by decorating it with a global scoped provider; then put it in **_ApplicationModule_**. However, this would **violate** the **encapsulation principle** of the modular approach.\n\n\nTo summarize; while your **_DatabaseModule_** is imported by other modules in the lower level and that module will use a provider in its parent. It mustn‚Äôt know what imports it.\n\n\nWe handle this in a different way in GraphQL Modules by passing configuration by obeying the encapsulation rule;\n\n```typescript\nconst AppModule = new GraphQLModule({\n    imports: ({ config: { connectionStuff }}) => { // getting the configuration in schema and DI container generation phase\n        DatabaseModule.forRoot({ // Define this configured module as the default instance inside AppModule\n            connectionStuff\n        }),\n        OtherModuleThatUsesDB,\n    },\n    configRequired: true, // makes schema and DI container prevent to be requested without a valid configuration\n})\n\nconst DatabaseModule = new GraphQLModule({\n    providers: [\n        SomeDbProvider\n    ],\n    configRequired: true, // makes this module prevent to be used without a valid configuration in any part of the application\n});\n\n@Injectable()\nexport class SomeDbProvider {\n    constructor(@ModuleConfig() config) { // get configuration into the provider\n        // some logic with the configuration\n    }\n}\n\nconst OtherModuleThatUsesDB = new GraphQLModule({\n    imports: [\n        DatabaseModule.forChild() // Use the configured DatabaseModule in the higher level, prevent this module to be imported without unconfigured DatabaseModule\n    ]\n})\n```\n\nThe three benefits we have with this type of DI and modular system;\n\n-   _AppModule_ is protected from an unsafe call without a valid configuration that is needed in the internal process (_DatabaseModule_); thanks to `configRequired` .\n\n-   _DatabaseModule_ is protected from an unsafe import without a valid configuration that is needed in the internal process (_SomeDbProvider_); thanks to `configRequired` again!\n\n-   _OtherModuleThatUsesDb_ is protected from an unsafe call or import without a definition of a well-configured _DatabaseModule._\n\n\n# **Hierarchy**\n\n\nWe also have another problem about the hierarchical approach of existing DI implementations. Let me give an example;\n\n-   **_A DI Container_** has **_FooProvider_**\n\n-   **_B DI Container_** has **_BarProvider_**\n\n-   **_C DI Container_** has **_BazProvider_**\n\n-   **_D DI Container_** has **_QuxProvider_**\n\n-   **A** imports **B**\n\n-   **B** imports **D**\n\n-   **B** imports **C**\n\n\nFor example the following case will happen in our DI;\n\n-   **_FooProvider_** cannot be injected inside **_B_** while **_BarProvider_** can be injected by **A**; because the injector of **_B_** only have its providers and **_D_**‚Äôs and **C**‚Äôs (**_BazProvider_** and **_QuxProvider_**).\n\n\nAs you can see in the comparison with **_Inversify_**, **_Inversify_** can attach only one child DI container in a parent DI container; and this wouldn‚Äôt fit our hierarchy-based modular approach. For example, you cannot make **B extend** both **D** and **C** by keeping **D** and **C** encapsulated. If you merge all of them into the one injector like Angular does, **D** can access **C**‚Äôs providers without importing **C**.\n\n\n# Scoped Providers\n\nIn contrast with client side application, your DI system wouldn‚Äôt need to have different scopes like Application Scope and Session Scope. In our implementation, we can define providers that have a life time during a single GraphQL Network Request and not the whole the application runtime; because some providers needs to belong in a single client. Unfortunately, you need to find tricky ways to manage scoped providers if you use existing DI libraries like **_Inversify_**.\n\n\n> ### In server-side applications, every client request has its own scope that we call \\`**session scope\\`**. We think this session scope should be able to have its own providers and DI logic outside of the application scope.\n>\n\nYou can read more about the different scopes that we have in GraphQL-Modules here:\n\n[https://medium.com/p/949cd2588e0/](https://medium.com/p/949cd2588e0/ \"Scoped Providers in GraphQL-Modules Dependency Injection System\nWe recently released a new version of GraphQL-Modules with a new feature called Scoped Providers in the dependency‚Ä¶medium.com\")\n\n# Comparisons with Other DI Implementations of frameworks\n\n## Comparison with Inversify\n\nTo provide _true encapsulation_; we should have an **_injector/container_** with multiple children, and these children must not know each other and even its parent. In **_Inversify_**, they have something like that which is called **_Hierarchical_** **_DI_**. In this feature of **_Inversify_**, the`parent` term can be misunderstood. because an injector seeks for its own providers then looks for the other injector that is being defined as `parent` in that feature. But, we need is more than that. We want to have multiple `parent` according to their logic.\n\n\n> ### Every module has its own injector together with its children‚Äôs injectors. So, every module can interact with its children‚Äôs providers with its own injector.\n\nYou can read more about _Hierarchy_ and _Encapsulation_ in the beginning of this article.\n\n\n## Comparison with Angular‚Äôs DI\n\nIn Angular, there is one injector that is shared across all the application while there are different encapsulated injectors belonging to each module in different scope.\n\n> ### Our Dependency Injection implementation is more strict in terms of encapsulation than Angular‚Äôs.\n\n```typescript\nimport { NgModule } from '@angular/core';\nimport { FooModule, FooProvider } from '@foo';\nimport { BarModule } from '@bar';\n\n@NgModule({\n    imports: [\n        FooModule,\n        BarModule\n    ]\n    providers: [\n        {\n            provide: FooProvider,\n            useClass: MyFooProvider\n        }\n    ]\n})\nexport class AppModule {}\n\n\n```\n\nThis is an example top module written in Angular. Let‚Äôs assume `FooProvider` originally implemented and defined inside `FooModule` and used by `BarModule` . When `FooProvider` token is replaced by `MyFooProvider` in `AppModule` scope, `BarModule` also uses our `MyFooProvider` inside its logic. This explicitly violates encapsulation in the modular approach, because Angular is supposed to send to `BarModule` `FooModule` ‚Äòs `FooProvider` implementation instead of the one defined outside of `BarModule` ; because it shouldn‚Äôt know what is defined in the higher level.\n\n\n```typescript\nimport { GraphQLModule } from '@graphql-modules/core';\nimport { FooModule, FooProvider } from '@foo';\nimport { BarModule } from '@bar';\n\nexport const AppModule = new GraphQLModule({\n    imports: [\n        FooModule,\n        BarModule\n    ]\n    providers: [\n        {\n            provide: FooProvider,\n            useClass: MyFooProvider\n        }\n    ]\n});\n\n\n\n```\n\nHowever, GraphQL-Modules will send to `BarModule` the correct `FooProvider` , because `BarModule` imports `FooModule` not `AppModule` . So, `MyFooProvider` will be sent if the current injector is inside `AppModule` scope.\n\n\nIn GraphQL-Modules, if A imports B and B imports C, A can access C‚Äôs scope. But, C cannot access the scopes of B and A. This allows us to create a safely built GraphQL Application and reduces the error prone. You can read more about _Hierarchy_ and _Encapsulation_ in the beginning of this article.\n\n\nAngular doesn‚Äôt care about that. it has a single injector for the all application. This may cause some problems for debugging on a large scale backend application.\n\n> ### That ability is not so important for Angular applications; because they are running on the browser, not on the server. But still you can notice the similar behavior to GraphQL-Modules DI‚Äôs if you load an Angular module lazily using router‚Äôs `loadChildren` property.\n>\n\nAnd Angular‚Äôs DI library doesn‚Äôt differentiate _Application and Session scopes_ because it doesn‚Äôt need that. An Angular application has a life time until `window` is terminated by closing it or refreshing page; the session and application runtime can be considered same in the client application. That‚Äôs why, our DI implementation is more complex than Angular‚Äôs as it need to handle multiple clients by running a single application. You can read more about [_Scoped Providers_](https://medium.com/@ardatan/949cd2588e0)  in the beginning of this article\n\n\n## Comparison with NestJS‚Äôs DI implementation\n\nNestJS is a server-side model-view-controller full fledged framework that has all the principles of MVC Backend framework. exposing a GraphQL API is only one of its various features. Our goal with GraphQL Modules was to create a set of tools and libraries that answer needs for the GraphQL ecosystem, and can be (and should be) used by NestJS users as well.\n\n> ### The principles and approaches we‚Äôre trying to apply in GraphQL Modules is not only for Dependency Injection but also for GraphQL Schemas and Context.\n\nIn comparison to Nest‚Äôs goals, GraphQL-Modules is a platform agnostic library that can be used even with the plain `graphqljs` package **without a server**; because it was designed to work exactly same in all GraphQL Server platforms such as Apollo, Yoga, graphql-express etc. For example, you can **use _Apollo_‚Äôs data sources with graphql-express**; because GraphQL Modules **passes its own cache mechanism into the dataloaders thanks to our independent DI logic**.\n\n\n> ### The result of a GraphQLModule is a context builder and a schema while NestJS‚Äôs GraphQLModule is a NestJS module that exposes an API using Apollo.\n\nNestJS has its own dependency injection system which is similar to Angular‚Äôs but **more strict**; you can define both global (not by default like Angular) and encapsulated providers at the same time. We preferred not to have global providers like Angular (you can see how it works above in the Angular comparison); because we consider it can be more **error prone** and it has to be done by **passing configuration**. You can read more with an example about passing configuration and keeping safe boundaries between your modules in the [_Encapsulation_](https://medium.com/the-guild/why-is-true-modular-encapsulation-so-important-in-large-scale-graphql-projects-ed1778b03600) article.\n\n\nAlso, NestJS DI system doesn‚Äôt share the important feature of defining providers that has the life-time of the client request (we call it **session scope**). We think a backend system would need to differentiate DI containers according to these different scopes. You can read more about it in [_Scoped Providers_](https://medium.com/@ardatan/949cd2588e0) part of this article above.\n\n\n# Working together\n\nWe wanted to share the principles behind our implementation in order to get more background to our community and get feedback from other library authors.\n\nThat is also one of the reasons we created our DI library as a separate library, not only so it would be optional to our users, but also to potentially share that implementation with other libraries like NestJS and Inversify for example.\n\n# All posts about GraphQL Modules\n\n1.  [GraphQL Modules ‚Äî Feature based GraphQL Modules at scale](https://medium.com/the-guild/graphql-modules-feature-based-graphql-modules-at-scale-2d7b2b0da6da)\n\n1.  [Why is True Modular Encapsulation So Important in Large-Scale GraphQL Projects?](https://medium.com/the-guild/why-is-true-modular-encapsulation-so-important-in-large-scale-graphql-projects-ed1778b03600)\n\n1.  [Why did we implement our own Dependency Injection library for GraphQL-Modules?](https://medium.com/p/f25a234a9762)\n\n1.  [Scoped Providers in GraphQL-Modules Dependency Injection](https://medium.com/p/949cd2588e0)\n\n1.  [Writing a GraphQL TypeScript project w/ GraphQL-Modules and GraphQL-Code-Generator](https://medium.com/the-guild/writing-strict-typed-graphql-typescript-project-w-graphql-modules-and-graphql-code-generator-c22f6caa17b8)\n\n1.  [Authentication and Authorization in GraphQL (and how GraphQL-Modules can help)](https://medium.com/the-guild/authentication-and-authorization-in-graphql-and-how-graphql-modules-can-help-fadc1ee5b0c2)\n\n1.  [Authentication with AccountsJS & GraphQL Modules](https://medium.com/the-guild/authentication-with-accountsjs-graphql-modules-e0fb9799a9da)\n\n1.  [Manage Circular Imports Hell with GraphQL-Modules](https://medium.com/the-guild/manage-circular-imports-hell-with-graphql-modules-4b1611dee781)\n\n\n> Follow us on [**GitHub**](https://github.com/Urigo/graphql-modules) and [**Medium**](https://medium.com/the-guild), we are planning to release many more posts in the next couple of weeks about what we‚Äôve learned using **GraphQL** in recent years.\n>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"f25a234a9762\",\"publishedDate\":1547219980544,\"url\":\"https://medium.com/the-guild/why-did-we-implement-our-own-dependency-injection-library-for-graphql-modules-f25a234a9762\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDo1NDo0MCswMTowMM4izqGV",
            "node": {
              "title": "Why is True Modular Encapsulation So Important in Large-Scale GraphQL Projects? ‚Äî GraphQL Modules is your savior!",
              "body": "![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*F9zPdgtNF9oL3IG0eL4NTg.png?raw=true \"Encapsulation matters in large-scale projects\")\n\n**TL;DR**: If you are writing a large-scale project, it‚Äôs necessary to understand the relations between your pieces of code, and how they effect each other. Otherwise, it might be difficult to deal with changes later.\n\n\nWhile developing a **large-scale project**, removing, changing and modifying parts of the project can become a very time consuming and risky task, because understanding the full side-effects of those changes is very hard.\n\n\nIn [**GraphQL-Modules**](https://graphql-modules.com/), you can declare your modules in a feature-based structure, with clear enforced boundaries and avoid unexpected side-effects during development.\n\n\nEach module can declare it‚Äôs own scope of the complete schema:\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*ZtOhO2PCRh6FDQanTk_yug.png?raw=true \"Every module has its own schema, context and DI container. Here you can see AuthModule is appended to UserModule. But, other modules don‚Äôt import AuthModule. So, they cannot access directly AuthModule DI container or context.\")\n\nEach module has its own **_schema_**, **_context_**, **_typeDefs_**, **_resolvers,_** and business-logic and each module is encapsulated, which limits the module‚Äôs access to only its own parts of the schema.\n\n\n**So, what‚Äôs the real benefit of this?**\n\n\nLet‚Äôs assume you have an authentication module;\n\nAfter a while, you decided to use **_AccountsJS_** in your **_GraphQL_** project which has completely different implementation than the existing one.\n\n\nThis can be a risky change, because you‚Äôre afraid of breaking a lot of things and you can‚Äôt be sure about the all the places in your code that uses values affected by the authentication module, for example the global context.\n\nWith GraphQL-Modules‚Äôs approach of encapsulation, even the context is completely encapsulated, so every module that uses your existing **_AuthenticationModule_**‚Äôs **_context_** in defined on the`imports` of the dependent modules, and its interface is already extended by **_AuthenticationModule_**‚Äôs **_context_** if you‚Äôre using _TypeScript_. When it is removed, you will notice that change on compile-time immediately.\n\n\nLet‚Äôs take a look at some code, to show how GraphQL Modules makes you create those dependencies explicitly.\n\n`AppModule` is our top Application Module;\n\n\n```typescript\nimport { GraphQLModule } from '@graphql-modules/core';\nimport { AuthenticationModule } from './modules/auth.module';\n\nconst AppModule = new GraphQLModule({\n    imports: [\n        AuthenticationModule, //this module has `user` in its context\n        SomeImportantModuleThatUsesAuthenticatedContext,\n        ...\n    ],\n});\n\n```\n\nAnd there is another module that tries to use `AuthenticationModule`‚Äôs context, but it doesn‚Äôt import `AuthenticationModule`. In this case, it is not possible to get anything from `AuthenticationModule` in the resolvers, because it is not imported. The following module doesn‚Äôt know anything about `AuthenticationModule`.\n\n\n```typescript\nconst SomeImportantModuleThatUsesAuthenticatedContext = new GraphQLModule({\n    typeDefs: SOME_TYPE_DEFS_HERE\n    imports: [\n        ...,\n        // This module doesn't import AuthenticationModule\n        ...\n    ],\n    resolvers: {\n        ...,\n        Query: {\n            getUser: (root, args, context) => {\n                return context.user; // Oops! Undefined!\n            }\n        }\n        ...\n    }\n});\n```\n\nTo fix this, we need to import `AuthenticationModule` into that ‚Äòimportant‚Äô module to make it able to access `AuthenticationModule`‚Äôs context like below;\n\n\n```typescript\nconst SomeImportantModuleThatUsesAuthenticatedContext = new GraphQLModule({\n    typeDefs: SOME_TYPE_DEFS_HERE\n    imports: [\n        ...,\n        // This module imports AuthenticationModule\n        AuthenticationModule,\n        ...\n    ],\n    resolvers: {\n        ...,\n        Query: {\n            getUser: (root, args, context) => {\n                return context.user; // Yes, we have that user HERE!\n            }\n        }\n        ...,\n    }\n});\n```\n\nSo, these examples above show us that the encapsulation can be very important in the long term of our project development.\n\n**We think modular approach is not just merging schemas and concatenate context factory functions to each other.**\n\n\nHaving a tool that knows how to **encapsulate modules** and **force this policy**, makes it much easier to write modular schema, and later, even reuse existing modules and share them across multiple projects.\n\n\n# All posts about GraphQL Modules\n\n1.  [GraphQL Modules ‚Äî Feature based GraphQL Modules at scale](https://medium.com/the-guild/graphql-modules-feature-based-graphql-modules-at-scale-2d7b2b0da6da)\n\n1.  [Why is True Modular Encapsulation So Important in Large-Scale GraphQL Projects?](https://medium.com/the-guild/why-is-true-modular-encapsulation-so-important-in-large-scale-graphql-projects-ed1778b03600)\n\n1.  [Why did we implement our own Dependency Injection library for GraphQL-Modules?](https://medium.com/p/f25a234a9762)\n\n1.  [Scoped Providers in GraphQL-Modules Dependency Injection](https://medium.com/p/949cd2588e0)\n\n1.  [Writing a GraphQL TypeScript project w/ GraphQL-Modules and GraphQL-Code-Generator](https://medium.com/the-guild/writing-strict-typed-graphql-typescript-project-w-graphql-modules-and-graphql-code-generator-c22f6caa17b8)\n\n1.  [Authentication and Authorization in GraphQL (and how GraphQL-Modules can help)](https://medium.com/the-guild/authentication-and-authorization-in-graphql-and-how-graphql-modules-can-help-fadc1ee5b0c2)\n\n1.  [Authentication with AccountsJS & GraphQL Modules](https://medium.com/the-guild/authentication-with-accountsjs-graphql-modules-e0fb9799a9da)\n\n1.  [Manage Circular Imports Hell with GraphQL-Modules](https://medium.com/the-guild/manage-circular-imports-hell-with-graphql-modules-4b1611dee781)\n\n\n> _Follow us on [**GitHub**](https://github.com/Urigo/graphql-modules) and [**Medium**](https://medium.com/the-guild), we are planning to release many more posts in the next couple of weeks about what we‚Äôve learned using **GraphQL** in recent years._\n>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"ed1778b03600\",\"publishedDate\":1546861733955,\"url\":\"https://medium.com/the-guild/why-is-true-modular-encapsulation-so-important-in-large-scale-graphql-projects-ed1778b03600\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDo1NDoyOCswMTowMM4izqEx",
            "node": {
              "title": "Writing a GraphQL TypeScript project w/ GraphQL-Modules and GraphQL-Code-Generator",
              "body": "![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*dt-D8lmQyIGZ-e5993wn0Q.png?raw=true \"GraphQL Code Generator will boost your DX\")\n\nLast year we‚Äôve released **[GraphQL-Modules](https://graphql-modules.com/)** ‚Äî which applies modular approach to large scale, GraphQL-based applications.\n\n\nWe‚Äôve also released a new version of [GraphQL Code Generator](https://graphql-code-generator.com) which generates server-side typings and signatures for resolvers from GraphQL Schemas.\n\n\nThose are two separate projects, but because we use both in production across many different applications, we wanted to write about the benefits of the tight integration of those projects and how it provides us with great development experience while implementing our projects in TypeScript.\n\nGraphQL Code Generator can take a JS/TS export from GraphQL-Modules to generate server-side typings (or anything else that its [plugins can generate](https://graphql-code-generator.com/docs/plugins/)). So, let‚Äôs export typeDefs without any business logic that includes resolvers, DI, providers etc‚Ä¶\n\n\nYou can create a `schema.ts` file to expose `typeDefs` to GraphQL Code Generator:\n\n\n```typescript\nimport { AppModule } from './modules/app';\n\nexport default AppModule.typeDefs;\n\n// If your module needs a configuration\n\nexport default AppModule.forRoot({ ...dummyConfiguration }).typeDefs;\n\n```\n\nCreate a `codegen.yml` config file, including `schema.ts` as a schema source, and generate [common](https://graphql-code-generator.com/docs/plugins/typescript-common) and [server](https://graphql-code-generator.com/docs/plugins/typescript-server) typings for TypeScript. We use `transpile-only` to prevent errors related to TypeScript on typing generation phase to let `ts-node` handle this on running the actual application.\n\n\n```yaml\noverwrite: true\nschema: ./src/schema.ts\nrequire:\n  - ts-node/register/transpile-only\ngenerates:\n  ./src/generated-models.ts:\n    plugins:\n      - typescript\n      - typescript-resolvers\n    config:\n      contextType: @graphql-modules/core#ModuleContext\n\n```\n\nWe can add a script to `package.json` to run:\n\n\n```json5\n{\n  //...\n \"scripts\": {\n   //...\n    \"generate\": \"gql-gen\",\n    // You can use nodemon to watch changes on graphql files\n    \"generate:watch\": \"nodemon --exec yarn generate -e graphql\",\n   //...\n //...\n}\n```\n\nThen, we can use these typings in our project. This example shows a resolvers handler that implements resolvers for `Query` type with generated types.\n\n\n```typescript\nimport { UsersProvider } from '../providers/users.provider';\nimport { IResolvers } from '../../generated-models';\n\nexport default {\n  Query: {\n    // all parameters and return value are typed\n    users: (root, args, context, info) => context.injector.get(UsersProvider).getUsers(args)\n  }\n} as IResolvers;\n\n```\n\nAt the end, we have a strictly-typed backend project, based of separate feature modules, and each of those modules uses GraphQL and TypeScript.\n\nYou can check our working example that is created by using this approach; <https://github.com/darkbasic/graphql-modules-seed>\n\n\n# All posts about GraphQL Modules\n\n1.  [GraphQL Modules ‚Äî Feature based GraphQL Modules at scale](https://medium.com/the-guild/graphql-modules-feature-based-graphql-modules-at-scale-2d7b2b0da6da)\n\n1.  [Why is True Modular Encapsulation So Important in Large-Scale GraphQL Projects?](https://medium.com/the-guild/why-is-true-modular-encapsulation-so-important-in-large-scale-graphql-projects-ed1778b03600)\n\n1.  [Why did we implement our own Dependency Injection library for GraphQL-Modules?](https://medium.com/p/f25a234a9762)\n\n1.  [Scoped Providers in GraphQL-Modules Dependency Injection](https://medium.com/p/949cd2588e0)\n\n1.  [Writing a GraphQL TypeScript project w/ GraphQL-Modules and GraphQL-Code-Generator](https://medium.com/the-guild/writing-strict-typed-graphql-typescript-project-w-graphql-modules-and-graphql-code-generator-c22f6caa17b8)\n\n1.  [Authentication and Authorization in GraphQL (and how GraphQL-Modules can help)](https://medium.com/the-guild/authentication-and-authorization-in-graphql-and-how-graphql-modules-can-help-fadc1ee5b0c2)\n\n1.  [Authentication with AccountsJS & GraphQL Modules](https://medium.com/the-guild/authentication-with-accountsjs-graphql-modules-e0fb9799a9da)\n\n1.  [Manage Circular Imports Hell with GraphQL-Modules](https://medium.com/the-guild/manage-circular-imports-hell-with-graphql-modules-4b1611dee781)\n\n\n> _Follow us on [**GitHub**](https://github.com/Urigo/graphql-modules) and [**Medium**](https://medium.com/the-guild), we are planning to release many more posts in the next couple of weeks about what we‚Äôve learned using **GraphQL** in recent years._\n>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"c22f6caa17b8\",\"publishedDate\":1543902834786,\"url\":\"https://medium.com/the-guild/writing-strict-typed-graphql-typescript-project-w-graphql-modules-and-graphql-code-generator-c22f6caa17b8\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDo1NDoxNiswMTowMM4izqDJ",
            "node": {
              "title": "Authentication with AccountsJS & GraphQL Modules",
              "body": "![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*emrpS_BYaLltTGadD6GaIw.png?raw=true \"AccountsJS just started to use GraphQL-Modules internally\")\n\nWhen starting a backend project, two of the biggest concerns will usually be the right structure of the project and authentication. If you could skip thinking and planning about these two, starting a new backend project can be much easier.\n\n> If you haven‚Äôt checked out our [blog post about authentication and authorization in GraphQL Modules](https://medium.com/the-guild/authentication-and-authorization-in-graphql-and-how-graphql-modules-can-help-fadc1ee5b0c2), please read that before!\n>\n\nInternally, we use [GraphQL-Modules](https://graphql-modules.com/) and [AccountsJS](https://github.com/accounts-js/accounts) to help us with those two decisions, GraphQL-Modules helps us solve our architectural problems in modular, schema-first approaches with the power of GraphQL and AccountsJS helps us create our authentication solutions by providing a simple API together with client and server libraries that saves us a lot of the ground work around authentication.\n\n\nIf you haven‚Äôt heard about [AccountsJS](https://github.com/accounts-js/accounts) before, it is a set of libraries to provide a full-stack authentication and accounts-management solutions for Javascript.\n\n\nIt is really customizable; so you can write any plugins for your own authentication methods or use the already existing email-password or the Facebook and Twitter OAuth integration packages.\n\nAccountsJS has connector libraries for MongoDB and Redis, but you can write your own database handler by implementing a simple interface.\n\nAccounts JS provide a ready to use GraphQL API if you install their GraphQL library and **we are happy to announce that the GraphQL library is now internally built using GraphQL-Modules**!\n\n\nIt doesn‚Äôt affect people who are not using GraphQL Modules, but it helps the maintainers of AccountsJS and simplifies the integration for GraphQL-Modules-based projects.\n\n# How To Implement Server-Side using AccountsJS, GraphQL-Modules and Apollo-Server\n\nFirst install required dependencies from npm or yarn;\n\n```\nyarn add mongodb @accounts/server @accounts/password @accounts/database-manager @accounts/mongo @accounts/graphql-api @graphql-modules/core apollo-server graphql-import-node\n```\n\nLet‚Äôs assume that we‚Äôre using MongoDB as our database, password-based authentication and ApolloServer;\n\n```typescript\nimport 'graphql-import-node';\nimport { ApolloServer } from 'apollo-server';\nimport { MongoClient, ObjectId } from 'mongodb';\nimport { AccountsServer } from '@accounts/server';\nimport { AccountsPassword } from '@accounts/password';\nimport { DatabaseManager } from '@accounts/database-manager';\nimport MongoDBInterface from '@accounts/mongo';\nimport { AccountsModule } from '@accounts/graphql-api';\nimport * as typeDefs from './typeDefs.graphql';\nimport { resolvers } from './resolvers';\n\nconst PORT = process.env['MONGO_URI'] || 4000;\nconst MONGO_URI = process.env['MONGO_URI'] || 'mongodb://localhost:27017/myDb';\nconst TOKEN_SECRET = process.env['TOKEN_SECRET'] || 'myTokenSecret'; \n\nasync function main() {\n    const mongoClient = await MongoClient.connect(MONGO_URI, {\n        useNewUrlParser: true,\n        native_parser: true\n    });\n    const db = mongoClient.db();\n    const userStorage = new MongoDBInterface(db, {\n        convertUserIdToMongoObjectId: false\n    });\n    // Create database manager (create user, find users, sessions etc) for accounts-js\n    const accountsDb = new DatabaseManager({\n        sessionStorage: userStorage,\n        userStorage,\n    });\n        // Create accounts server that holds a lower level of all accounts operations\n    const accountsServer = new AccountsServer(\n            { \n                db: accountsDb, \n                tokenSecret: TOKEN_SECRET \n            },\n            {\n                password: new AccountsPassword(),\n            }\n        );\n    const { schema } = new GraphQLModule({\n      typeDefs,\n      resolvers,\n      imports: [\n        AccountsModule.forRoot({\n          accountsServer\n        });\n      ],\n      providers: [\n        {\n          provide: Db,\n          useValue: db // Use MongoDB instance inside DI\n        }\n      ]\n    });\n    const apolloServer = new ApolloServer({\n        schema,\n        context: session => session,\n        introspection: true\n    });\n    const { url } = await apolloServer.listen(PORT);\n    console.log(`Server listening: ${url}`);\n}\n\nmain();\n```\n\nAnd we can extend User type with custom fields in our schema, and add a mutation which is restricted to authenticated clients.\n\n```graphql\ntype Query {\n  allPosts: [Post]\n}\n\ntype Mutation {\n  addPost(title: String, content: String): ID @auth\n}\n\ntype User {\n  posts: [Post]\n}\n\ntype Post {\n  id: ID\n  title: String\n  content: String\n  author: User\n}\n```\n\nFinally let‚Äôs define some resolvers for it;\n\n```typescript\nexport const resolvers = {\n  User: {\n    posts: ({ _id }, args, { injector }) => {\n      const db = injector.get(Db);\n      const Posts = db.collection('posts');\n      return Posts.find({ userId: _id }).toArray(); \n    }\n  },\n  Post: {\n    id: ({ _id }) => _id,\n    author: ({ userId }, args, { injector }) => {\n       const accountsServer = injector.get(AccountsServer);\n       return accountsServer.findUserById(userId);\n    }\n  },\n  Query: {\n    allPosts: (root, args, { injector }) => {\n      const db = injector.get(Db);\n      const Posts = db.collection('posts');\n      return Posts.find().toArray();\n    }\n  },\n  Mutation: {\n    addPost: (root, { title, content }, { injector, userId }: ModuleContext<AccountsContext>) => {\n      const db = injector.get(Db);\n      const Posts = db.collection('posts');\n      const { insertedId } = Posts.insertOne({ title, content, userId });\n      return insertedId;\n    }\n  }\n  \n```\n\nWhen you print the whole app‚Äôs schema, you would see something like above;\n\n```typescript\ntype TwoFactorSecretKey {\n  ascii: String\n  base32: String\n  hex: String\n  qr_code_ascii: String\n  qr_code_hex: String\n  qr_code_base32: String\n  google_auth_qr: String\n  otpauth_url: String\n}\n\ninput TwoFactorSecretKeyInput {\n  ascii: String\n  base32: String\n  hex: String\n  qr_code_ascii: String\n  qr_code_hex: String\n  qr_code_base32: String\n  google_auth_qr: String\n  otpauth_url: String\n}\n\ninput CreateUserInput {\n  username: String\n  email: String\n  password: String\n}\n\ntype Query {\n  twoFactorSecret: TwoFactorSecretKey\n  getUser: User\n  allPosts: [Post]\n}\n\ntype Mutation {\n  createUser(user: CreateUserInput!): ID\n  verifyEmail(token: String!): Boolean\n  resetPassword(token: String!, newPassword: String!): Boolean\n  sendVerificationEmail(email: String!): Boolean\n  sendResetPasswordEmail(email: String!): Boolean\n  changePassword(oldPassword: String!, newPassword: String!): Boolean\n  twoFactorSet(secret: TwoFactorSecretKeyInput!, code: String!): Boolean\n  twoFactorUnset(code: String!): Boolean\n  impersonate(accessToken: String!, username: String!): ImpersonateReturn\n  refreshTokens(accessToken: String!, refreshToken: String!): LoginResult\n  logout: Boolean\n  authenticate(serviceName: String!, params: AuthenticateParamsInput!): LoginResult\n  addPost(title: String, content: String): Post\n}\n\ntype Tokens {\n  refreshToken: String\n  accessToken: String\n}\n\ntype LoginResult {\n  sessionId: String\n  tokens: Tokens\n}\n\ntype ImpersonateReturn {\n  authorized: Boolean\n  tokens: Tokens\n  user: User\n}\n\ntype EmailRecord {\n  address: String\n  verified: Boolean\n}\n\ntype User {\n  id: ID!\n  emails: [EmailRecord!]\n  username: String\n  posts: [Post]\n}\n\ninput UserInput {\n  id: ID\n  email: String\n  username: String\n}\n\ninput AuthenticateParamsInput {\n  access_token: String\n  access_token_secret: String\n  provider: String\n  password: String\n  user: UserInput\n  code: String\n}\ntype Post {\n  id: ID\n  title: String\n  content: String\n  author: User\n}\n\n```\n\n# How To Implement Client-Side using AccountsJS, React and Apollo-Client\n\nNow we can create a simple frontend app by using Apollo-Client and AccountsJS client for this backend app. The example below shows some example code that works on these two.\n\n```tsx\nimport React, { Component } from 'react';\nimport { AccountsClient } from '@accounts/client';\nimport { AccountsClientPassword } from '@accounts/client-password';\nimport GraphQLClient from '@accounts/graphql-client';\nimport ApolloClient from 'apollo-boost';\nimport { Query, Mutation, ApolloProvider } from 'react-apollo';\nimport gql from 'graphql-tag';\nimport ReactDOM from 'react-dom';\n\nconst apolloClient = new ApolloClient({\n    request: async operation => {\n        const tokens = await accountsClient.getTokens();\n        if (tokens) {\n            operation.setContext({\n                headers: {\n                    'accounts-access-token': tokens.accessToken\n                }\n            });\n        }\n    },\n    uri: 'http://localhost:4000/graphql',\n});\n\nconst accountsGraphQL = new GraphQLClient({ graphQLClient: apolloClient });\nconst accountsClient = new AccountsClient({}, accountsGraphQL);\nconst accountsPassword = new AccountsClientPassword(accountsClient);\n\nconst ALL_POSTS_QUERY = gql`\n    query AllPosts {\n        allPosts{\n            id\n            title\n            content\n            author {\n                username\n            }\n        }\n    }\n`;\n\nconst ADD_POST_MUTATION = gql`\n    mutation AddPost($title: String, $content: String) {\n        addPost(title: $title, content: $content)\n    }\n`;\n\nclass App extends Component {\n    state = {\n        credentials: {\n            username: '',\n            password: ''\n        },\n        newPost: {\n            title: '',\n            content: ''\n        },\n        user: null\n    }\n    componentDidMount() {\n        return this.updateUserState();\n    }\n    async updateUserState() {\n        const tokens = await accountsClient.refreshSession();\n        if (tokens) {\n            const user = await accountsGraphQL.getUser();\n            await this.setState({ user });\n        }\n    }\n    renderAllPosts() {\n        return (\n            <Query query={ALL_POSTS_QUERY}>\n                {({ data, loading, error }) => {\n                    if (loading) {\n                        return <p>Loading...</p>;\n                    }\n                    if (error) {\n                        return <p>Error: {error}</p>\n                    }\n                    return data.allPosts.map((post: any) => (\n                        <li>\n                            <p>\n                                {post.title}\n                            </p>\n                            <p>\n                                {post.content}\n                            </p>\n                            <p>\n                                Author: {post.author.username}\n                            </p>\n                        </li>\n                    ))\n                }}\n            </Query>\n        );\n    }\n    renderLoginRegister() {\n        return (\n            <fieldset>\n                <legend>\n                    Login - Register\n                </legend>\n                <form>\n                    <p>\n                        <label>\n                            Username:\n                          <input value={this.state.credentials.username} onChange={e => this.setState({\n                                credentials: {\n                                    ...this.state.credentials,\n                                    username: e.target.value\n                                }\n                            })} />\n                        </label>\n                    </p>\n                    <p>\n                        <label>\n                            Password:\n                          <input value={this.state.credentials.password} onChange={e => this.setState({\n                                credentials: {\n                                    ...this.state.credentials,\n                                    password: e.target.value\n                                }\n                            })} />\n                        </label>\n                    </p>\n                    <p>\n                        <button onClick={e => {\n                            e.preventDefault();\n                            accountsPassword.login({\n                                password: this.state.credentials.password,\n                                user: {\n                                    username: this.state.credentials.username,\n                                },\n                            }).then(() => this.updateUserState());\n                        }}>\n                            Login\n                      </button>\n                    </p>\n                    <p>\n                        <button onClick={e => {\n                            e.preventDefault();\n                            accountsPassword.createUser({\n                                password: this.state.credentials.password,\n                                username: this.state.credentials.username,\n                            }).then(() => {\n                                alert('Please login with your new credentials');\n                                this.setState({\n                                    credentials: {\n                                        username: '',\n                                        password: '',\n                                    }\n                                });\n                            });\n                        }}>\n                            Register\n                      </button>\n                    </p>\n                </form>\n            </fieldset>\n        );\n    }\n    renderAddPost() {\n        return (\n            <Mutation mutation={ADD_POST_MUTATION}>\n                {addPost => {\n                    return (\n                        <fieldset>\n                            <legend>Add Post</legend>\n                            <form>\n                                <p>\n                                    <label>\n                                        Title:\n                                  <input value={this.state.newPost.title} onChange={e => this.setState({\n                                            newPost: {\n                                                ...this.state.newPost,\n                                                title: e.target.value\n                                            }\n                                        })} />\n                                    </label>\n                                </p>\n                                <p>\n                                    <label>\n                                        Content:\n                                  <input value={this.state.newPost.content} onChange={e => this.setState({\n                                            newPost: {\n                                                ...this.state.newPost,\n                                                content: e.target.value\n                                            }\n                                        })} />\n                                    </label>\n                                </p>\n                                <p>\n                                    <input type='submit' onClick={e => {\n                                        e.preventDefault();\n                                        addPost({\n                                            variables: {\n                                                title: this.state.newPost.title,\n                                                content: this.state.newPost.content\n                                            }\n                                        })\n                                    }} />\n                                </p>\n                            </form>\n                        </fieldset>\n                    );\n                }}\n            </Mutation>\n        );\n    }\n    render() {\n        return (\n            <div>\n                <h2>All Posts</h2>\n                {this.renderAllPosts()}\n                {!this.state.user && this.renderLoginRegister()}\n                {this.state.user && this.renderAddPost()}\n            </div>\n        );\n    }\n}\n\nReactDOM.render(\n    <ApolloProvider client={apolloClient}>\n        <App />\n    </ApolloProvider>,\n    document.getElementById('root')\n);\n```\n\nAs you can see from the example, it can be really easy to create an application that has authentication in modular and future proof approach.\n\nYou can learn more about AccountsJS from the [docs](https://accounts-js.netlify.com/docs/getting-started.html) of this great library for more features such as Two-Factor Authentication and Facebook and Twitter integration using OAuth.\n\n\nAlso you can learn more about GraphQL-Modules on the [website](https://graphql-modules.com/) and see how you can add GraphQL Modules features into your system in a gradual and selective way.\n\n\nIf you want strict types based on GraphQL Schema, for each module, GraphQL Code Generator has built-in support for GraphQL-Modules based projects. [**See the docs**](https://github.com/Urigo/graphql-modules#graphql-code-generator-integration)  for more details.\n\n\nYou can check out our example about this integration; [**https://github.com/ardatan/graphql-modules-accountsjs-boilerplate**](https://github.com/ardatan/graphql-modules-accountsjs-boilerplate)\n\n\n# All posts about GraphQL Modules\n\n1.  [GraphQL Modules ‚Äî Feature based GraphQL Modules at scale](https://medium.com/the-guild/graphql-modules-feature-based-graphql-modules-at-scale-2d7b2b0da6da)\n\n1.  [Why is True Modular Encapsulation So Important in Large-Scale GraphQL Projects?](https://medium.com/the-guild/why-is-true-modular-encapsulation-so-important-in-large-scale-graphql-projects-ed1778b03600)\n\n1.  [Why did we implement our own Dependency Injection library for GraphQL-Modules?](https://medium.com/p/f25a234a9762)\n\n1.  [Scoped Providers in GraphQL-Modules Dependency Injection](https://medium.com/p/949cd2588e0)\n\n1.  [Writing a GraphQL TypeScript project w/ GraphQL-Modules and GraphQL-Code-Generator](https://medium.com/the-guild/writing-strict-typed-graphql-typescript-project-w-graphql-modules-and-graphql-code-generator-c22f6caa17b8)\n\n1.  [Authentication and Authorization in GraphQL (and how GraphQL-Modules can help)](https://medium.com/the-guild/authentication-and-authorization-in-graphql-and-how-graphql-modules-can-help-fadc1ee5b0c2)\n\n1.  [Authentication with AccountsJS & GraphQL Modules](https://medium.com/the-guild/authentication-with-accountsjs-graphql-modules-e0fb9799a9da)\n\n1.  [Manage Circular Imports Hell with GraphQL-Modules](https://medium.com/the-guild/manage-circular-imports-hell-with-graphql-modules-4b1611dee781)\n\n\n> _Follow us on [**GitHub**](https://github.com/Urigo/graphql-modules) and [**Medium**](https://medium.com/the-guild), we are planning to release many more posts in the next couple of weeks about what we‚Äôve learned using **GraphQL** in recent years._\n>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"e0fb9799a9da\",\"publishedDate\":1542380881464,\"url\":\"https://medium.com/the-guild/authentication-with-accountsjs-graphql-modules-e0fb9799a9da\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDo1NDowNSswMTowMM4izqB_",
            "node": {
              "title": "GraphQL Code Generator for Typescript React Apollo",
              "body": "![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*e9-8DMsw80IYIaK1cf3odg.png?raw=true \"GraphQL Code Generator ‚Äî React Apollo Typescript template\")\n\n[**GraphQL Code Generator**](https://github.com/dotansimha/graphql-code-generator/)  is a template based generator that lets you generate anything out of your GraphQL schemas and queries.\n\n\nSo we‚Äôve created a new template that generates **React Apollo**‚Äôs **_Query_**, **_Mutation_** and **_Subscription_** components, as well as **_HOC_** components, all completely typed by **_TypeScript_**, so you won‚Äôt have to do that work manually!\n\n\n# Introducing a code generator for React Apollo\n\nWhether you use the new **React Apollo API** or you prefer to use **HOC**, there is really no need to write those wrapper components again and again!\n\n\nBased on a GraphQL static schema and a GraphQL query, the [**GraphQL Codegen - Typescript React Apollo Template**](https://github.com/dotansimha/graphql-code-generator/tree/master/packages/templates/typescript-react-apollo) will generate a ready to use, fully typed components. All you need to do is to write your query, mutation or subscription and just use those components in your application.\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*tEGsG1VbNTHCBfAo?raw=true)\n\nUsing **_React_**, **_TypeScript_** and **_GraphQL_** in a coordinated way, gives us new level of simplicity and power for our developer experience:\n\n\n-   **Less code to write** ‚Äî no need to create a network call, no need to create Typescript typings, no need to create a dedicated React Component\n\n-   **Strongly typed out of the box** ‚Äî all types are being generated, no need to write any Typescript definitions and struggle to keep them updated\n\n-   **Full developer experience of tools and IDEs** ‚Äî development time autocomplete and error checking, not only across your frontend app but also with your API teams!\n\n\n# Play with it\n\nWe prepared an example of how to use those auto generated components, [it‚Äôs available on StackBlitz](https://stackblitz.com/edit/react-apollo-code-generator-example).\n\n\n[https://stackblitz.com/edit/react-apollo-code-generator-example?embed=1&file=List.tsx](https://stackblitz.com/edit/react-apollo-code-generator-example?embed=1&file=List.tsx \"react-apollo-code-generator-example - StackBlitz Auto generated react-apollo components GraphiQL: https\\://launchpad.graphql.com/1jzxrj179\")\n\nAnd another example on exist on this repository:\n\n[https://github.com/dotansimha/graphql-code-generator/tree/master/examples/typescript-react-apollo](https://github.com/dotansimha/graphql-code-generator/tree/master/examples/typescript-react-apollo \"dotansimha/graphql-code-generator\ngraphql-code-generator - GraphQL code generator with flexible support for custom templatesgithub.com\")\n\n# Start using it\n\nAll you need to do to use React Apollo template is to install two packages:\n\n```\nnpm install graphql-code-generator graphql-codegen-typescript-react-apollo-template --save-dev\n```\n\nNow let‚Äôs set up a npm script to run gql-gen command:\n\n```\ngql-gen --schema https://fakerql.com/graphql --template graphql-codegen-typescript-react-apollo-template --out ./src/generated-models.tsx \"./src/**/*.graphql\"\n```\n\nIt might seem like a lot but lets split it into smaller pieces and explain each one of them it will make things easier.\n\n-   **‚Äî schema** ‚Äî path of a file with schema or an URL\n\n-   **‚Äî template** ‚Äî name of a template, equals name of a package\n\n-   **‚Äî out** ‚Äî path of a file for an output\n\n-   **glob** based on which GraphQL Codegen will try to find documents\n\n\nThen, define a `.graphql` file with a document that you‚Äôd like to use in a component:\n\n\n```\nquery UserQuery($id: ID!) {\n    User(id: $id) {\n        id\n        firstName\n        lastName\n        email\n        avatar\n    }\n}\n```\n\nNext, you need to run GraphQL Code Generator to generate Typescript types and React components.\n\nThen, you simply import and use it like any React Apollo API component (Query, Mutation or Subscription):\n\n```\nimport { UserQuery } from './generated-models';\n...\n<UserQuery.Component>\n {({ loading, error, data }) => {\n  ...\n }\n</UserQuery.Component>\n```\n\n> **GraphQL Code Generator** _takes the query‚Äôs name, makes it_ PascalCased _and puts ‚Äú\\_Component‚Äù \\_in its namespace. For example, ‚Äú\\_userQuery_‚Äù becomes ‚Äú_UserQuery_‚Äù; and its React Apollo API component is generated as ‚Äú_UserQuery.Component_‚Äù\\_\n>\n\nYou can learn more about React Apollo API;\n\n[https://www.apollographql.com/docs/react/essentials/get-started.html#request](https://www.apollographql.com/docs/react/essentials/get-started.html#request \"Get started | Apollo Client\nThe simplest way to get started with Apollo Client is by using Apollo Boost, our starter kit that configures your‚Ä¶www.apollographql.com\")\n\n# Higher Order Components\n\nYou may use **_Higher Order Components_** in your React project together with Redux connectors or other state management tools.\n\n\nIf you don‚Äôt know which one you should use, please check the following docs to learn more about HOCs\n\n[https://reactjs.org/docs/higher-order-components.html](https://reactjs.org/docs/higher-order-components.html \"Higher-Order Components - React\nA higher-order component (HOC) is an advanced technique in React for reusing component logic. HOCs are not part of the‚Ä¶reactjs.org\")\n\nReact-Apollo template works for you as well, it generates HOC functions with generated typings. So, the only thing you do is to import the HOC functions from your query‚Äôs namespace like the component version.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*zPsA5FLnJa0UszBk?raw=true \"HOC Function Example Usage\")\n\n---\n\nWe believe **_GraphQL_** is a game changer in how you plan and create your frontend apps.\n\n\nThe vision that guides us is that you should be able to sketch a list of data types your backend can provide, sketch components and their data dependencies ‚Äî and all the rest of the plumbing can be generated for you.\n\nOnce you‚Äôll write an app like that, you will ask yourself why did you write all the other boilerplate code by yourself before.\n\nPlease try this template out and let us know what you think in the comments!\n\nThis is just one template out of many, check out more things you can generate with the **GraphQL Code Generator** and give us ideas about other templates you would like to see implemented.\n\n\n[https://github.com/dotansimha/graphql-code-generator#available-templates](https://github.com/dotansimha/graphql-code-generator#available-templates \"dotansimha/graphql-code-generator\ngraphql-code-generator - GraphQL code generator with flexible support for custom templatesgithub.com\")\n\n---\n\n> Follow us on **_GitHub_** and **_Medium_**, we are planning to release many more posts in the next couple of weeks about what we‚Äôve learned using **_GraphQL_** in recent years.\n>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"7b225672588f\",\"publishedDate\":1534869692976,\"url\":\"https://medium.com/the-guild/graphql-code-generator-for-typescript-react-apollo-7b225672588f\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDo1MzozNyswMTowMM4izp-g",
            "node": {
              "title": "Angular CLI + Meteor ‚Äî No more ejecting Webpack Configuration",
              "body": "Previously, we have to eject Webpack configuration generated by Angular CLI to modify module aliases for Meteor‚Äôs special import syntax such as `meteor/meteor` and `meteor/mongo` etc.. However, this is not required after the latest release of Meteor Client Bundler. Now, MCB can create stub modules for these imports.\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*y615EoYILerbBLdV.png?raw=true)\n\n# Quick Start\n\nCheck out the example in `angular-meteor` ; <https://github.com/Urigo/angular-meteor/tree/master/examples/AngularCLI>\n\n\n# How to add Meteor Client to your existing project;\n\n-   After installation of `meteor-client-bundler` ;\n\n\n```\nyarn add meteor-client-bundler --dev\n// or\nnpm install meteor-client-bundler --save-dev\n```\n\n-   Add `meteor-client.config.json` with the necessary options;\n\n\n```\n// meteor-client.config.json\n{\n  \"runtime\": {\n    \"DDP_DEFAULT_CONNECTION_URL\": \"http://localhost:3000\",\n    \"ROOT_URL\": \"http://localhost:3000\"\n  },\n    // This option enables the generation of stub modules\n    \"generateNodeModules\": true\n}\n```\n\n-   After that; don‚Äôt forget to add generated `meteor-client.js` to `angular.json` ;\n\n\n```\n// angular.json\n...\n\"scripts: [\n  \"node_modules/meteor-client.js\"\n],\n...\n```\n\n-   Optionally, you can add `postinstall` script to generate all modules in every `node_modules` generation; because `yarn` or `npm` may remove your generated modules from this directory.\n\n\n```\n// package.json\n...\n \"scripts\": {\n   ...\n  \"postinstall\": \"meteor-client bundle -s <PATH-TO-METEOR-PROJECT>\",\n   ...\n },\n...\n```\n\n-   Ready to use!\n\nThank you for reading my blog post about using Angular CLI with new MCB. I‚Äôd appreciate your claps to this post if you like it.\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"4e718aa855b6\",\"publishedDate\":1531451756752,\"url\":\"https://medium.com/the-guild/angular-cli-meteor-no-more-eject-webpack-configuration-4e718aa855b6\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDo1MzozMCswMTowMM4izp9V",
            "node": {
              "title": "Connecting React Native and Meteor backend w/o any 3rd party library in 2018",
              "body": "## **Introduction to new features of client bundler and React Native Meteor Polyfills including OAuth and persistent login session support etc‚Ä¶**\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*Y7GAmHPY1F4BT41j?raw=true \"source: https://medium.com/handlebar-labs/announcing-learn-react-native-meteor-c245f38a6d46\")\n\n# What was the problem and the existing solutions?\n\nI was working on a project that has RN frontend and Meteor backend, but uses [`react-native-meteor`](https://github.com/inProgress-team/react-native-meteor) npm package in RN project. I couldn‚Äôt share any code between them without struggling aliasing module import names and the other stuff.\n\n\nI wanted to share the code between client and server like many Meteor projects do, because I was working on backend with a React Native developer who hadn‚Äôt know Meteor a lot. And, my TypeScript code will help him to write less error-prone code with type-checking feature of VSCode.\n\nThen, I searched on Google for any alternative that makes the code sharing available.`react-native-meteor` package is quite useful, but is not able to share the code between client and server which Meteor does for Web.\n\n\nI found a pretty old alternative called [`meteor-native-packages`](https://github.com/Urigo/meteor-native-packages) . It is a set of modified core packages of Meteor that replaces Browser API codes with React Native and NodeJS compatible ones . This idea makes Meteor Client work when they are bundled via `meteor-client-bundler`. However, all these need to be synced with Meteor‚Äôs native API which is really hard to maintain.\n\n\nAlso we have another problem; older `meteor-client-bundler` versions haven‚Äôt supported use of external node modules in the client project‚Äôs `node_modules` .\n\n\nTo summarize, there were various libraries and 3rd party solutions to connect React Native to Meteor such as `react-native-meteor` and `meteor-native-packages` with the challenge in `meteor-client-bundler` .\n\n\n# Solution: Browser Polyfills for Official Meteor Client\n\nI‚Äôve published a different package [`react-native-browser-polyfills`](https://github.com/ardatan/react-native-browser-polyfills) that shims necessary APIs of browser to make Meteor‚Äôs official client compatible with React Native that is bundled by `meteor-client-bundler` .\n\n\nI also added some features such as generating stub modules in `node_modules` directory to make `meteor/PACKAGE_NAME` syntax available, and support the use of external npm dependencies in the client project‚Äôs `node_modules` directory for the official `meteor/react-meteor-data` package instead of using the replication version in npm which has the same name. You can see more on the related post about MCB;\n\n\n[https://medium.com/@‚Äãardatan/whats-new-on-meteor-client-bundler-better-react-native-support-1c3b512bdd16](https://medium.com/@ardatan/whats-new-on-meteor-client-bundler-better-react-native-support-1c3b512bdd16)\n\n\nAs you know, Meteor has SockJS built-in which is compatible with both browser and NodeJS. So, the only problem is the code that uses DOM API. Luckily, _WebSocket_ has already been implented by React Native. There is another savior for the rest.\n\n\n`react-native-browser-polyfills` has been just released for polyfilling DOM API including `localStorage` , `navigator.connection` , `document.location` and some other subsets that uses React Native API equivalent ones.\n\n\n`AsyncStorage` is used for `localStorage` , `NetInfo` is used for `navigator.connection` and `Linking` is used for `document.location` . But, the problem is that these APIs from React Native are asynchronous while they are synchronous in browser. As a workaround, `react-native-browser-polyfills` waits for resolving their promises, then emits `DOMContentsLoaded` for `document` which Meteor Client would be waiting for in order to initiate the connection between RN and Meteor backend.\n\n\n# Also we have Facebook, Twitter and Google Login on React Native and Meteor stack\n\nThis was the most challenging one which is solved by another package [`react-native-meteor-polyfills`](https://github.com/ardatan/react-native-meteor-polyfills) that extends `react-native-browser-polyfills` .\n\n\nI‚Äôve released another package `react-native-meteor-polyfills` to polyfill `window.open` with `Linking` by extending `react-native-browser-polyfills`. However, this polyfill must be included to Meteor project as well to make it able to redirect to the RN app after a successful OAuth login.\n\n\nThanks to this polyfill, you can use `accounts-{SERVICE_NAME}` packages without any extra native libraries.\n\n\n# Easy Start with Boilerplate\n\nJust check out this up-to-date boilerplate;\n\n<https://github.com/DAB0mB/ReactNativeMeteorBoilerplate>\n\n\n# How To Add All These To Your Existing Project\n\nIf you want to learn more to integrate all these features to your existing RN and Meteor projects step-by-step;\n\n-   First, install `react-native-meteor-polyfills`in both Meteor and RN projects.\n\n\n```\n//For Meteor Project\nmeteor npm install react-native-meteor-polyfills--save\n```\n\n```\n//For React Native Project\nyarn add react-native-meteor-polyfills\n//or\nnpm install react-native-meteor-polyfills--save\n```\n\n-   Install `meteor-client-bundler` in your RN project\n\n\n```\n//For React Native Project\nyarn add meteor-client-bundler --dev\n//or\nnpm install meteor-client-bundler --save-dev\n```\n\n-   Add `meteor-client.config.json` ;\n\n\n```\n{\n    \"runtime\": {\n        // These variables should be pointed to your Meteor server.\n        \"DDP_DEFAULT_CONNECTION_URL\": \"http://localhost:3000\",\n        \"ROOT_URL\": \"http://localhost:3000\"\n    },\n    \"externalNpmPackages\": [\n        \"react\" // Use `react` from `node_modules`\n    ],\n    \"generateNodeModules\": true //Generate for `meteor/PACKAGE_NAME`\n}\n```\n\n-   Add `postinstall` to your `package.json` of your RN project, because generated `meteor-client.js` and other stub modules might be deleted. This script will restore them after each `node_modules` install.\n\n\n```\n{\n...\n```\n\n```\n  \"scripts\":{\n   ...\n```\n\n```\n   \"postinstall\": \"meteor-client bundle -s {PATH_OF_METEOR_PROJECT}\"\n   ...\n}\n...\n}\n```\n\n-   Finally, run this script to generate those modules.\n-   After that do not forget to include `react-native-meteor-polyfills/client` and `meteor-client` in the top of React Native entry file `App.jsx` or `index.*.js` etc.\n\n\n```\nimport 'meteor-client';\nimport 'react-native-meteor-polyfills';\n```\n\nIf you never used Meteor with React before, check out Meteor‚Äôs official documentation for `react-meteor-data` package, and OAuth packages.\n\n\nAnd, YOUR NEW STACK IS READY TO RUN!\n\n# Optional: Facebook, Twitter and Google Login Support\n\n-   If you want to make `Meteor.loginWith` work with React Native, you have to add custom URI scheme to your React Native project.\n\n-   Then, tell Meteor what your URI scheme is;\n\n```\nimport { setApplicationPrefix } from 'react-native-meteor-polyfills/server';\n```\n\n```\nsetApplicationPrefix('myURIscheme');\n```\n\n# Contribution\n\nIf you find any bugs, problems and issues, please open a new issue on GitHub. If you solve any of them, please feel free to push a pull request.\n\nI‚Äôd appreciate your claps and comments for this post!\n\n# Credits\n\n> **Special thanks to;**\n>\n>\n> **_DAB0mB‚Äî Eytan Manor_**\n>\n>\n> Urigo**_‚Äî Uri Goldshtein_**\n>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"3e784d33acb0\",\"publishedDate\":1531451719951,\"url\":\"https://medium.com/the-guild/connecting-react-native-and-meteor-w-o-any-3rd-party-library-in-2018-3e784d33acb0\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDo1MzoyMyswMTowMM4izp8g",
            "node": {
              "title": "Meteor with Webpack in 2018 ‚Äî Faster compilation and better source handling",
              "body": "## Introduction to Meteor-Webpack\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*VDMfFrMCaBguctSv?raw=true)\n\n[Meteor](https://meteor.com) is a complete full stack framework for fast-start on your real-time web application. I don‚Äôt focus on that for now.\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*HlAocP6PijF4VfIO.png?raw=true)\n\n[Webpack](https://webpack.js.org) is a great bundler to compile your code including view templates, assets and the all stuff on your application.\n\n\nHowever, Meteor already has its own built-in bundler; but it needs some challenging tricks when you‚Äôre working with ES2015 external npm dependencies or any compilation methods.\n\nMeteor-Webpack is here as a solution to this kind of problems and lack of features in Meteor‚Äôs bundler.\n\n# Why do you need this?\n\nFor example, you have a Progressive Web Application using Service Workers, written in Angular, then you have to create a service worker manifest based on your output files. We don‚Äôt have a solution for this on Meteor CLI natively. However, Webpack has a lot of community plugins such as [`OfflinePlugin`](https://github.com/NekR/offline-plugin) , [`Workbox`](https://developers.google.com/web/tools/workbox/guides/codelabs/webpack) and many others for this problem as a solution. Just install them, and add to your [`webpack.config.js`](https://webpack.js.org/configuration/) . Meteor-Webpack will handle it like you‚Äôre working on a pure Webpack project.\n\n\nOther example is server-side rendering. [Angular CLI](https://cli.angular.io) is based on Webpack, and the project can be compiled for SSR by Angular CLI; but you need a different server application to serve your Angular Universal application seperate from Meteor backend. By using Meteor-Webpack, it is possible only by ejecting Angular CLI‚Äôs `webpack.config.js` , and use it on Meteor project.\n\n\n# Hot Module Replacement; even for server (Beta)\n\n![HMR hot module replacement ile ilgili g√É¬∂rsel sonucu](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*v9fTLeyCHg3hVpdjKhvLxw.png?raw=true \"Hot Module Replacement\")\n\nReloading on recompilation while developing your app may take a lot of time. HMR comes to save us from this time loss on development. If you don‚Äôt know, what HMR is. You can [check out Webpack‚Äôs documentation.](https://webpack.js.org/concepts/hot-module-replacement/)\n\n\nMeteor-Webpack integrates [`webpack-dev-middleware`](https://github.com/webpack/webpack-dev-middleware) and [`webpack-hot-middleware`](https://github.com/webpack-contrib/webpack-hot-middleware) to benefit HMR in your project. The only thing you have to do is enabling this feature just like any other Webpack project;\n\n\n```\n...\ndevServer: {\n  hot: true\n}\n...\n```\n\nAlso, you can use HMR for server side. Meteor-Webpack supports [`webpack-hot-server-middleware`](https://github.com/60frames/webpack-hot-server-middleware) , that replaces changed modules on your server without restarting all Meteor server. This also provides a lot of benefits on development.\n\n\n# More examples\n\nThere are more examples in the repository; <https://github.com/ardatan/meteor-webpack>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"bc5ccc5735ef\",\"publishedDate\":1531451671259,\"url\":\"https://medium.com/the-guild/meteor-with-webpack-in-2018-faster-compilation-better-source-handling-benefit-from-bc5ccc5735ef\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDo1MzowOSswMTowMM4izp6j",
            "node": {
              "title": "What‚Äôs new on Meteor Client Bundler ‚Äî Better React Native support, handling Meteor imports etc‚Ä¶",
              "body": "## Introduction to new features of MCB\n\n![METEOR client bundler ile ilgili g√É¬∂rsel sonucu](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*CKGGtcy7rgOwCQ-mAFmw0g.png?raw=true \"source: https://blog.meteor.com/leverage-the-power-of-meteor-with-any-client-side-framework-bfb909141008\")\n\nMeteor Client Bundler is a solution for packaging Meteor‚Äôs official client packages into a single module in order to use your projects not using Meteor CLI.\nUntil last version, it is not possible to use MCB on non-browser projects without some tricks such as React Native, Electron etc‚Ä¶\n\n# New Features on MCB\n\n-   Generate stub modules for `meteor/[PACKAGE]` if you cannot use module-aliasing somehow. It is really challenging situation on Angular CLI and React Native CLI.\n\n-   Use external NPM modules from your client project‚Äôs `node_modules` directory instead of adding it to the Meteor Client Bundle; this is required not to duplicate `react` for React Native projects.\n\n-   Possibility not to add `__meteor_runtime_config` , if you want to add it by yourself in your project. Especially, if you want to seperate production and development URLs for Meteor backend\n\n\nThis features allow you to use directly Angular CLI and React Native CLI without the need of ejecting any configuration file.\n\nAlso, there is other specific post about React Native CLI integration of Meteor without using 3rd party libraries such as `react-native-meteor` or `react-meteor-data` which are copies of official client libraries. The most important disadvantage of using these extra libraries is lack of code sharing between Meteor and React Native project. Otherwise, Client Bundle generated by MCB allows this.\n\n\n# Related posts\n\n-   You can access React Native integration post from this link;\n\n[https://medium.com/@‚Äãardatan/connecting-react-native-and-meteor-w-o-any-3rd-party-library-in-2018-3e784d33acb0](https://medium.com/@ardatan/connecting-react-native-and-meteor-w-o-any-3rd-party-library-in-2018-3e784d33acb0)\n\n\n-   Another post explains Angular CLI with MCB is here;\n\n[https://medium.com/@‚Äãardatan/angular-cli-meteor-no-more-eject-webpack-configuration-4e718aa855b6](https://medium.com/@ardatan/angular-cli-meteor-no-more-eject-webpack-configuration-4e718aa855b6)\n\n\n# Examples\n\nThese are direct links to the example projects using MCB;\n\n-   Angular CLI Example; <https://github.com/Urigo/angular-meteor/tree/master/examples/AngularCLI>\n\n-   React Native CLI Example w/ Expo; <https://github.com/DAB0mB/ReactNativeMeteorBoilerplate>\n\n\n_Special thanks to_ Urigo _for this great tool, and allowing me to modify the code to add these features._\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"1c3b512bdd16\",\"publishedDate\":1531451634340,\"url\":\"https://medium.com/the-guild/whats-new-on-meteor-client-bundler-better-react-native-support-1c3b512bdd16\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDo1MzowNiswMTowMM4izp6J",
            "node": {
              "title": "ValuAg; New Generation Marketplace ‚Äî Meteor, Angular and Material Design",
              "body": "We‚Äôre proud of announcing the first version of ValuAg. As you can see the landing page on ValuAg Web Site, it is a marketplace for buyers and farmers who cares GMO-free and organic food.\n\nIn terms of technology, ValuAg is built on latest technologies. Meteor, Angular, Progressive Web Application approach, Google‚Äôs Material Design, ElasticSearch and great 3rd party services such as Twilio, SendGrid, Firebase and Crisp.\n\n# Why there is no extra mobile app?\n\nAs I described above we used the new generation web technologies, so a Progressive Web Application can be installed in the similar way with a native mobile application, receive push notifications, work offline thanks to Service Workers.\nUsing Angular‚Äôs Flex-Layout and Material libraries, we could create a mobile-first web application that user would nearly have same experience with a native mobile application.\n\nYou don‚Äôt need seperate development processes for each platform such as dealing with Xcode for iOS and Android Studio for Android.\n\nOnly one development process gives you an application that runs almost all platforms on a major browser.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*cvDkccC2S9-FkDJvHJl7lQ.png?raw=true \"Architecture Diagram of ValuAg\")\n\n# Why Meteor?\n\nMeteor is a new generation framework that has an oplog driver for MongoDB which provides you real-time data transfer between your application server and the database, and also Meteor uses WebSockets which creates a real-time connection between your application server and client which is browser. All these provides you three way data binding between the database and the client. Angular‚Äôs bi-directional data flow and RxJS Observables can have a tight integration with Meteor.\n\nMeteor aims zero-configuration for developers, so you can only focus on your development, which is ready-to-use initially on Meteor. Otherwise, you would have to deal with the integration of different libraries to create an architecture from scratch.\n\nThat‚Äôs why, Meteor fits very well the requirements of software-based products, which belongs to startups like ValuAg.\n\n# Why Angular?\n\nAngular is a complete framework that has Model-View-Controller approach and stands on TypeScript which is a superset of JavaScript. Angular has nearly everything you will need to initiate your development. Like Meteor, the development team don‚Äôt have to find out the ways for the integration of different libraries, because Angular already gives you TypeScript, RxJS and other stuff inside.\n\nThanks to Meteor and RxJS; `meteor-rxjs`, you don‚Äôt have to use an extra state management libraries such as Flux and Redux.\n\n\n# Why Material?\n\nMaterial Design is not another framework like Bootstrap, but just a set of design specifications. These specifications are already used on Android. It makes life easier for a developer who are not an actual designer like me.\n\nThen we can easily focus on the development of features without considering about design.\n\n# Why ElasticSearch?\n\nThe short answer is speed. ElasticSearch is very good at handling large datas. ValuAg uses ElasticSearch to handle big DBA, Certifications, Cuisine, EDI, PLU and Vegetable Planting Calendar data.\n\n# What is next?\n\nWe, ValuAg Team, are thinking of new features on blockchain, and quick rewriting of ValuAg Web Application with Stencil and Firebase. However, we will try these technologies on our ICO Website. This is the topic of another blog post. Stay tuned!\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"1df9c73ade54\",\"publishedDate\":1531451557571,\"url\":\"https://medium.com/valuag/valuag-new-generation-marketplace-meteor-angular-and-material-design-1df9c73ade54\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDo0ODo1OCswMTowMM4izpaK",
            "node": {
              "title": "GraphQL Config ‚Äî One configuration for all your tools",
              "body": "## Simplify your everyday GraphQL workflow\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*3ow-Coz2GhxfmNY447Wacw.gif?raw=true)\n\n# TLDR\n\n-   Visit our website **[graphql-config.com](https://graphql-config.com)**\n\n-   [**GraphQL Config**](https://github.com/kamilkisiela/graphql-config) is **one** simple place to store **all** your GraphQL Configurations for **any** GraphQL based tool\n\n-   [Prisma recently transferred the project](https://www.prisma.io/blog/the-guild-takes-over-oss-libraries-vvluy2i4uevs) to [The Guild](http://the-guild.dev) ‚Äî and we **completely rewrote it** and addressed **more than ‚Öî of the issues** (and the remaining are waiting for feedback)\n\n-   We‚Äôve already **merged configurations** from [GCG](https://graphql-code-generator.com/), [GraphQL Inspector](https://graphql-inspector.com/), [GraphQL CLI](https://github.com/Urigo/graphql-cli) ‚Äî and are looking to learn and **integrate** with GraphiQL, AppSync, Apollo, Gatsby, VS-Code extensions, Relay and the GraphQL team at Facebook and any GraphQL tool creators\n\n-   This is an **alpha phase** ‚Äî **we want your feedback**, as a user and as a creator ‚Äî Please [**create an issue**](https://github.com/kamilkisiela/graphql-config) or [**join our Discord channel**](https://discord.gg/xud7bH9)\n\n\n# How did we get here?\n\nAbout 2 years ago Prisma came up with a great idea for the GraphQL community ‚Äî Why repeat yourself in creating your configuration for each tool you use in your application.\n\nSo together with many developers from the GraphQL community, [they introduced the GraphQL Config library and spec](https://www.prisma.io/blog/new-tooling-to-improve-your-graphql-workflows-7240c81e1ba3) and many tools have since embraced that standard.\n\n\nBut time has passed and the library slowly became unmaintained.\n\nPrisma were very kind and generous with moving the project forward and [passing it to us](https://www.prisma.io/blog/the-guild-takes-over-oss-libraries-vvluy2i4uevs).\n\n\nSo when we took over the GraphQL Config, our main goal was to bring it back to life and push it forward for the community.\n\nWe asked for feedback, looked at existing and new tools that came out since it was released, went through all the open issues and PRs, listened to your suggestions and got to work!\n\n---\n\n# Our main goals are\n\n-   Highly **customizable** and **extensible**\n\n-   More **useful** structure\n\n-   **Flexible** and helpful enough to become a standard in the community\n\n-   Make it **platform agnostic** (Node, Browser)\n\n\n---\n\n# Try it out today\n\nWe‚Äôve already refactored most of the code, created a new structure, referenced all the related issues and released a new alpha version:\n\n```\nnpm install graphql-config@next\n```\n\n```\nyarn add graphql-config@next\n```\n\nNow we want to hear from you ‚Äî GraphQL developers and GraphQL tool creators.\n\nHere is a deeper dive into what we‚Äôve done:\n\n---\n\n# Different formats of GraphQL Config file\n\nThe new [GraphQL Config](https://github.com/kamilkisiela/graphql-config) now allows to use JSON, YAML and JavaScript.\n\n\n## GraphQL Config looks for:\n\n-   `.graphqlrc`\n\n-   `.graphqlrc.yaml`\n\n-   `.graphqlrc.yml`\n\n-   `.graphqlrc.json`\n\n-   `.graphqlrc.js`\n\n-   `graphql.config.js`\n\n\nThe new config can also be created programmatically too.\n\nIt also accepts a config defined under `graphql` property in your `package.json` file.\n\n\n> We‚Äôre open to expand the range of file names and looking forward to hear more of your use cases.\n\n# New structure\n\nGraphQL Config allowed to indicate  a single graphql file, an introspection file or a URL to an endpoint. That‚Äôs the past!\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*3JRL5JR5Hd3kQgsSq57n4Q.png?raw=true \"New GraphQL Config with Schema and Documents\")\n\n## **Schema**\n\n\nWe‚Äôve decided to expand [GraphQL Config](https://github.com/kamilkisiela/graphql-config) for variety of sources of GraphQL Schema and rename `schemaPath` to just `schema`.\n\n\nIt accepts now not only a single file but also a glob pattern to match your modularized schema.\n\n## **Allows to generate schema from:**\n\n\n-   files matching a glob pattern (or a list of patterns)\n-   an explicit list of files\n-   an endpoint\n-   an introspection file\n-   **TypeScript and JavaScript files**\n\n-   and even more‚Ä¶\n\nIt was possible thanks to the concept of **Loaders** which we‚Äôll talk about later in the article.\n\n\n## **Documents**\n\n\nMajority of the GraphQL tools depend not only on Schema but Operations and Fragments, so we‚Äôve decided to cover that use case too.\n\n> ### **With the new** GraphQL **Config, you‚Äôre able to indicate files containing GraphQL operations and fragments (documents) and load them all within a single method.**\n>\n\nGraphQL Config accepts not only `.graphql` files but also extracts documents from **TypeScript and JavaScript files, including JSX and TSX**.\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*5TCyeU_ZZVaiK1kxX3guRA.png?raw=true \"GraphQL Config understands JSX too!\")\n\nThanks to that, you can still write your operations and fragments with `graphql-tag` and put them in your React components. GraphQL Config is smart enough to find and collect them.\n\n\n## **Include and Exclude**\n\n\n`Include` and `Exclude` options are still relevant, but we improved and fixed the logic behind them.\n\n\n> ### Their purpose is to tell config‚Äôs consumer which files belongs to what project.\n\nFiles covered by schema or documents options are automatically included, there‚Äôs no need to include them twice.\n\n## **Extensions**\n\n\nWe also kept `extensions` and turned them into a first class citizen in GraphQL Config, **making them way more powerful than before**.\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*_r0JTLAlMzw3XyljlJuEqQ.png?raw=true \"Example of GraphQL Config for GraphQL Code Generator\")\n\n# Pluggable loaders\n\nThe source of GraphQL Schema may differ, depending on the setup. In some projects SDL is kept within graphql files, others store it in code.\n\n**The new GraphQL Config is capable of loading schema from:**\n\n\n-   `.graphql` files\n\n-   introspection result file\n-   running endpoints\n-   Files on **GitHub**\n\n-   Files on **Git repository**\n\n-   files with documents wrapped with `graphql-tag`and gatsby‚Äôs `graphql`\n\n-   documents with the magic comment `/* GraphQL */`\n\n-   single **JavaScript** and **TypeScript** file that exports GraphQLSchema object, DocumentNode or schema as string\n\n\n**The possibilities are endless here!**\n\n\n> ### The main idea behind loaders is to **extend the default behavior of GraphQL Config and allow to load GraphQL Schema from many different sources**.\n>\n\nLoaders are flexible enough to let you decide what exactly you want to use, even just to keep the bundle size smaller.\n\nIt also simplifies the codebase of GraphQL tools as they don‚Äôt need to take care of that work themselves anymore.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*9fXJ8lOIYjGKGs7UzmBPdg.png?raw=true \"An example Loader\")\n\nWe maintain [a few loaders](https://github.com/ardatan/graphql-toolkit/tree/master/packages/loaders) but we believe the community will start to cover other use cases as well.\n\n\n# All platforms\n\nOur goal is to make **GraphQL Config platform agnostic**.\n\n\nThe old version relied heavily on Node‚Äôs file system, which is a blocker in many cases.\n\n**Loader fits here perfectly.**\n\n\nBecause it‚Äôs just an asynchronous function that receives an input and gives back a GraphQL Schema, it should work fine in browser and in any other environment.\n\n# Extensions\n\nIn the previous generation of GraphQL Config `extensions` namespace, there was a way to pass custom information to the consumers of the config file, like libraries and IDE extensions.\n\n\nWe believe `extensions` should actually **extend** GraphQL Config‚Äôs behavior.\n\n\nTake for example loaders. Imagine you want to collect operations and fragments from your Relay project. With the new GraphQL Config, you can write a loader and register it through a Relay Extension.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*nTEtaYLi62XtCtdtZhmmHA.png?raw=true \"An example GraphQL Config Extension\")\n\nThe new `extensions` allows you to turn GraphQL Config into something fully customizable and to be used in tools like Webpack!\n\n\n# Hooks\n\nWe believe that there‚Äôs a need to **intercept the schema building process** or to simply **validate the config**.\n\n\nIt‚Äôs not currently available but with your help and suggestions we could make it happen.\n\n# Environment Variables\n\nIn the new GraphQL Config, we‚Äôve decided to support environment variables. **It was a long time hanging and highly requested issue**. Now the usage in JS config file is straightforward. It‚Äôs also very easy to use environment variables in YAML and JSON files.\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*wEla1gmqhAi8v3KSkHw0Yg.png?raw=true \"Example of environment variables in GraphQL Config file\")\n\nEvery `${ENV_VAR}` in the config file is replaced with the actual value. We also allow for defaults. Using `${ENV_VAR:foo}` results in `foo`.\n\n\n# Easier to contribute\n\nWe also wanted to make the codebase itself easy to understand and contribute to.\n\nOur first task was to **bring the repository back to life** by updating the build and test setup.\n\n\nThe `graphql-config` package now ships with **CommonJS** and **ES Modules** thanks to **Rollup** and **TypeScript**. Tests are done thanks to **Jest**. The codebase stays consistent because of **Prettier** and **ESLint** on top.\n\n\nWe also migrated from Travis to **GitHub Actions** and run tests on **Node 8, 10 and 12**.\n\n\nTo keep dependencies always up to date and to make sure no new release breaks GraphQL Config‚Äôs logic, we decided to use **Dependabot**.\n\n\nWe also addressed more than 70% of the issues and open PRs (and the remaining are waiting for feedback).\n\n---\n\nStart using it today!\n\nEven though we are in an alpha phase, If you‚Äôre the author or maintainer of a GraphQL library or another related tool, **we encourage you to adopt the GraphQL Config standard**.\n\n\n> Please link to this [GitHub issue](https://github.com/kamilkisiela/graphql-config/issues/27) to track the progress.\n>\n\n---\n\nIf you have a project that use those tools, we encourage you to try it out in your current project.\n\nWe will support and answer all your questions on [**Github**](https://github.com/kamilkisiela/graphql-config) and on [**our Discord channel**](https://discord.gg/xud7bH9).\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"708dd0e5d15f\",\"publishedDate\":1572013852098,\"url\":\"https://medium.com/the-guild/graphql-config-708dd0e5d15f\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDo0ODoxNSswMTowMM4izpUQ",
            "node": {
              "title": "Introducing: GraphQL Inspector",
              "body": "## Prevent breaking changes. Find broken operations. Get Schema Coverage. Check deprecated usage and type duplicates. All as part of your CI process\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*CyqZ1l33OqR4uOIl8l7X3A.png?raw=true)\n\nThroughout almost three years of working with GraphQL, me and [**The Guild**](https://medium.com/the-guild)  introduced solutions that changed the way we write our projects today.\n\n\nIn order to use GraphQL in our Angular applications, we created [**Angular Apollo**](https://github.com/apollographql/apollo-angular). To automate and increase type-safety, we open-sourced [**GraphQL Code Generator**](https://github.com/dotansimha/graphql-code-generator). Most recent thing was [**GraphQL Modules**](https://github.com/Urigo/graphql-modules) that helped us to separate a server into smaller, reusable, feature based parts. All of that was developed based on the experience and used with huge success by our clients.\n\n\nToday, I‚Äôm happy to introduce another piece of our tech stack, we call it\n\n> ### **GraphQL Inspector**!\n>\n\n**GraphQL inspector** is a tool that‚Äôs main purpose is to make sure your GraphQL API and all its clients are well developed.\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*EgkI2pedKBucOh0tdbm9mw.gif?raw=true \"GraphQL Inspector CLI\")\n\n---\n\n# Key features\n\n-   [**Finds breaking, dangerous and safe changes**](https://graphql-inspector.com/docs/essentials/diff) when modifying a GraphQL API\n\n-   [**Github Application**](https://graphql-inspector.com/install)  +  [Github Action](https://graphql-inspector.com/docs/recipies/github) _(Bitbucket integration soon)_\n\n-   **Command Line Interface**\n\n-   **Completely free and open-source** ‚Äî host your own GraphQL Inspector\n\n-   [**Schema coverage**](https://graphql-inspector.com/docs/essentials/coverage) **‚Äî**see unused parts of Schema based on all your clients‚Äô fragments and operations\n\n-   [**Validates operations**](https://graphql-inspector.com/docs/essentials/validate) against a GraphQL Schema ‚Äî you notice errors before run-time!\n\n-   [**Finds duplicates or similar types**](https://graphql-inspector.com/docs/essentials/similar)\n\n\n---\n\n# Use it in Github\n\nWe offer GraphQL Inspector as a [**Github Application**](https://graphql-inspector.com/install)  that you can install in any of your repositories within a single click. That‚Äôs the easiest way possible to start using Inspector.\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*I1xcycuoXNgi4ox7BrmjxA.jpeg?raw=true \"GraphQL Inspector annotates every change in your GraphQL Schema\")\n\n## Inspector as part of your workflow\n\nIn order to use GraphQL Inspector, you need to make sure you write an entire GraphQL Schema to a file so Inspector could see it. Git hooks fits well here. Whenever there‚Äôs a new commit, the file will be updated.\n\nNext, you configure GraphQL Inspector in `package.json` :\n\n\n```json\n{\n  \"name\": \"my-app\",\n  \"scripts\": {\n    \"graphql:write\": \"graphql-inspector introspect src/schema.js --write schema.graphql\"\n  },\n  \"graphql-inspector\": {\n    \"diff\": true,\n    \"schema\": {\n      \"ref\": \"head/master\",\n      \"path\": \"schema.graphql\"\n    }\n  }\n}\n```\n\n> You can read more about that in [‚ÄúGithub Application‚Äù chapter](https://graphql-inspector.com/docs/recipies/github#usage) on [our website](https://graphql-inspector.com).\n>\n\nNow, whenever someone submits a Pull Request the GraphQL Inspector will compare schemas and fail if there are breaking changes.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*MapECo7_Q4aWzNy-HvNfXA.png?raw=true \"Prevents from merging the Pull Request\")\n\n## Github Actions\n\nI know Github Actions are not yet publicly available but if you‚Äôre lucky enough, you can use them to host your own GraphQL Inspector that is deployed and live per each commit or a pull request. Because an Action is temporarily executed with Docker, you won‚Äôt use any Cloud service or any other paid resources.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*RP5OmxhmtyAgFj7VrdHrQg.jpeg?raw=true \"An example workflow. Check your API on every pull request or commit.\")\n\nRight now, Actions are not the most enjoyable thing but because it‚Äôs free and super easy to setup we highly recommend to take advantage of it if you don‚Äôt want to use hosted by us GraphQL Inspector.\n\nWe don‚Äôt store any data, the code is open-sourced and deployed with Netlify Functions.\n\n> ### Because we strongly believe in open-source, **you can also have your own instance of GraphQL Inspector up and running.**\n>\n\n# **Bitbucket integration**\n\n\nGraphQL Inspector doesn‚Äôt support Bitbucket yet but it‚Äôs on top of our roadmap and we‚Äôre starting working on it. If you need it, please reach out or comment on [the open issue](https://github.com/kamilkisiela/graphql-inspector/issues/54).\n\n\n# **Prevent breaking changes**\n\n\nGraphQL Inspector compares an old and a new GraphQL Schema in order to alert you about breaking changes. It also tracks other changes, dangerous to implement and those that are entirely safe.\n\nThis way you have a clear vision of how your Schema is developed.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*nk1uo9UKFSUfr8yWXAKK1w.jpeg?raw=true \"Schema Comparison in GraphQL Inspector CLI\")\n\n# **Schema coverage**\n\n\nThe idea behind it is to see which part of your schema is used, how many times and by which operation. It only applies to documents that can be statically analyzed.\n\nInspector is able to extract every fragment or operation from your TypeScript and JavaScript files. It supports any kind of template literal tag but also `.graphql` files.\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*2f8IKL4CvCqtRssSdtGolg.jpeg?raw=true \"Shows you how many times each field is used by all fragments and operations\")\n\n# **Validate documents and find deprecated usage**\n\n\nIn order to find out that your operation or fragment is broken you need to run an app and execute a query or mutation. Thanks to GraphQL Inspector, you can easily check for errors or deprecated usage at any point of time.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*68paZgth-naSfyMGk7glig.jpeg?raw=true)\n\n> I recommend to make it as part of your CI or even git hooks.\n\n# Find duplicates\n\nAnother interesting feature of Inspector allows you to find similar types and maybe even duplicates. It‚Äôs not something everyone might want to use but we found it really helpful when we were migrating few separate GraphQL APIs to a monorepo and merging them into a single server at [**Air France ‚Äî KLM**](https://medium.com/airfrance-klm). The person who could say more about that would be Mart Ganzevles, who‚Äôs the father of that particular feature and it was his first ever open-source contribution. Amazing work Mart!\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*Wgv8s_QVibJddHtmanVwFQ.jpeg?raw=true)\n\n# Desktop application\n\nWe are going to work on a Desktop version of GraphQL Inspector to boost the whole experience even further. Imagine exploring everything in a nicely done and interactive application. You could click on things in order to see them in details, just amazing!\n\n# Other features\n\n-   Runs a GraphQL Server with faked data within a single command\n-   Writes an introspection result of GraphQL Schema to a file\n\n# How does it compare to other tools\n\n**Apollo Engine** GraphQL Inspector tries to solve a bit of a different use-case. The main idea behind Apollo Engine is to get insights of how a GraphQL server behaves in production.\n\n\nIt supports schema comparison too but the main difference is that we **don‚Äôt store any of your data** and in order to track changes, **we simply take advantage of Git**. Each change is available in git history, so the workflow is straightforward and it‚Äôs something you‚Äôre already familiar with.\n\n\nBecause of that, Apollo‚Äôs advantage is that it takes into account production data and not only your code. But if that is important to you, you can gather this data from your GraphQL servers today, store it wherever you want, and we can add a feature to add this data into one of our reports.\n\n**GraphQL Doctor** GraphQL Doctor and our tool have in common only the Schema Comparison feature, but Inspector tracks also changes that are safe to introduce. Doctor‚Äôs main goal is to run within Github and prevent from breaking an API. We would love to collaborate with them, make sure we truly covered all their use cases and maybe merge their library into ours.\n\n\n# Open-Source Community\n\nIn [The Guild](https://medium.com/the-guild), we love open-source, our whole careers were possible because of that. We also found out each other through Open-Source :)\n\n\nThat‚Äôs why I encourage you to help us develop GraphQL Inspector and **let‚Äôs build it together**.\n\n\nSmallest piece of code, bug fix, documentation improvement or even a simplest suggestion counts as contribution!\n\n---\n\n# Links\n\n-   [Website](https://graphql-inspector.com) and [documentation](https://graphql-inspector.com/docs/)\n\n-   Visit the [repository](https://github.com/kamilkisiela/graphql-inspector) on Github\n\n-   CLI available ‚Äî `$ yarn global add @graphql-inspector/cli`\n\n-   Checkout the [Github Application](https://graphql-inspector.com/install)\n\n-   See an [example](https://github.com/kamilkisiela/graphql-inspector-example/pull/3) app that uses GraphQL Inspector\n\n\n[https://medium.com/the-guild](https://medium.com/the-guild \"The Guild\nThe Guild at medium.com\")\n\n> Follow us on [**GitHub**](https://github.com/Urigo/graphql-modules) and [**Medium**](https://medium.com/the-guild), we are planning to release many more posts in the next couple of weeks about what we‚Äôve learned using **GraphQL** in recent years.\n>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"481c1a5ef616\",\"publishedDate\":1547830531291,\"url\":\"https://medium.com/the-guild/graphql-inspector-481c1a5ef616\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDo0NzoxMSswMTowMM4izpK5",
            "node": {
              "title": "How I helped improve Angular Console",
              "body": "## By doing GraphQL right\n\nIn this guest blog post by Kamil Kisiela for the [blog of Nrwl](https://blog.nrwl.io/) , Kamil covers the topic of the new Angular Console product. Nrwl is an Angular consulting, training and developer product firm. _If you like this, click the_ üëè s_o other people will see it. Follow [@‚Äãnrwl_io](https://medium.com/@nrwl_io) to read more!_\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*xBk9L_j521FRuqLTLjyFkg@2x.png?raw=true)\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*-3J5MEc1ocyXpWdK?raw=true)\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*9McDGpqiVh3sZ_CK74sxXw.png?raw=true)\n\nDid you know that **Angular Console** uses **GraphQL** under the hood? I want to tell about how it used it and how I helped to improve it because that might be useful for people trying to implement GraphQL in their applications, both on client and server.\n\n\n> [Angular Console](http://angularconsole.com) is a user interface for Angular CLI created by [Nrwl](http://medium.com/nrwl), supported by [Angular](http://medium.com/angular-blog) team. It‚Äôs widely used in Angular Community.\n>\n>\n> I will link to the PRs I‚Äôve made to Angular Console throughout the article so you could see everything I recommend in practice.\n\nAfter reading [the announcement](https://blog.nrwl.io/angular-console-the-ui-for-the-angular-cli-a5d0924240b7) of **Angular Console** I got very excited about the tool and immediately decided to explore the codebase. I noticed **Electron** and that the project is based on **Angular CLI** and Nrwl‚Äôs **NX**.\n\n\nThat‚Äôs super cool but what I found the most interesting was\n\n> ### GraphQL.\n\nAs a freelancer, I work on daily basis with [The Guild](http://medium.com/the-guild). Most of our projects are built with GraphQL. Throughout the 3 years of adopting it, our team **tested practices and developed open source tools that helped to improve our workflow**.\n\n\nSo when I saw the first implementation, I thought it would be nice to share some ideas and implement some code that might help to improve the GraphQL part of Angular Console.\n\n---\n\n# Apollo Angular as the GraphQL client\n\nI was hoping to find [**Apollo Angular**](https://github.com/apollographql/apollo-angular) as one of dependencies. I might be a bit bias as the author of that library but our team used it in all of our angular based projects with huge success.\n\n\n> KLM and AirFrance runs on Apollo Angular\n\nOkay, but just like in REST, you don‚Äôt need sophisticated tools to communicate with the API. Simple `fetch` or Angular‚Äôs `HttpClient` is far enough. Why then the GraphQL client?\n\n\nHaving a client, like Apollo, allows you to easily execute GraphQL operations and by having a cache layer, fetched data stays consistent across all components. Dhaivat Pandya explains it well in his [_‚ÄúWhy you might want a GraphQL client_](https://blog.apollographql.com/why-you-might-want-a-graphql-client-e864050f789c)_‚Äù post_.\n\n\nApollo has a comprehensive [documentation](https://www.apollographql.com/docs/angular/) that covers a lot of use cases and I highly recommend to read it.\n\n\n---\n\n# Using DI to create Apollo\n\nAngular Console used an old way of initializing Apollo. In one of the recent versions of Apollo Angular I introduced `APOLLO_OPTIONS`, an InjectionToken that provides a configuration object to Apollo service. The old API caused an issue with a race condition where a service tried to use Apollo before it got created.\n\n\n[https://github.com/nrwl/angular-console/pull/158](https://github.com/nrwl/angular-console/pull/158 \"Use APOLLO_OPTIONS by kamilkisiela ¬∑ Pull Request #158 ¬∑ nrwl/angular-console\nHi guys, thanks for using Apollo! :) I refactored a bit the way you initialize Apollo. There‚Äôs a InjectionToken for it‚Ä¶github.com\")\n\nThat was the first, very small PR. Next PR brought more changes and was focused only on the server.\n\n# Apollo Server 2.0\n\nI replaced `express-graphql` with a more complete solution, Apollo Server. This move helped to improve developer experience by having a **built-in support for GraphQL Subscription**, file uploading and error handling. I‚Äôm pretty sure the team behind Angular Console have plans to take advantage of it and implement subscriptions in the app, for example to replace currently used polling technique.\n\n\n# Schema Definition Language\n\nSDL, in short, is a syntax that allows to define GraphQL Schema, so instead of using GraphQL‚Äôs API, you simply write everything as string.\n\nFor example, using `GraphQLObjectType` might look like this:\n\n\n```typescript\nnew GraphQLObjectType({\n  name: 'Post',\n  fields: {\n    id: {\n      type: GraphQLString\n    },\n    text: {\n      type: GraphQLString\n    }\n  }\n});\n```\n\nwith Schema Definition Language:\n\n```graphql\ntype Post {\n  id: String\n  text: String\n}\n```\n\nIn my opinion, it‚Äôs more convenient and way more intuitive to work with.\n\n# Keeping resolve functions separated from SDL\n\nIn our projects, we try to group resolvers by GraphQL type and have them nearby the corresponding schema definition.\n\nHaving both, type definition and resolve functions in the `GraphQLObjectType` looks like that:\n\n\n```typescript\nnew GraphQLObjectType({\n  name: 'Post',\n  fields: {\n    id: {\n      type: GraphQLString,\n      resolve: (parent) => parent._id\n    },\n    text: {\n      type: GraphQLString,\n      resolve: (parent) => parent.content\n    }\n  }\n});\n```\n\nI personally think it was a good choice because it forces developers to write logical part right next to type definition. The problem is, the bigger types the more confusing it gets. Also keeping resolvers as standalone functions makes them easier to test.\n\nWith Schema Definition Language, it‚Äôs looks way better.\n\n```typescript\nconst PostType = gql`\n  type Post {\n    id: String\n    text: String\n  }\n`;\n\nconst Post = {\n  id: (parent) => parent._id,\n  text: (parent) => parent.content\n};\n```\n\nHere are the relevant changes that I‚Äôve mentioned above, that allowed me to introduce something really interesting in the next PR.\n\n[https://github.com/nrwl/angular-console/pull/175](https://github.com/nrwl/angular-console/pull/175 \"Apollo Server 2.0, latest Apollo Angular, refactoring, SDL by kamilkisiela ¬∑ Pull Request #175 ¬∑‚Ä¶\nApollo Server 2.0 Latest Apollo Angular refactoring ‚Äî moved files under /api directory used SDL instead of classes from‚Ä¶github.com\")\n\n# Strongly typed resolvers\n\nWe love [TypeScript](https://typescriptlang.org) and we saw an opportunity to take our GraphQL servers to the next level. Instead of having `any` or defining interfaces for each resolver by hand, we decided to take advantage of one of our tools, called [GraphQL Code Generator](https://graphql-code-generator.com/) (thanks Dotan Simha for creating it).\n\n\nIn short, it‚Äôs a tool to generate pretty much any piece of code, based on a GraphQL Schema. We use it a lot, mostly for types (server and client) but also to create MongoDB models, introspection files, Angular components and more.\n\nIn Angular Console, I used the TypeScript plugins to generate types for a schema and also for GraphQL Resolvers. It‚Äôs one of the pieces that makes your code even more strongly typed, from end to end.\n\nHere‚Äôs how it might look like.\n\n```typescript\nimport { PostResolvers } from './generated-types';\n\nconst Post: PostResolvers.Resolvers = {\n  id: (parent) => parent._id,\n  text: (parent) => parent.content\n};\n```\n\n```typescript\nexport interface PostParent {\n  _id: string;\n  content: string;\n}\n```\n\nIf you want to take a look at the changes and read about GraphQL Code Generator:\n\n[https://github.com/nrwl/angular-console/pull/185](https://github.com/nrwl/angular-console/pull/185 \"Use code generation to generate types for resolver and whole schema by kamilkisiela ¬∑ Pull Request‚Ä¶\nIt makes resolvers strongly typed. You can also use it on the client side, to generate types for each GraphQL query and‚Ä¶github.com\")\n\nWe recently released another new version of the GraphQL Code Generator that fixed a lot of issues, introduced a feature called Mappers, made signatures of resolve functions more strict and handles multiple results in parallel.\n\n[https://github.com/nrwl/angular-console/pull/413](https://github.com/nrwl/angular-console/pull/413 \"\\[WIP] New GraphQL Code Generator by kamilkisiela ¬∑ Pull Request #413 ¬∑ nrwl/angular-console\nNew GraphQL Code Generator We changed the API a bit. It‚Äôs no longer required to use ‚Äî flags with CLI, the codegen‚Ä¶github.com\")\n\nThe GraphQL Code Generator is one powerful beast that enables any kind of code generation based just on GraphQL Schema (you can create your own custom generation templates).\n\n# Named operations\n\nGraphQL in most cases allows to use a shorthand syntax but putting a type and a name of an operation is very useful, simply for debugging and logging. It‚Äôs easier to track down a failed operation, because it‚Äôs no longer anonymous and by keeping all names unique you‚Äôre able to take advantage of any tool or service. One tool I described in the next chapter.\n\n# Strongly typed operations and code generation\n\nFetching data with Apollo Angular, requires few steps:\n\n-   Import `Apollo` service\n\n-   Inject the service in a component\n-   Define GraphQL operation\n-   Wrap the operation with the `gql` tag\n\n-   Call `Apollo.watchQuery` with the operation\n\n-   Get an `Observable` with data\n\n\nThat‚Äôs a lot, and in order to have everything strongly typed you even have to define extra interfaces that are specific for each operation.\n\n```typescript\nimport { Apollo } from 'apollo-angular';\nimport gql from 'graphql-tag';\n\ninterface Post {\n  id: string;\n  text: string;\n}\n\ninterface PostQuery {\n  post: Post;\n}\n\n@Component({...})\nexport class PostComponent {\n  @Input() postId: string;\n  post: Observable<Post>;\n  \n  constructor(private apollo: Apollo) {}\n  \n  ngOnInit() {\n    this.post = this.apollo.watchQuery<PostQuery>({\n      query: gql`\n        query getPost ($id: String!) {\n          post(id: $id) {\n            id\n            text\n          }\n        }\n     `,\n     variables: {\n       id: this.postId\n     }\n   })\n     .valueChanges\n     .pipe(\n       map(result => result.data.post)\n     );\n  }\n}\n```\n\nI wanted to share with Angular Console, something that we use and what helped to improve our workflow.\n\nOne interesting thing that we‚Äôre able to achieve is the [`apollo-angular` code-generator plugin](https://graphql-code-generator.com/docs/plugins/typescript-apollo-angular).\n\n\nIts main purpose is to generate strongly typed services for each GraphQL operation. Take a look at the following scientific visualization:\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*m0Qci4KAiAjj075wn5PJLw.gif?raw=true \"This is how magic happens.\")\n\nGiven the example I previously used, this is how it might look like with Apollo Angular plugin now.\n\n-   Write a query in a `.graphql` file\n\n-   Run the codegen _(has watch mode)_\n\n-   Use a **fully typed generated Angular service** directly in your component\n\n\n```graphql\nquery getPost ($id: String!) {\n  post(id: $id) {\n    id\n    text\n  }\n}\n```\n\n```typescript\nimport { GetPostGQL, Post } from './generated/graphql';\n\n@Component({...})\nexport class PostComponent {\n  @Input() postId: string;\n  post: Observable<Post>;  \n  \n  constructor(\n   private getPostGQL: GetPostGQL\n  ) {}\n  \n  ngOnInit() {\n    this.post = this.getPostGQL\n      .watch({ id: this.postId })\n      .valueChanges\n      .pipe(\n        map(result => result.data.post)\n      );\n  }\n}\n```\n\nAs you can see, we no longer use Apollo service directly (it‚Äôs used under the hood) and every operation has now strongly typed API.\n\nIt wouldn‚Äôt be possible without introducing this new API. I highly recommend to read an article linked below, it explains what it is and how it could be used with the codegen.\n\n[https://medium.com/the-guild/apollo-angular-code-generation-7903da1f8559](https://medium.com/the-guild/apollo-angular-code-generation-7903da1f8559 \"Apollo-Angular 1.2 ‚Äî using GraphQL in your apps just got a whole lot easier!\nCheck what‚Äôs new in Apollo Angular and how to get the full potential benefits of using Angular + GraphQL + TypeScript‚Ä¶medium.com\")\n\nI also prepared an explanation video that might help you to learn step by step, what code generation is and how to use it in a project.\n\n[https://www.youtube.com/watch?v=KGBPODrjtKA](https://www.youtube.com/watch?v=KGBPODrjtKA \"GraphQL Code Generator‚Ää - ‚ÄäAngular Apollo Template get the full potential benefits of using Angular + GraphQL + TypeScript combined thanks to GraphQL-Code-Generator. Generate a strongly typed Angular service, for every defined query, mutation or subscription, ready to use in your components!\")\n\nHere is the relevant PR introducing this change into Angular Console:\n\n[https://github.com/nrwl/angular-console/pull/219](https://github.com/nrwl/angular-console/pull/219 \"Use GraphQL Code Generator and Apollo Angular template by kamilkisiela ¬∑ Pull Request #219 ¬∑‚Ä¶\nAdds apollo-angular template of GraphQL Code Generator to produce strongly typed services with more convenient API and‚Ä¶github.com\")\n\n---\n\n[https://github.com/nrwl/angular-console/pull/263](https://github.com/nrwl/angular-console/pull/263 \"Renovate by kamilkisiela ¬∑ Pull Request #263 ¬∑ nrwl/angular-console\nWe use renovate in all of our projects, super helpful to update dependencies. One PR per monorepos, for example‚Ä¶github.com\")\n\n# Summary\n\nGraphQL is a very useful and fast growing technology. It helps with so many different use cases of developing applications, large and small. But don‚Äôt forget that the ecosystem of GraphQL is huge and there are a lot of extra tools and best practices that might make it even more useful!\n\nI hope this post was helpful for you to learn about some handy things in GraphQL.\n\nIf you want to read more about the GraphQL ecosystem and keep up with everything that happens around it, I would recommend also checking out [The Guild‚Äôs Medium publication](https://medium.com/the-guild).\n\n\n---\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*9McDGpqiVh3sZ_CK74sxXw.png?raw=true)\n\nIn this guest blog post by Kamil Kisiela for the [blog of Nrwl](https://blog.nrwl.io/) , Kamil covered the topic of the new Angular Console product. Nrwl is an Angular consulting, training and developer product firm. _If you like this, click the_ üëè s_o other people will see it. Follow [@‚Äãnrwl_io](https://medium.com/@nrwl_io) to read more!_\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*xBk9L_j521FRuqLTLjyFkg@2x.png?raw=true)\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"aa28b67376c9\",\"publishedDate\":1543616371782,\"url\":\"https://blog.nrwl.io/angular-console-graphql-aa28b67376c9\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDo0NjozMiswMTowMM4izpFh",
            "node": {
              "title": "Introducing Loona: Application State Management",
              "body": "## Loona is an application state management library for React and Angular. It helps you manage the local and remote data in a single store. It‚Äôs built with GraphQL and Apollo.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*Kxmlga18dE4w652C7mskUg.png?raw=true)\n\nMe and [**The Guild**](https://medium.com/the-guild) are very excited to introduce a library that dramatically improves and simplifies **managing your local and remote data**, both in **React** and **Angular**.\n\n\n> ### Hi, my name is Loona!\n\n# TL;DR\n\n-   State Management done with GraphQL and Apollo\n-   We took the best concepts from the Redux and Apollo worlds\n-   React and Angular\n-   [Website](https://loonajs.com/) and [Documentation](https://loonajs.com/)\n\n\n---\n\n[https://www.youtube.com/watch?v=479WD8OCTfs](https://www.youtube.com/watch?v=479WD8OCTfs \"GraphQL Anywhere, How GraphQL can improve your work across all your stack - Uri Goldshtein In this talk Uri will give a very short introduction about GraphQL and then dive deep into new use cases you probably haven't thought of where GraphQL fit in the picture and improve your developer life, even if you don't have a GraphQL backend at all!\")\n\n---\n\n# What is Loona\n\nLoona is a state management library built with **GraphQL** and [**Apollo**](https://apollographql.com). It takes some the of **Redux** / **NGRX** concepts and combines them with **Apollo Client.**\n\n\n> ### Loona works side by side with Apollo\n\nSo while you still get all the benefits from Apollo Client like _caching_, _offline persistence, normalized cache_ and more, on top of that you gain other benefits like **stream of actions** and **better separation** between executing a mutation and updating the store.\n\n\nInstead of having a second store for your local data, **keep everything in just one space**.\n\n\nWorks out of the box with [**React Native**](https://facebook.github.io/react-native/) and [**NativeScript**](https://www.nativescript.org/). It also supports [**Create React App**](https://github.com/facebook/create-react-app) and [**Angular CLI**](https://cli.angular.io/) (_has its own collection of schematics_).\n\n\n> ### We built it on top of Apollo Client which means setting everything up, including Links or even Cache, stays exactly the same.\n\nLoona can be described by few core concepts:\n\n-   [**Queries**](https://loonajs.com/docs/react/essentials/queries) ‚Äî ask for what you need\n\n-   [**Mutations**](https://loonajs.com/docs/react/essentials/mutations)  ‚Äî a way to modify your remote and local data\n\n-   **Store** ‚Äî a single source of truth of all your data\n\n\nIt also defines:\n\n-   [**Actions**](https://loonajs.com/docs/react/essentials/actions) ‚Äî declarative way to call a mutation or trigger an action\n\n-   [**Updates**](https://loonajs.com/docs/react/essentials/updates) ‚Äî modify the store after a mutation\n\n\nIt helps you to **keep every piece of your data‚Äôs flow separated**.\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*4zBAz2BmiRp3JbkkqXeUaA.png?raw=true \"Loona lives between the UI and the Apollo Client and intercepts queries and mutations through the Apollo Link.\")\n\n## How to get started\n\nFirst, you need to install Loona depending on a used framework.\n\n```\nyarn add @loona/react\n```\n\n```\nor\n```\n\n```\nyarn add @loona/angular\n```\n\nThen, you create Loona very similar to what you would do with Apollo.\n\n```javascript\nimport { createLoona, LoonaProvider } from '@loona/react';\n\nimport { InMemoryCache } from 'apollo-cache-inmemory';\nimport { ApolloClient } from 'apollo-client';\nimport { ApolloProvider } from 'react-apollo';\n\n// Instance of a cache\nconst cache = new InMemoryCache();\n\n// Create Loona Link\nconst loona = createLoona(cache);\n\n// Apollo\nconst client = new ApolloClient({\n  link: loona,\n  cache,\n});\n\nReactDOM.render(\n  <ApolloProvider client={client}>\n    <LoonaProvider loona={loona}>\n      <App />\n    </LoonaProvider>\n  </ApolloProvider>,\n  document.getElementById('root'),\n);\n```\n\n> I‚Äôm going to use React examples in the article, but same logic applies to Angular. The API is pretty much the same.\n\n# How does it compare with Apollo Link State?\n\nBut by extracting some logic from the resolvers, it introduces a new way of updating the store that allows to persist mutations with their side effects across page reloads or while app is offline.\nIn fact, the logic behind Effects (middleware) opened up Loona for all kinds of tooling and capabilities.\n\nIt also provide some helpers that are based on `Immer` so the whole experience is much better.\n\n\nBy keeping Loona close with Apollo Link State we are able to collaborate and improve both of them.\n\n# Play with Loona\n\nYou can find few examples in [our repository](https://github.com/kamilkisiela/loona/tree/master/examples) but we prepared a simple application that you can run and play with in the browser.\n\n\nOne written with **React**:\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*1DKdAbZxbgad-RTa1qaocA.png?raw=true \"Click to play with Loona and React\")\n\n**Angular** version:\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*NjQuoW139Gjt75c3FNBaFg.png?raw=true \"Click to play with Loona and Angular\")\n\n---\n\n# Loona, step by step\n\nNow since everything is ready, let‚Äôs take a closer look on what Loona does and why.\n\n## State\n\nState is a model that describes slice of your application‚Äôs state, with all possible mutations, queries and others. It‚Äôs important to keep it simple and easy to read.\n\n```typescript\nimport {state} from '@loona/react';\n\n@state()\nexport class BooksState {}\n```\n\nAs you can see, we use `state` decorator and a class to define a state.\n\n\n---\n\n## Queries\n\nQueries work just like in any other GraphQL client, you simply ask for data and receive it either from a cache or a network. Both, remote and local data can be used together in a query.\n\n```javascript\nimport React from 'react';\nimport { Query } from '@loona/react';\n\nimport { List } from '../common/List';\n\nconst ALL_BOOKS = gql`\n  query GetAllBooks {\n    books @client {\n      id\n      title\n    }\n  }\n`;\n\nexport function BooksList() {\n  return (\n    <Query query={ALL_BOOKS}>\n      {({ data, loading }) => {\n        if (loading) return '...';\n\n        return <List list={data.books} />;\n      }}\n    </Query>\n  );\n}\n```\n\nWe used a `Query` component but Loona also allows to use the HoC.\n\n\n```javascript\nimport {state} from '@loona/react';\n\n@state({\n  defaults: {\n    books: []\n  }\n})\nexport class BooksState {}\n```\n\nNow when `BooksList` component asks for data, it gets an empty array.\n\n\n> We also support Higher Order Components. [Learn more about queries](https://loonajs.com/docs/react/essentials/queries).\n>\n\n---\n\n## Mutations\n\nWhen mutation is called, Loona catches that and decides which part reaches the network and which stays on the client.\n\n```javascript\nimport {Mutation} from '@loona/react';\n\nconst ADD_BOOK = gql`\n  mutation AddNewBook($title: String!) {\n    addBook(title: $title) @client {\n      id\n      title\n    }\n  }\n`;\n\nconst NewBook = () => (\n  <Mutation mutation={ADD_BOOK}>\n    {(addBook) => (\n      <BookForm onBook={(title) => addBook({variables: {title}}) }>\n    )}\n  </Mutation>\n);\n```\n\nAnd here‚Äôs how you might update the store. Loona uses [`Immer`](https://www.npmjs.com/package/immer) and has few helpers to make writes and updates easier.\n\n\n```javascript\nimport { mutation } from '@loona/react';\n\nexport class BooksState {\n  @mutation('addBook')\n  addBook(args, context) {\n    // our new book\n    const book = {\n      id: generateRandomId(),\n      title: args.title,\n      __typename: 'Book',\n    };\n\n    // updates the store with help of Immer\n    context.patchQuery(\n      gql`\n        {\n          books {\n            id\n            title\n          }\n        }\n      `,\n      data => {\n        data.books.push(book);\n      },\n    );\n\n    return book;\n  }\n}\n```\n\n> [Read more about Mutations on our website](https://loonajs.com/docs/react/essentials/mutations)\n>\n\n---\n\n## Actions\n\nThink of an Action as a declarative way to call a mutation or to trigger a different action based on some behavior.\n\nLet‚Äôs take a look at the example. Here‚Äôs our action called `AddBook`:\n\n\n```javascript\nexport class AddBook {\n  static type = '[Books] Add';\n\n  constructor(public title: string) {}\n}\n```\n\nLoona has an `Action` and `connect` components:\n\n\n```javascript\n//\n// Using Action component\n// \n\nimport { Action } from '@loona/react';\n\nexport const NewBook = () => (\n  <Action>\n    {dispatch => (\n      <button onClick={() => dispatch(new AddBook('Harry Potter'))}>\n        Add Harry Potter\n      </button>\n    )}\n  </Action>\n);\n\n\n//\n// Using connect HOC\n//\n\nimport {connect} from '@loona/react';\n\nconst NewBookView = ({addBook}) => (\n  <button onClick={() => addBook('Harry Potter')}>Add Harry Potter</button>\n);\n\nconst actions = dispatch => ({\n  addBook: title => dispatch(new AddBook(title)),\n});\n\nexport const NewBook = connect(actions)(NewBookView);\n```\n\nIn the example above, we dispatched an action and as the `type` says, it should somehow add a new book to the list.\n\n\n## Effect\n\nTo listen for an action we have a concept called [**effects**](https://loonajs.com/docs/react/essentials/effects)  (works for both, actions and mutations).\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*aDAYavALDVgLLgAy8Q-vIg.png?raw=true \"UI dispatches an Action and Effects are called. An effect can mutate / update the store or even dispatch another action. UI gets updated too.\")\n\n```typescript\nimport {effect} from '@loona/react';\n\nexport class BooksState {\n  @effect(AddBook)\n  bookAdded(action, context) {\n    console.log(action);\n    // outputs:\n    // {\n    //   type: '[Books] Add',\n    //   title: '...'\n    // }\n\n    // Update the store: \n    context.patchQuery(...);\n\n    // Dispatch another action:\n    context.dispatch(new DifferentAction());\n  }\n}\n```\n\n> It‚Äôs also possible to [dispatch a mutation](https://loonajs.com/docs/react/advanced/mutation-as-action). [More about Actions on the website](https://loonajs.com/docs/react/essentials/actions).\n>\n\n---\n\n## Updates\n\nUpdate allows to modify the data based on a mutation.\n\nThe whole idea behind Updates is to keep store updates separated from mutations. Updates work for remote and local mutations.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*OuyCtBqAMq_G9WYzQi4IYg.png?raw=true \"Update runs synchronously, every time mutation happens. They work also for remote calls.\")\n\n**What are the benefits of using Updates?**\n\n\n-   you no longer keep the code responsible for store updates inside of your components\n-   it scales easier\n-   keeps the code clean\n-   allows to execute them even after mutation that has been persisted, did run again\n\n> ### This is probably **the most important piece** of Loona‚Äôs data flow.\n>\n\n```javascript\nexport class BooksState {\n  // It does nothing except creating a new book\n  @mutation('addBook')\n  addBook(args, context) {\n    return {\n      id: generateRandomId(),\n      title: args.title,\n      __typename: 'Book',\n    };\n  }\n\n  // This part adds a book to the list\n  @update('addBook')\n  addToBooks({result}, context) {\n    context.patchQuery(\n      gql`\n        {\n          books\n        }\n      `,\n      data => {\n        data.books.push(result);\n      },\n    );\n  }\n  \n  // you can add more updates\n  @update('addBook')\n  anotherUpdate({result}, context) {\n    ...\n  }\n}\n```\n\nIn the example above, we separated two things:\n\n-   creation of a book _(happens in the mutation)_\n\n-   adding a book to the list _(happens in the update)_\n\n\n**Why would we need _many_ Updates?**\n\n\nImagine a state that not only has a list of books but also holds a recently added one. Instead of having two updates in the mutation resolver we can scale that and pass the book to any function.\n\n> [We covered Updates](https://loonajs.com/docs/react/essentials/updates) in the documentation.\n>\n\n# About the API\n\nLoona **doesn‚Äôt require decorators**, it provides an API to consume the state without them.\n\n\nIf it comes to consuming data in the UI, we decided to enhance and reuse `Query`, `Mutation` and `Subscription` components of `react-apollo` and also provide two helpful Higher Order Components: `graphql` and `connect`.\n\n\nTo learn how to use those components, we prepared a chapter in our [documentation](https://loonajs.com/docs/react/api/components).\n\n\n# How does it compare with other libraries?\n\n## Make it work offline\n\nWith Loona and Apollo you‚Äôre able to **persist the cache** and restore it on every page load.\n\n\n```jsx\nimport React from 'react';\nimport { Mutation } from '@loona/react';\n\nexport default props => (\n  <Mutation mutation={ADD_BOOK}>\n    {addBook => (\n      <button onClick={() => addBook({\n        variables: {\n          title: props.title\n        },\n        // update() {\n        //   we keep it all inside of the state class\n        //   otherwise it would be hard to persist those store updates\n        // }\n      })}> Submit </button>\n    )}\n  </Mutation>\n);\n```\n\nThanks to keeping the logic responsible of store updates, outside of a component, we‚Äôre able to **persist mutations across page reloads** or while an app is offline and rerun them once it‚Äôs up again. The whole chain of actions and updates will then continue.\n\n\n## Smart store\n\nThe store is smart enough to re-render only components affected by an update. Thanks to **keeping data normalized** you can mutate an entity and the store will update every reference.\n\n\n```javascript\nconst bookFragment = gql`\n  fragment book on Book {\n    id\n    title\n    liked\n  }\n`;\n\nconst LIBRARY = gql`\n  query library {\n    books {\n      ...book\n    }\n    authors {\n      id\n      name\n      books {\n        ...book\n      }\n    }\n  }\n\n  ${bookFragment}\n`;\n\nexport class BooksState {\n  @mutation(TOGGLE_LIKE_BOOK)\n  likeBook({ id }, {patchFragment}) {\n    return patchFragment(book, {id}, book => {\n      book.liked = !book.liked;\n    });\n  }\n}\n```\n\nIt would be hard to keep a list of books and their authors in a structure as shown above in Redux-like libraries and to still be able to update everything easily by touching only a single book.\n\nBecause the data is **normalized** **stored flat** it is super straightforward to do it in Loona. Having helpers like `patchQuery` and `patchFragment` that uses [`immer`](http://npmjs.com/package/immer) internally helps a lot too.\n\n\n## Single source of truth\n\nWhen using GraphQL with Redux or any other state management library it‚Äôs hard to keep two stores in sync. With Loona you keep everything in one place and local data can enhance the remote one.\n\n## Unified interface of all data\n\nYou access data in the same way across the whole application and thanks to Apollo Link, for example `apollo-link-rest`, you can include other source of data too.\n\n\nYou can even enhance the server-side operations with your local state and fetch everything in a single query.\n\n## Built-in solutions\n\nNo need to implement things like **Caching** or **Optimistic UI** yourself, it‚Äôs part of Apollo and Loona.\n\n\n## Lazy loading\n\nIt‚Äôs also possible to provide a lazy loaded state when using code-splitting\n\n## Easy static type generation\n\nTools like [GraphQL Code Generator](https://github.com/dotansimha/graphql-code-generator) produce interfaces for every piece of data making your application **strongly typed**.\n\n\n## Share the same tools\n\nBy using GraphQL for client-side state you can reuse already existing tools.\n\n## Explore the state of your application\n\nThanks to Apollo Dev Tools you can see your remote schema stitched together with the client-side part.\n\n**Works with other Apollo Links** Loona wraps Apollo Client and has its own Apollo Link. Thanks to that it‚Äôs easy to use Loona with other Apollo Links.\n\n\n---\n\n# We‚Äôre open for your feedback!\n\nWe‚Äôd be happy to hear your feedback so we could improve Loona and figure out the direction of using GraphQL for local state management **together, with the whole community,** not only React‚Äôs but from other frameworks like Angular or Vue.\n\n\nWe also want to collaborate with the **Apollo Team** on shaping the best way to manage local state with GraphQL and maybe even add parts of our solution into a future Apollo Client release.\n\n\n-   [Website](https://loonajs.com)\n\n-   [GitHub repository](https://github.com/kamilkisiela/loona)\n\n-   Examples for [React](https://github.com/kamilkisiela/loona/tree/master/examples/react/) and [Angular](https://github.com/kamilkisiela/loona/tree/master/examples/angular/)\n\n\n---\n\n[https://medium.com/the-guild](https://medium.com/the-guild \"The Guild\nThe Guild on medium.com\")\n\n> _Follow us on [**GitHub**](https://github.com/the-guild-org) (check each person individually) and [**Medium**](https://medium.com/the-guild)**.** we are planning to release many more posts in the next couple of weeks about what we‚Äôve learned using **GraphQL** in recent years._\n>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"77baf6734f1\",\"publishedDate\":1541520469757,\"url\":\"https://medium.com/the-guild/loona-state-management-graphql-77baf6734f1\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDo0NTo0OSswMTowMM4izo_s",
            "node": {
              "title": "Apollo-Angular 1.2 ‚Äî using GraphQL in your apps just got a whole lot easier!",
              "body": "_Check what‚Äôs new in Apollo Angular and how to get the full potential benefits of using Angular + GraphQL + TypeScript combined thanks to GraphQL-Code-Generator._\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*uNJMkGOWodBQKubVRVCP0A.png?raw=true \"GraphQL Code Generator ‚Äî Angular Apollo Template\")\n\nWe are very excited to announce a new version of Apollo Angular that dramatically improves and simplifies the usage of GraphQL with Angular.\n\nThis version also adds production and scale related features, that our large Enterprise and production users had been asking for.\n\n# TL;DR\n\n-   [Code generation for Apollo Angular](https://graphql-code-generator.com/docs/plugins/typescript-apollo-angular)\n\n-   Query, Mutation, Subscription as an Angular service\n-   [Apollo Angular Boost](https://www.npmjs.com/package/apollo-angular-boost)\n\n-   Testing tools\n\n---\n\n[https://www.youtube.com/watch?v=KGBPODrjtKA](https://www.youtube.com/watch?v=KGBPODrjtKA \"GraphQL Code Generator‚Ää - ‚ÄäAngular Apollo Template get the full potential benefits of using Angular + GraphQL + TypeScript combined thanks to GraphQL-Code-Generator. Generate a strongly typed Angular service, for every defined query, mutation or subscription, ready to use in your components!\")\n\n---\n\n# Introducing Query, Mutation and Subscription as an Angular services\n\nThrough almost two years of using GraphQL in Angular we gained a lot of experience, and learned how people use the library.\n\nWith the current API, having `query` and `watchQuery` methods sometimes confused a lot of developers. For people who use Apollo for long time it‚Äôs obvious but we often get asked about differences between them and many newcomers are surprised.\n\n\n> ### We decided to add a new approach of working with GraphQL in Angular.\n\n```typescript\nimport { Injectable } from '@angular/core';\nimport { Query } from 'apollo-angular';\nimport gql from 'graphql-tag';\n\n@Injectable({...})\nexport class FeedGQL extends Query {\n  document = gql`\n    query Feed {\n      posts {\n        id\n        title\n      }\n    }\n  `\n}\n```\n\nThere are now 3 new simpler APIs: `Query`, `Mutation` and `Subscription`. Each of them allows to define the shape of a result & variables.\n\n\nThe only thing you need to do is to set the `document` property, That‚Äôs it, and now you use it as a regular Angular service:\n\n\n```typescript\nimport { Component } from '@angular/core';\nimport { FeedGQL } from './feed-gql.ts';\n\n@Component({ ‚Ä¶ })\nexport class FeedComponent {\n  constructor(feedGQL: FeedGQL) {\n    feedGQL.watch()\n       .valueChanges\n       .subscribe(result => {\n         // ...\n       })\n  }\n}\n```\n\nIn our opinion, the new API is more intuitive and documents feels now like a first class-citizens.\n\n> ### But it also opens up the doors for something wayyyyy cooler!\n\n# Taking it to the next level\n\nAs an Angular developer, you already understand how much power Typescript adds to your development ‚Äî the Angular community took those capabilities to the next level with code generation, through things like schematics.\n\nThe GraphQL community also took the concept of static type capabilities into new places ‚Äî over the API and managing data automatically at runtime with the query language.\n\nWhile using GraphQL, Typescript and Angular and maintaining `apollo-angular` in the past 2 years we always keep thinking how can we get all those technologies closer to create something that is more powerful than the sum of its parts.\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*Ur68qpIO4w26oNRZTQFAKA.gif?raw=true \"Ever wondered how GraphQL Code Generator works?\")\n\n# GraphQL Code Generator for Apollo Angular\n\nWe are pleased to announce a new set of tools that takes the GraphQL schema from the server and the query from the Angular component and generate everything in the middle for you!\n\nJust by consuming a static GraphQL schema and defining the data you need and its structure in a GraphQL Query, there is no need for you to write any Typescript! You already defined it, why writing it again?\n\nWe will generate a strongly typed Angular service, for every defined query, mutation or subscription, ready to use in your components!\n\n## How it works\n\nYou create a `.graphql` file with a document that you want to use in a component:\n\n\n```\nquery Feed {\n  posts {\n    id\n    title\n  }\n}\n```\n\nNext, you run the [**GraphQL Code Generator ‚Äî Angular Apollo Plugin**](https://graphql-code-generator.com/docs/plugins/typescript-apollo-angular)  to generate types and angular services.\n\n\nThen you simply import and use it as a regular, Angular service.\n\n```\nimport { FeedGQL } from './generated';\n```\n\n> GraphQL Code Generator takes query‚Äôs name, makes it PascalCased and adds GQL suffix to it. An example, ‚ÄúmyFeed‚Äù becomes ‚ÄúMyFeedGQL‚Äù.\n\nSee it here in action and play with it:\n\n[https://stackblitz.com/edit/apollo-angular-code-generator-example?embed=1&file=app/list.component.ts](https://stackblitz.com/edit/apollo-angular-code-generator-example?embed=1&file=app/list.component.ts \"apollo-angular-code-generator-example - StackBlitz\nAuto generated apollo-angular services. Posts and Authors - new Apollo Angular GraphiQL‚Ä¶stackblitz.com\")\n\nTo play with code generator try to clone this repository:\n\n[https://github.com/kamilkisiela/apollo-angular-services](https://github.com/kamilkisiela/apollo-angular-services \"kamilkisiela/apollo-angular-services\napollo-angular-services - Write .graphql files, use them as auto generated Angular services.github.com\")\n\nUsing Angular, Typescript and GraphQL in a coordinated way, gives us new level of simplicity and power for our developer experience:\n\n-   **Less code to write** ‚Äî no need to create a network call, no need to create Typescript typings, no need to create a dedicated Angular service\n\n-   **Strongly typed out of the box** ‚Äî all types are being generated, no need to write any Typescript definitions and struggle to keep them updated\n\n-   **Full developer experience of tools and IDEs** ‚Äî development time autocomplete and error checking, not only across your frontend app but also with your API teams!\n\n-   **Tree-shakable** thanks to Angular 6\n\n\n# More thanks to GraphQL\n\nWe believe GraphQL is a game changer in how you plan and create your frontend apps.\n\nThe vision that guides us is that you should be able to sketch a list of data types your backend can provide, sketch components and their data dependencies ‚Äî and all the rest of the plumbing can be generated for you.\n\nOnce you‚Äôll write an app like that, you will ask yourself why did you write all the other boilerplate code by yourself before.\n\nBut we‚Äôve just talked about one new feature in apollo-angular. there is more:\n\n-   **Testing utilities** There were a lot of questions about testing Apollo components, so we decided to finally release something with a similar API to the one Angular‚Äôs `HttpClient` uses. [Sergey Fetiskin](https://medium.com/@sergeyfetiskin?source=post_header_lockup) wrote [an article about it](https://medium.com/@sergeyfetiskin/testing-apollo-graphql-in-your-angular-application-595f0a04aad3).\n\n-   **Apollo Angular Boost** It‚Äôs hard for newcomers to get started with Apollo Angular. Inspired by Apollo Boost we decided to create an Angular version of it. Here‚Äôs [an interactive example](https://stackblitz.com/edit/simple-apollo-angular-boost-example).\n\n-   **Create Apollo on DI level** There is now an extra way to create Apollo Client. Instead of using `Apollo.create` inside of a constructor, you can provide settings on Dependency Injection level. Read the [‚ÄúUsing Dependency Injection‚Äù](https://www.apollographql.com/docs/angular/basics/setup.html#using-dependency-injection) chapter in docs.\n\n-   **GraphQL Subscription outside NgZone** Apollo.subscribe accepts now a second argument in which you can enable running subscription‚Äôs callback outside NgZone.\n\n-   **Automatic Persisted Queries for Angular** It‚Äôs now possible to use APQ with Angular‚Äôs HttpClient, just install [this package](http://apollo-angular-link-persisted).\n\n\n---\n\n-   Query and Mutation as a service on [StackBlitz](https://stackblitz.com/edit/apollo-angular-services) and [GitHub](https://github.com/kamilkisiela/apollo-angular-services)\n\n-   Query and Mutation ‚Äî [Step by step tutorial](https://github.com/kamilkisiela/apollo-angular-introduction)\n\n-   Example: [Apollo Angular Boost on StackBlitz](https://stackblitz.com/edit/basic-apollo-angular-app)\n\n-   [Apollo Angular repository](https://github.com/apollographql/apollo-angular)\n\n-   [Documentation](http://apollographql.com/docs/angular/basics/services.html)\n\n\n> Follow us on **GitHub** and **Medium**, we are planning to release many more posts in the next couple of weeks about what we‚Äôve learned using **GraphQL** in recent years.\n>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"7903da1f8559\",\"publishedDate\":1534869699627,\"url\":\"https://medium.com/the-guild/apollo-angular-code-generation-7903da1f8559\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDo0NToxMCswMTowMM4izo6c",
            "node": {
              "title": "Apollo Angular 0.11",
              "body": "## New name, AoT support, TypeScript improvements, and Angular 4 readiness\n\nWe recently released version`0.11.0`of [apollo-angular](http://github.com/apollographql/apollo-angular) and a lot of things have changed and improved since our last update blog!\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*7xPa2S4ifdRYkUE1Oz5RZQ.png?raw=true)\n\nFirst, here is a overview list of the main changes:\n\n-   New name\n-   Support for Apollo Client 0.8+\n-   AoT support\n-   Multiple Apollo Client instances in a single app\n-   TypeScript improvements and TypeScript codegen\n-   Apollo Client Developer Tools\n-   ES6 Modules and Tree Shaking\n-   Support for Angular 4\n\nSo let‚Äôs dive into it!\n\n---\n\n# New name\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*x6ACBRKGlFSaoovTNaU1-w.png?raw=true \"After years of research we discovered a secret formula\")\n\nAs you all know, the term ‚ÄúAngular 2‚Äù is [no longer a thing](http://angularjs.blogspot.com/2017/01/branding-guidelines-for-angular-and.html), now it‚Äôs just ‚ÄúAngular‚Äù, without the version suffix (#justAngular). So we renamed the package to be **‚Äúapollo-angular‚Äù**. We really wanted ‚Äúangular-apollo‚Äù to match up with `react-apollo`, but it was already taken. That means that from now on the ‚Äúangular2-apollo‚Äù package is deprecated.\n\n\nWe‚Äôve applied this rule to the service as well, so there is no ‚ÄúAngular2Apollo‚Äù anymore. It‚Äôs just **Apollo**. Simpler and more convenient. The migration process is very simple:\n\n\n```typescript\nimport { Angular2Apollo } from 'angular2-apollo';\n\nclass AppComponent {\n  constructor(\n    apollo: Angular2Apollo\n  ) {}\n}\n```\n\n```typescript\nimport { Apollo } from 'apollo-angular';\n\nclass AppComponent {\n  constructor(\n    apollo: Apollo\n  ) {}\n}\n```\n\n---\n\n# Apollo Client 0.8\n\nWe‚Äôve updated our dependency to apollo-client 0.8 which includes a lot of improvements in size and performance. check out the full list [here](https://dev-blog.apollodata.com/apollo-client-0-8-e8db5efc75fb).\n\n\n---\n\n# Ahead-of-Time Compilation\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*ufLuV-NiEVVx2SmVicrF0A.png?raw=true \"Ahead-of-Time Compilation\")\n\nOne of the most interesting features of Angular is Ahead-of-Time compilation. Angular‚Äôs compiler converts the application, components, and templates to executable JavaScript code at build time. AoT compilation improves the size of the app as well as the performance and stability thanks to static-code analysis at build time.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*uSC5IDVm0nlUoLOjdwwbfA.png?raw=true \"Just-In-Time Compilation\")\n\nTo support this feature, we had to change the way of providing ApolloClient to ApolloModule. Instead of using an instance of ApolloClient directly, it has to be wrapped with a function. Here‚Äôs an example:\n\n```typescript\nimport { ApolloClient } from 'apollo-client';\nimport { ApolloModule } from 'apollo-angular';\n\nconst client = new ApolloClient();\n\nfunction provideClient() { return client; }\n\nApolloModule.withClient(provideClient);\n```\n\n---\n\n# Multiple clients\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*dFmjEuSKwZgIe4RMZKt7Uw.png?raw=true \"Apollo service\")\n\nWe‚Äôre happy to introduce a support for multiple clients. Yes, it‚Äôs now possible to use many instances of the ApolloClient inside of the ApolloModule, meaning you can call multiple GraphQL endpoints from your single client app.\n\nThe use case for this feature came from some of our enterprise users. Some common use cases are when working with a server endpoint as well as a 3rd party API, or in case you are calling multiple microservices GraphQL endpoints from on client app. While it‚Äôs always better to have all of your data in one GraphQL service to be able to get all of the data you need in one request, sometimes it‚Äôs unavoidable to have to call multiple APIs.\n\nWe decided to make it as an optional feature and to implement it in a way that doesn‚Äôt break your existing app. Let me explain how it works. First thing, you need to define a function to return a map of clients:\n\n```typescript\nfunction provideClients() {\n  return {\n    default: defaultClient,\n    extra: extraClient\n  };\n}\n```\n\nThen, you can use a new method of ApolloModule called **forRoot** to provide clients, so you can use it in your app:\n\n\n```\nApolloModule.forRoot(provideClients)\n```\n\nThe `Apollo` service has now two new methods: `use()` and `default()`. First one takes a key of a client you want to use, second one returns the default client.\n\n\n```typescript\n\nclass AppComponent {\n  apollo: Apollo;\n  \n  ngOnInit() {\n    // uses the defaultClient\n    this.apollo.watchQuery({...}).subscribe(() => {});\n    \n    // works the same as the one above\n    this.apollo.default().watchQuery({...}).subscribe(() => {});\n    // uses the extraClient\n    this.apollo.use('extra').watchQuery({...}).subscribe(() => {});\n  }\n}\n\n```\n\n> It‚Äôs important to know that if you want to have a default client, you need to use`default` as a key.\n>\n\n---\n\n# More control\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*NC-dIAE-NRwfPwkjnlIxVA.png?raw=true \"We improved integration between frameworks\")\n\nApollo-Client and Apollo-Angular both are written in TypeScript, but we still had room for improvements for our users, here are some of them.\n\nThanks to [the recent change](https://github.com/apollographql/apollo-client/pull/914) we were able to take advantage of TypeScript‚Äôs feature called **Generic Types**. It‚Äôs now possible to easily define an interface of the ‚Äúdata‚Äù property in methods like _watchQuery_, _query_, _mutation_ and many more.\n\n\nThis gives you **more control** over the code, making it **more predictable** and easier to **prevent bugs.** Take a look at an example.\n\n\n```typescript\nconst query = gql`\n  query currentUser {\n    currentUser {\n      name\n    }\n  }\n`;\n\ninterface User {\n  name: string;\n}\n\ninterface Data {\n  currentUser: User;\n}\n\nclass AppComponent {\n  apollo: Apollo;\n  currentUser: User;\n  \n  ngOnInit() {\n    this.apollo.watchQuery<Data>({ query })\n      .subscribe((result) => {\n        this.currentUser = result.data.currentUser;\n      });\n  }\n}\n```\n\nIt‚Äôs very helpful and convenient, especially when used with RxJS operators. You gain more control over the result modifications. But there are even more improvements!\n\n## Let‚Äôs talk about observables\n\nIn Angular world, we commonly use RxJS. Unfortunately, Apollo‚Äôs standard observable shim is not compatible with RxJS, so to have the best developer experience, we created the ApolloQueryObservable. They both behave the same, containing the same methods (like refetch for example), except the RxJS support.\n\nWe recently changed the logic of the ApolloQueryObservable‚Äôs generic type. Here‚Äôs an example to see how to migrate:\n\n```typescript\nclass AppComponent {\n  user: ApolloQueryObservable<ApolloQueryResult<Data>>;\n  \n  getUser() {\n    this.user.subscribe((result) => {\n      // result is of type ApolloQueryResult<Data>\n    });\n  }\n}\n```\n\n```typescript\nclass AppComponent {\n  user: ApolloQueryObservable<Data>;\n  \n  getUser() {\n    this.user.subscribe((result) => {\n      // result is of type ApolloQueryResult<Data>\n    });\n  }\n}\n```\n\n## It is human nature to be lazy\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*IFc90ZHGCi96R2ofXRdrSw.png?raw=true)\n\nWe love automation, just to avoid keep repeating the same things on and on again. I have a great news for you!\n\nAs we know, GraphQL is strongly typed, so we have created a tool to **generate API code or type annotations based on a GraphQL schema and query documents**. This tool is called [‚Äúapollo-codegen‚Äù](https://github.com/apollographql/apollo-codegen).\n\n\nThanks to Robin Ricard‚Äôs work, Apollo Codegen now supports TypeScript, so Angular developers no longer have to define types for their queries manually.\n\n\n## Better Developer Experience\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*0Bwu5g2JhkjSX0O63h9w8w.png?raw=true)\n\nWe are happy to announce that Angular integration works great with the [**Apollo Client Developer Tools**](https://dev-blog.apollodata.com/apollo-client-developer-tools-ff89181ebcf).\n\n\nIt‚Äôs a Chrome DevTools extension for Apollo Client which has 3 main features:\n\n-   A built-in GraphiQL console that allows you to make queries against your GraphQL server using your app‚Äôs network interface directly (no configuration necessary).\n-   A query watcher that shows you which queries are being watched by the current page, when those queries are loading, and what variables those queries are using.\n-   A cache inspector that displays your client-side Redux store in an Apollo-Client-friendly way. You can explore the state of the store through a tree-like interface, and search through the store for specific field keys and values.\n\nTry the dev tools in your Angular Apollo app today!\n\n---\n\n# ES6 Modules and Tree Shaking\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*d97zDD9vgj3xfIr6-BZO7A.png?raw=true \"UMD bundle and ES6 Modules\")\n\nApp load time is an important part of the overall user experience. Earlier, I talked about AoT compilation, which radically improves performance, but there is still room to speed things up.\n\nTo make our app even smaller we can use a process called **Tree Shaking**. It basically follows the trail of import and export statements by statically analyzing the code. This way we get rid of unused parts of the application.\n\n\nAs you know, every angular package has a **UMD bundle** (to support **CommonJS** and **AMD**) and a separate space for **ES6 Modules**. Thanks to recent changes in the [apollo-client](https://github.com/apollographql/apollo-client/pull/1069) and [apollo-client-rxjs](https://github.com/kamilkisiela/apollo-client-rxjs/pull/16), we do the same, so you can use tree shaking in your app!\n\n\n---\n\n# Ready for the future\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*h4ek1STf_eO9XhJOamIXMQ.png?raw=true \"Coming out in March 2017\")\n\nWith the first stable version of Angular, the core team announced a predictable release schedule. It means that every 6 months there‚Äôs going to be a new major version of the framework.\n\nWe have good news!\n\n**Angular 4.0.0** is now still in beta but it‚Äôs **fully compatible with Apollo** so you don‚Äôt have to worry about any breaking changes.\n\n\n# Keep improving\n\nWe are working hard to give Angular developers the best developer experience we can. We want to hear more from you ‚Äî what should we do next, what can we improve?\n\nAnd if you are really interested in GraphQL, Did you know [Apollo is hiring](https://www.meteor.com/careers#open-source-engineer)?\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"54d3aedd2c9a\",\"publishedDate\":1488387895902,\"url\":\"https://blog.apollographql.com/apollo-angular-0-11-54d3aedd2c9a\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDoxNToxOSswMTowMM4izlSw",
            "node": {
              "title": "GraphQL CLI is back! Your Swiss Army Knife for the GraphQL ecosystem",
              "body": "![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*_7z5TiN1g22xJpdOQbfZ1Q.gif?raw=true)\n\n# GraphQL CLI is back! Your Swiss Army Knife for the GraphQL ecosystem\n\n## Production-ready GraphQL app in seconds\n\n# TL;DR;\n\n-   [GraphQL CLI](https://github.com/urigo/graphql-cli) is a **popular command-line tool** providing various tools for creating and maintaining GraphQL based applications\n\n-   [Prisma recently transferred the project to The Guild](https://www.prisma.io/blog/the-guild-takes-over-oss-libraries-vvluy2i4uevs) ‚Äî and we **completely rewrote** it and closed over 100 issues\n\n-   We‚Äôve already fixed and added many commands but we are looking to **learn and integrate** with tools and companies **across the ecosystem!**\n\n-   You can now generate a **full stack working app**, from a GraphQL schema **model**, in **2 minutes** using the init+generate commands!\n\n-   This is an alpha phase ‚Äî **we want your feedback**, as a user and as a tool creator ‚Äî Please [create an issue](https://github.com/Urigo/graphql-cli/issues/new/choose) and [join our Discord channel](https://discord.gg/xud7bH9)\n\n\n---\n\n[https://youtu.be/NDrPeQB1v5w](https://youtu.be/NDrPeQB1v5w \"GraphQL CLI - Generate Full Stack GraphQL Application in minutes See how GraphQL CLI can make your daily lives easier with just a few commands. Learn more in https\\://github.com/Urigo/graphql-cli\")\n\n# Overview\n\nThe GraphQL CLI provides:\n\n1.  Helpful commands to improve your daily workflows, from starting a project to maintaining it for the long run\n1.  Rich ecosystem and compatibility with libraries, editors and IDEs based on a unified [graphql-config](https://medium.com/the-guild/graphql-config-708dd0e5d15f)\n\n1.  A powerful plugin system to extend GraphQL CLI with custom commands ‚Äî supported by the community and The Guild\n\n> ### The main target of the GraphQL CLI is to provide a default entry point for the community to use proven techniques for building and deploying GraphQL enabled applications while being vendor agnostic.\n\nAdvanced developers and tool creators can **extend** [graphql-cli](https://github.com/urigo/graphql-cli) to provide additional capabilities while still benefiting from a robust set of default commands for daily use ‚Äî We want to use the CLI to encourage open collaborations between different tool creators.\n\n\n---\n\n# History\n\nOver the years the GraphQL ecosystem flourished and evolved towards more production-ready use cases with a large number of active community packages available.\n\nGraphQL evolved thanks to the large community and the many supporting libraries it has created.\n\nThe GraphQL CLI has become a place for the community to share ideas and best practices across different solutions and libraries thanks [to the push from Prisma](https://www.prisma.io/blog/new-tooling-to-improve-your-graphql-workflows-7240c81e1ba3).\n\n\n[The Guild took over GraphQL CLI](https://www.prisma.io/blog/the-guild-takes-over-oss-libraries-vvluy2i4uevs) to continue on that promise:\n\n\n-   Making it as easy as possible create and deploy GraphQL based applications\n-   Making it easier to maintain production-grade, scalable GraphQL applications\n\nAll of that while:\n\n-   Keeping the CLI updated with the latest solutions and practices\n-   Making it extensible and configurable without any solution bias ‚Äî any approach and architecture could easily integrate and benefit from the CLI\n-   Keeping the industry leading, long term open source library maintenance standard that The Guild is known for\n\n---\n\n# Try it out today\n\nWe‚Äôve already refactored most of the code, created a new structure, closed and fixed all the known issues and released a new alpha version.\n\nInstall new version (follow the latest alpha in the [releases page](https://github.com/Urigo/graphql-cli/releases)):\n\n\n```\n$ npm install graphql-cli@canary\n```\n\nCreate a new project with GraphQL CLI by running:\n\n```\n$ graphql init\n```\n\nGraphQL CLI will guide you and after only few seconds, your project will be ready to use!\n\n---\n\n# **End-to-end type safety**\n\n\nCode generation + end-to-end type safety is a hot topic nowadays. Thanks to tools like [**GraphQL Code Generator**](https://graphql-code-generator.com) we‚Äôre able to produce flexible code for both backend and frontend, just from GraphQL Schema and Operations with Fragments.\n\n\nIn GraphQL CLI, you get it out of the box by running:\n\n```\n$ graphql codegen\n```\n\n> _Discover what can be generator on [GraphQL Codegen website](https://graphql-code-generator.com)._\n>\n\n# Production ready GraphQL Backend\n\nThanks to integration with [**GraphBack**](https://graphback.dev/), you‚Äôre able to produce an entire Data Base, GraphQL schema with operations and strongly typed resolvers.\n\n\n```\n$ graphql generate\n```\n\n> Take a look at [GraphBack website](https://graphback.dev/) to learn more.\n>\n\n# Bulletproof your GraphQL API\n\nGraphQL CLI comes with most of the features of [**GraphQL Inspector**](https://graphql-inspector.com)**.**\n\n\nWith just few simple commands you‚Äôre able to:\n\n-   detect breaking or dangerous changes\n-   validate Operations and Fragments at build time\n-   analyze the usage of GraphQL Schema (unused types and fields)\n-   find duplicates and similar GraphQL Types\n-   serve faked GraphQL schema\n\n```\n$ graphql diff\n$ graphql similar\n$ graphql validate\n$ graphql coverage\n$ graphql serve\n```\n\n> Visit [GraphQL Inspector docs](https://graphql-inspector.com).\n>\n\n---\n\n# This is just the start!\n\nThe GraphQL CLI has been rewritten in order to make it extremely customizable and extensible.\n\nOur goal is to make sure that any tool can work and benefit from this setup.\n\nThe CLI offers freedom for anyone to create any command that will extend their workflows by creating separate library. Alternatively you can open a conversation about new command that can be included into our supported set of commands.\n\nIf you prefer to use all of the Apollo toolings and products, AppSync‚Äôs solutions, Prisma, OneGraph, Hasura, Postgraphile or any other tool ‚Äî we want to make the GraphQL CLI the best supporting tool for your stack.\n\n> ### We won‚Äôt impose any choices on the users. We want the community to lead and have template generators for any technology.\n\nThis project is completely open and free from any bias and we are open to any feedback and collaboration with anyone from the community. Please reach out!\n\n# Example use cases of GraphQL CLI\n\nThe CLI gives you the ability to build a base template with your favorite stack and tools.\n\nTemplates can be based on graphql.js, Apollo, Nexus, TypeGraphQL or anything other framework. Creating a custom template may help to enforce a specific structure that fits your product and company.\n\nThe CLI comes with two default templates that provide a seamless starting point for both backend and frontend, both could be pushed to production in a short time period.\n\nAdditionally, for existing applications, the CLI will support migrating existing databases or REST API to GraphQL.\n\n## Production-ready GraphQL app in seconds\n\n> Or ‚ÄúMaking GraphQL easy ‚Äî From nothing to a full production-ready app in 2 minutes ‚Äî with any stack!‚Äù\n\nThere are many great GraphQL boilerplate repositories on available Github.\n\nBut when using those, it is often hard to adjust those to real business cases.\n\nAs an alternative to sample apps, developers can rely on frameworks that provide a high level of abstraction.\n\nBut technologies that offer rapid application development might often come at the cost of the maintenance and flexibility that can seriously limit the extensibility of your application server.\n\n```\n$ graphql init\n```\n\nWe believe that making it easy to start with GraphQL is extremely important, but without sacrificing other factors like extensibility, scalability and wider control.\n\n> **Simple shouldn‚Äôt equal bad architecture.**\n>\n\nGraphQL CLI addresses this very important problem in the core by utilizing two main concepts: code generation and rich ecosystem of base templates.\n\nThe `graphql init` command is trying to address three simple questions:\n\n\n-   _Can we build an application template that can offer production-ready capabilities and yet is simple enough to work without extensive learning?_\n\n-   _Can we provide our data model as input to the GraphQL engine and benefit from autogenerated data access methods?_\n\n-   _Can we use the same techniques for an existing application and generate partial models?_\n\n\n> ### You can think of it as a smarter `create-react-app`, that works on a full-stack and understands your data model.\n>\n\nWe are calling leading boilerplate creators and frameworks to collaborate with us. We can help you expose your boilerplates also as templates for the init command.\n\nWe would also love feedback from internal infrastructure teams from companies who wish to create their own best practices and guidelines.\n\nFor more information please refer to [https://github.com/aerogear/graphback](https://github.com/aerogear/graphback/)\n\n\n## One config to rule them all ‚Äî GraphQL Config\n\n_At the heart of a project created using GraphQL CLI is the GraphQL Config file. It lets the CLI know where all of the GraphQL parts are._\n\n\nConfig is essential for CLI templates and for the command creators that can utilize its extensibility to save additional metadata. Thanks to [`graphql-config`](https://graphql-config.com), the CLI can provide seamless support for every extension and streamline development experience on top of the GraphQL CLI generated projects and corresponding templates.\n\n\n_For more information about GraphQL Config, you can [click here to learn more.](https://graphql-config.com)_\n\n\n## Migration from 3.x.x to 4.x.x\n\nWe have provided a complete migration document for existing users who wish to update to the latest version of the CLI. Please keep in mind that CLI is still in the alpha phase and we are looking for the feedback before officially releasing a final version of the CLI.\n\nPlease follow <https://github.com/Urigo/graphql-cli/blob/master/MIGRATION.md> migration guide.\n\n\n---\n\n# Help us to shape the GraphQL ecosystem\n\nStart using the GraphQL CLI today!\n\nEven though we are in an alpha phase, the CLI is fully usable and ready for the community to adopt it.\n\nOur team is open to any suggestions and ideas for new commands.\n\n> We will support and answer all your questions on [Github](https://github.com/urigo/graphql-cli) and on our [Discord channel](https://discord.gg/xud7bH9).\n>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"3f41cf86b8b0\",\"publishedDate\":1572531217755,\"url\":\"https://medium.com/the-guild/graphql-cli-3f41cf86b8b0\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDoxNDo1MSswMTowMM4izlPE",
            "node": {
              "title": "The Guild is taking over maintenance of merge-graphql-schemas, so let‚Äôs talk about GraphQL Schema management",
              "body": "How stitching, federation and modules all fit together?\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*_wzuTgyI7I6asXpj-BhQfQ.png?raw=true \"merge-graphql-schemas as a new home\")\n\n# TL;DR\n\n-   After many years of supporting the community, the OK-Grow! Team is transferring ownership and maintenance of [**merge-graphql-schemas**](https://github.com/urigo/merge-graphql-schemas) to The Guild\n\n-   [merge-graphql-schemas](https://github.com/urigo/merge-graphql-schemas) will be added to the existing Schema management tools already created by [**The Guild**](https://github.com/the-guild-org) ([GraphQL-Toolkit](https://github.com/ardatan/graphql-toolkit), [GraphQL Modules](https://github.com/urigo/graphql-modules), [GraphQL Inspector](https://github.com/kamilkisiela/graphql-inspector) and [graphql-code-generator](https://graphql-code-generator.com/))\n\n-   This is a continuation of making order in the schema management tools across the ecosystem\n-   If you are at GraphQL-Conf this week, come say hi\n\n[merge-graphql-schemas](https://github.com/urigo/merge-graphql-schemas) is a popular library in the GraphQL Ecosystem.\n\n\nIt‚Äôs one of the first tools people encounter once they went through their first GraphQL implementation and start to wonder how to organize their GraphQL server code.\n\nThe OK-Grow! Team has been maintaining that library for years, filling a needed gap in the ecosystem.\n\nAt the same time, [The Guild](https://github.com/the-guild-org) has been working on [similar tools](https://github.com/the-guild-org/Stack) around GraphQL schema and module management.\n\n\nToday we are happy to announce that we are joining forces and merging our efforts to create open source, easy and scalable solutions for GraphQL servers.\n\nIn a couple of days of work we‚Äôve refactored the underlying implementation of [merge-graphql-schemas](https://github.com/urigo/merge-graphql-schemas) to use [GraphQL-Toolkit](https://github.com/ardatan/graphql-toolkit) under the hood, we can close around 90% of the open issues on the library while making sure all existing tests are passing!\n\n\nWe are happy to announce a new beta release (1.6.0-beta) is out!\n\nIf you are a user of [merge-graphql-schemas](https://github.com/urigo/merge-graphql-schemas) please give the new version a try before we make a full release.\n\n\n```\nyarn add merge-graphql-schemas@next\n```\n\n# What‚Äôs next?\n\nThe Guild has been busy for a while creating scalable GraphQL solutions around schema and modules management for large teams.\n\nThe main issue we see today in the ecosystem is that there is no clear overview of which tools solve which problem area.\n\nIn order to make sure we solve the right issues in the right place, we need clear boundaries between the different libraries and solutions.\n\nLet‚Äôs try to break down the different areas of solutions needed when splitting GraphQL schemas:\n\n-   Building and executing GraphQL according to spec ‚Äî **The Engine**\n\n-   Structuring multiple building blocks of the same server into a single executable schema ‚Äî **GraphQL Tools and Frameworks**\n\n-   Structuring multiple servers instances into a single executable schema ‚Äî **Federation**\n\n\nNow we can gather all use cases from the community, put them as tests on the right library and make sure we solve each one of them.\n\n# The Engine\n\nThe Engine (in the Javascript world the most popular one is [graphql.js](https://github.com/graphql/graphql-js)) should be responsible of taking a ready schema and resolvers, validate the objects, introspecting them and executing documents against them at runtime.\n\n\nThat GraphQLSchema input must be strictly valid according to the GraphQL Spec.\n\nThat‚Äôs why manipulating a ready GraphQLSchema object can be hard. GraphQLSchema object should be the final object to input the engine.\n\nThe Engine should not care or help you create that final schema or resolvers.\n\n# GraphQL Management Tooling\n\nWe can think of the Engine like a Web Browser ‚Äî It is responsible of taking a spec (Javascript and HTML) and execute it in a consistent way.\n\nBut the browser doesn‚Äôt care about how you create that Javascript and HTML bundle.\n\nThat means that like we use babel, Typescript or frameworks for manipulating code to generate spec-compliant output, we can do the same for GraphQL with [graphql.js](https://github.com/graphql/graphql-js) as our target ‚Äúbrowser‚Äù.\n\n\nThose tools should help you organize and manage your code in your preferred way, without needing to be bound by what [graphql.js](https://github.com/graphql/graphql-js) expects.\n\n\nOne of the main things that those tools can provide us is an easy way to split the code and the schema into small chunks and later merge them with different merging strategies.\n\nJust like Javascript frameworks, using those tools can get you very far and make it easy to handle huge codebases with many different teams.\n\n# Federation\n\nIn some scenarios you would want to run completely different servers and merge them somehow into a single GraphQL gateway.\n\nSchema stitching and [schema federation](https://www.apollographql.com/docs/apollo-server/federation/federation-spec/) are attempts to make that work less manual.\n\n\nThere are some use cases where you might want those types of solutions, but they also add a lot of complexity so it‚Äôs important to understand very well why you really can‚Äôt handle your use case in a build-tool type of solution, and to know if Federation is an end goal or a stepping point to get you further.\n\n# Breaking it all down\n\nAfter years of working with GraphQL, from small applications to managing schemas across huge corporations, creating open source tools and best practices around those, we want to share it all with the community.\n\nIn the next few weeks we will publish articles about each solution type, the tools around and when you should use what.\n\nThings like why you should split your schemas, why not, what are the existing solutions out there and when to use each one.\n\nWe will also add examples of all those use cases into our [main tutorial](https://www.tortilla.academy/Urigo/WhatsApp-Clone-Tutorial/).\n\n\nWe need you to send us your questions, use cases and ideas ‚Äî we want to make sure we cover as many use cases as possible across our libraries and other libraries we [contribute too](https://github.com/apollographql/graphql-tools/pull/1150) as well (some things might fit into graphql.js or Apollo for example).\n\n\nYou can comment here or submit issues into any of [our repositories](https://github.com/the-guild-org/Stack).\n\n\n# Thank you OK-Grow!\n\nI want to personally thank the OK-Grow! Team and specifically Paul for being a very early adopter and supporter of the GraphQL community.\n\nThe work you have done so far has been amazing and valuable and we are dedicated to continue to support our community in the best way possible.\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"46246557a225\",\"publishedDate\":1560872551959,\"url\":\"https://medium.com/the-guild/the-guild-is-taking-over-maintenance-of-merge-graphql-schemas-so-lets-talk-about-graphql-schema-46246557a225\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDoxNDo0NCswMTowMM4izlOB",
            "node": {
              "title": "Sofa ‚Äî The best way to REST (is GraphQL)",
              "body": "## Ending the REST vs GraphQL debate once and for all\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*ImnnfwJEdDIH3CtV2-U98A.gif?raw=true \"Activate REST API in a snap\")\n\n# TL;DR\n\n-   Don‚Äôt choose between REST and GraphQL ‚Äî **create a fully RESTful API automatically** from your GraphQL implementation (with a library and a single line of code)\n\n-   Get most of **the benefits of GraphQL** on the backend and frontend, while using and **exposing REST**\n\n-   **Support all your existing clients** with REST while improving your backend stack with GraphQL\n\n-   Create custom, perfectly client-aligned REST endpoints for your frontend simply by naming a route and attaching a query\n-   Stop arguing about REST vs GraphQL. Use GraphQL, generate REST and get the best from both\n-   In the other way around (REST to GraphQL) you won‚Äôt get the best of both world but less powerful, harder to maintain server implementation with some of the benefits of GraphQL. It is a good and fast start for a migration though..\n\n# Wait, WHAT!?\n\nMany articles have been written about the pros and cons of GraphQL and REST APIs and how to decide which one to use. I‚Äôm not going to repeat those here..\n\nA lot of time and energy spent by smart consultants to write those articles, read those articles, while most of them are finished with the ‚Äúit depends on your use case‚Äù summary, without actually specifying those use cases!\n\nI‚Äôve been working with REST, GraphQL and SOAP APIs for many years. So I thought, why not come up with a list of those use cases and for each one of those to check ‚Äî what can‚Äôt you do in GraphQL that you can do with REST and what you wouldn‚Äôt want to do with GraphQL and you would prefer REST.\n\nAfter creating that list, I suddenly had a thought ‚Äî what if there was another option ‚Äî what if my powerful GraphQL server could just generate a REST API for me?\n\n> ### Then I could get the best of both worlds!\n\nThe more I dived into the idea and implementation then more I realized it‚Äôs not only that we can have both types of APIs created for us, but even if we just want to expose REST APIs, and none of our clients use GraphQL, **GraphQL is the best way the create REST APIs!**\n\n\n## How does the above sentence even make sense?!\n\nUsually when we ([The Guild](https://medium.com/the-guild)) help companies and organizations to modernize their APIs, the first to understand the benefits of GraphQL are the frontend developers, for obvious reasons. But as soon as the backend developers ‚ÄúGet it‚Äù, they become the biggest advocates of the technology. But they still need to support existing clients and 3rd party partners.\n\n\nThat‚Äôs why those newly generated REST APIs get a lot of the features and benefits from the internal GraphQL implementation that make backend developers happy:\n\n-   Fully **generated documentation** that is always up-to-date (Swagger, OpenAPI and GraphiQL)\n\n-   Truly **RESTful API** out of the box\n\n-   **GraphQL Subscriptions as Webhooks**\n\n-   **Runtime validation of data** ‚Äî be 100% sure that fetched data matches schema‚Äôs and query‚Äôs structure. You send exactly what I want to send, string is a string, an object has exactly the same properties.\n\n-   Creating a custom endpoint is now a matter of choose a route name and attaching a query to it. done. **No more manual work of creating and maintaining client specific endpoints!**\n\n-   Use GraphQL‚Äôs philosophy of evolving APIs through schemas ‚Äî **no more painful V1 ‚Äî V2 API migrations.**\n\n-   Use modern technology that is easier to hire people to. Companies like Facebook, Airbnb and [others](https://graphql.org/users/) have moved to GraphQL. None of them has gone back.\n\n-   **The power of GraphQL resolvers** to create your API implementation, instead of manually written controllers from MVC\n\n\n**What I get from having resolvers?**\n\n\n-   Easier to transform data so it matches the response (GraphQL Schema). That‚Äôs because every entity has its own resolvers, so the mapping is moved into smaller pieces and reused across an entire app.\n-   GraphQL allows you to easily share data across every resolver, we call it Context.\n-   Forces you to define and resolve data in an opinionated way that actually helps building an API. It runs functions in parallel (functions that are nested at the same level), handles async and at the end, it is responsible of merging all of that into a single object, so you don‚Äôt have to think about it.\n\n# Sofa ‚Äî Use GraphQL to create RESTful APIs\n\nSo we created [Sofa](https://github.com/Urigo/SOFA) (pun intended), an open source library you install on your GraphQL server to create a fully RESTful and configurable API gateway. Use GraphQL to REST.\n\n\n## ‚ÄúHow to‚Äù tutorial\n\nLet‚Äôs create a short step by step tutorial on how to create a RESTful API.\n\nStep 1: npm install the \\`[sofa-api](https://www.npmjs.com/package/sofa-api)\\` package and add the following line of code:\n\n\n```typescript\nimport sofa from 'sofa-api';\nimport express from 'express';\n\nconst app = express();\n\napp.use(\n  sofa({ schema })\n);\n```\n\nStep 2: Go REST on a Sofa, you‚Äôre done.\n\nKamil Kisiela added Sofa to the [SpaceX GraphQL API](https://medium.com/open-graphql/migrating-spacex-api-to-graphql-e1fe69a3a8e7) implementation by Carlos Rufo, **in a single [commit](https://github.com/spacexland/api/pull/7/commits/9b50393ad33c27693d89f271ec1247715c6dcc53#diff-f41e9d04a45c83f3b6f6e630f10117fe)**.\n\n\nCheck out the fully generated [REST endpoints](https://api.spacex.land/rest/capsules), the [Swagger live documentation](https://api.spacex.land/rest/), [GraphiQL editor](https://api.spacex.land/graphql) and the [GraphiQL-Explorer](https://api.spacex.land/)!\n\n\nBy the way, what you see here is a REST API, generated on top of a GraphQL API, created on top of another REST API‚Ä¶.\n\n> ### Why did you do that for!?!?\n\n## Gradually migrating from old REST implementations\n\nThis is actually a good direction to go. In many of the companies we work with, they‚Äôve created REST API layers using old technology on top of their original web-services.\n\nBut those REST implementations are problematic (for all the obvious reasons people choose to move to GraphQL).\n\nSo our way to go is to create GraphQL implementations on top of those REST layers, migrate the clients to those implementations and then gradually remove the old RESTful layer and call the services directly.\n\nUsing Sofa made those transitions much faster because we can offer all the existing clients to migrate to our GraphQL implementation without actually using GraphQL themselves. We simply expose the same REST endpoints on top of GraphQL and they are moving to our layer happily because we can accommodate all of their requests and custom REST endpoints much faster than the original, old REST implementations.\n\n---\n\n# Give me more details\n\nSofa uses Express by default but you can use any other server framework. Sofa is also GraphQL server implementation agnostic.\n\nHead over to the [Sofa website](https://sofa-api.com) for documentation and to the [Github repository](https://github.com/Urigo/sofa) for reporting issues and helping out.\n\n\n# How Sofa works?\n\nUnder the hood, Sofa turns each field of Query and Mutation types into routes. First group of routes is available only through GET method, mutations on the other hand get POST.\n\nSofa uses GraphQL‚Äôs AST to create an operation with all possible variables (even those deeply nested) and knows exactly what to fetch. Later on it converts the request‚Äôs body into operation‚Äôs variables and execute it against the Schema. It happens locally, but it‚Äôs also possible to use an external GraphQL Server or even Apollo Link.\n\nRight now Sofa has a built-in support for [Express](https://expressjs.com) but it‚Äôs totally possible to use a different framework. The main concept stays exactly the same so only the way we handle the request differs across different server implementations.\n\n\n## GraphQL Subscriptions as Webhooks?\n\nThe way it works is simply, you start a subscription by calling a special route and you get a unique ID that later on might be used to update or even stop the subscription. Subscriptions are Webhooks. Sofa knows exactly when there‚Äôs an even happening on your API and notifies you through the endpoint you‚Äôve assigned a subscription to.\n\n## Models / Resources?\n\nIn some cases you don‚Äôt want to expose an entire object but just its id. How you‚Äôre able to do that with Sofa? You need to have two queries. First one has to return a single entity based just on its id (which would be an argument) and the second one should resolve a list of those. Also the names should match, for example a resource called User should have two queries: `user(id: ID): User` and `users: [User]`. Pretty much the same thing you would do with REST.\n\n\n```\ntype Query {\n  user(id: ID!): User\n  users: [User]\n}\n```\n\nBefore Sofa creates the routes, it looks for those Models and registers them so when the operations are built you don‚Äôt fetch everything but only an id.\n\nBut what if you want to fetch an entire object but only in few places?\n\nThere‚Äôs an option called `ignore` that allows you to do that. You simply pass a path in which you want to overwrite the default behavior.\n\n\nGiven the schema below, you would get just author‚Äôs id.\n\n```\ntype Book {\n  id: ID\n  title: String!\n  author: User!\n}\n```\n\n```\nextend type Query {\n  book(id: ID!): Book\n  books: [Book]\n}\n```\n\nWith `ignore: ['Book.author']`you end up with an entire User object.\n\n\n```\nsofa({\n  ...,\n  ignore: ['Book.author'],\n})\n```\n\n## Swagger and OpenAPI\n\nThanks to GraphQL‚Äôs type system Sofa is able to generate always up-to-date documentation for your REST API. Right now we support Swagger and its OpenAPI specification but it‚Äôs really easy to adopt different specs.\n\n```typescript\nimport sofa, { OpenAPI } from 'sofa-api';\n\nconst openApi = OpenAPI({\n  schema,\n  info: {\n    title: 'Example API',\n    version: '3.0.0',\n  },\n});\n\napp.use(\n  sofa({\n    schema,\n    onRoute(info) {\n      openApi.addRoute(info, {\n        basePath: '',\n      });\n    },\n  })\n);\n\nopenApi.save('./swagger.json');\n```\n\n# Summary\n\n[sofa-api](https://github.com/Urigo/sofa) makes it extremely easy to create a RESTful API with all the best practices of REST from a GraphQL server using all its power.\n\n\nStop wasting your life arguing about REST vs GraphQL ‚Äî Be productive, get the benefits of both worlds and move into the future of API development.\n\nI hope this would become the last REST vs. GraphQL article out there‚Ä¶. if you think it won‚Äôt, comment with a use case and let‚Äôs try it out!\n\nThanks to Kamil Kisiela for working with me on this and making this library a reality!\n\n\n> _Follow us on [**GitHub**](https://github.com/urigo/sofa) and [**Medium**](https://medium.com/the-guild), we are planning to release many more posts in the next couple of weeks about what we‚Äôve learned using **GraphQL** in recent years._\n>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"d9da6e8e7693\",\"publishedDate\":1548435958095,\"url\":\"https://medium.com/the-guild/sofa-the-best-way-to-rest-is-graphql-d9da6e8e7693\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDoxNDozMSswMTowMM4izlMD",
            "node": {
              "title": "GraphQL Modules‚Ää‚Äî‚ÄäFeature based GraphQL Modules at scale",
              "body": "![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*44e5SD72vLOc9h_Nz_Aqhg.png?raw=true \"https://graphql-modules.com/\")\n\n# GraphQL Modules ‚Äî Feature based GraphQL Modules at scale\n\nToday we are happy to announce that we are open sourcing a framework we‚Äôve been using for the past couple of months in production ‚Äî [GraphQL Modules](https://graphql-modules.com/)!\n\n\nYet another framework? well, kind of.. GraphQL Modules is a set of extra libraries, structures and guidelines around the amazing [Apollo Server 2.0](https://www.apollographql.com/docs/apollo-server/).\n\n\nYou can and should use them as completely separate packages, each one is good for different use cases, but all together they represent our current philosophy of building large scale GraphQL servers.\n\nWe would love to get feedback from the Apollo team and if they wish to use those ideas and integrate them into Apollo Server we would love to contribute. That‚Äôs why we‚Äôve developed it as a set of independent tools under a single monorepo.\n\nThe basic concept behind GraphQL Modules is to separate your GraphQL server into smaller, **reusable,** **feature based** parts.\n\n\nA basic and initial implementation of a GraphQL server usually includes:\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*BZO6RkX1KUHyH04mnWDcng.png?raw=true)\n\nA more advanced implementation will usually use a context to inject things like data models, data sources, fetchers, etc, like Apollo Server 2.0 provides us with:\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*FzIxW6sm6SOHdi1DvDSMxg.png?raw=true)\n\nUsually, for simple use cases, the example above will do.\n\nBut as applications grow, their code and schematic relationships becomes bigger and more complex, which can make schema maintenance a hard and agonizing thing to work with.\n\nSome of the more old school, MVC frameworks adds few more layers after the resolvers layer, but most of them just implement separation based technical layers: controllers, models, etc.\n\nWe argue that there is a better approach of writing your GraphQL Schema and implementation.\n\nWe believe you should **separates your GraphQL schema by modules**, or **features**, and includes anything related to a specific part of the app under a ‚Äúmodule‚Äù ‚Äî which is just a simple directory. Each one of the GraphQL Modules libraries would help you in the gradual process of doing that.\n\n\nThe modules are being defined by their GraphQL schema ‚Äî so we‚Äôve taken the ‚ÄúGraphQL First‚Äù approach lead by Apollo and combined it together with classic modularization tooling to create new ways of writing GraphQL servers!\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*SWNLOo8BKHbPP_evaq-GEw.png?raw=true)\n\nThe GraphQL Modules toolset has tools to help with:\n\n-   **Schema Separation** ‚Äî declare your GraphQL schema in smaller pieces, which you can later move and reuse.\n\n-   **Tools designed to create independent modules** ‚Äî each module is completely independent and testable, and can be shared with other applications or even open sourced if needed\n\n-   **Resolvers Composition** ‚Äî with GraphQL Modules you can write your resolver as you wish, and let the app that hosts the module to wrap the resolvers and extend them. It‚Äôs implemented with a basic middleware API, but with more flexibility. That means that you can, for example, implement your entire module without knowing about the app authentication process, and assume that `currentUser` will be injected for you by the app.\n\n-   **A clear, gradual path** from a very simple and fast, single-file modules, to scalable multi-file, multi-teams, multi-repo, multi-server modules.\n\n-   **A scalable structure for your GraphQL servers** ‚Äî managing multiple teams and features, multiple microservices and servers\n\n\nand more advanced tools, which you can choose to include when your schema gets into massive scale:\n\n-   **Communication Bridge** ‚Äî We also let you send custom messages with payload between modules ‚Äî that means you can even run modules in different microservices and easily interact between them.\n\n-   **Dependency Injection** ‚Äî Implement your resolvers, and later, only when you see fit, improve their implementation by gradually introducing dependency injection. It also includes richer toolset around testing and mocking.\n\n\n---\n\n# A Basic Example\n\nIn the following example, you can see a basic implementation for GraphQL Modules server, with 2 modules: `User` and `Chat`. Each module declares only the part that is relevant to it, and extends previously declared GraphQL types.\n\n\nSo when `User` module is loaded, the `type User` is created, and when `Chat` module is loaded, the `type User` being extended with more fields.\n\n\n```typescript\nimport { GraphQLModule } from '@graphql-modules/core';\nimport { UserModule } from './user-module';\nimport { ChatModule } from './chat-module';\n\nexport const appModule = new GraphQLModule({\n  imports: [\n    UserModule,\n    ChatModule,\n  ],\n});\n```\n\n```typescript\nimport { GraphQLModule } from '@graphql-modules/core';\nimport gql from 'graphql-tag';\n\nexport const ChatModule = new GraphQLModule({\n  typeDefs: gql`\n    # Query declared again, adding only the part of the schema that relevant\n    type Query {\n      myChats: [Chat]\n    }\n\n    # User declared again- extends any other `User` type that loaded into the appModule\n    type User {\n      chats: [Chat]\n    }\n\n    type Chat {\n      id: ID!\n      users: [User]\n      messages: [ChatMessage]\n    }\n\n    type ChatMessage {\n      id: ID!\n      content: String!\n      user: User!\n    }\n  `,\n  resolvers: {\n    Query: {\n       myChats: (root, args, { getChats, currentUser }) => getChats(currentUser),  \n    },\n    User: {\n      // This module implements only the part of `User` it adds\n      chats: (user, args, { getChats }) => getChats(user), \n    },\n  },\n});\n```\n\n```typescript\nimport { appModule } from './modules/app';\nimport { ApolloServer } from 'apollo-server';\n\nconst { schema, context } = appModule;\n\nconst server = new ApolloServer({ \n  schema,\n  context,\n  introspection: true,\n});\n\nserver.listen();\n\n```\n\n```typescript\nimport { GraphQLModule } from '@graphql-modules/core';\nimport gql from 'graphql-tag';\n\nexport const UserModule = new GraphQLModule({\n  typeDefs: gql`\n    type Query {\n      me: User\n    }\n\n    # This is a basic User, with just the basics of a user object\n    type User {\n      id: ID!\n      username: String!\n      email: String!\n    }\n  `,\n  resolvers: {\n    Query: {\n       me: (root, args, { currentUser ) => currentUser,  \n    },\n    User: {\n      id: user => user._id,\n      username: user => user.username,\n      email: user => user.email.address, \n    }, \n  },\n});\n```\n\nYou can and should adopt GraphQL Modules part by part, and you can try it now with your existing GraphQL server.\n\nWhat does a ‚Äú_module_‚Äù contain?\n\n\n-   **Schema (types declaration)** ‚Äî each module can define its own Schema, and can extend other schema types (without explicitly providing them).\n\n-   **Thin resolvers implementation** ‚Äî each module can implement its own resolvers, resulting in thin resolvers instead of giant files.\n\n-   **Providers** ‚Äî each module can have its own Providers, which are just classes/values/functions that you can use from your resolvers. Modules can load and use providers from other modules.\n\n-   **Configuration** ‚Äî each module can declare a strongly-typed config object, which the consuming app can provide it with.\n\n-   **Dependencies** ‚Äî modules can be dependent on other modules (by its name or its `GraphQLModule` instance, so you can easily create an ambiguous dependency that later could be changed).\n\n\n---\n\n# GraphQL Modules libraries\n\nGraphQL Modules is built as a toolkit, with the following tools, which you should individually and gradually adopt:\n\n**@‚Äãgraphql-modules/epoxy**\n\n\n-   That will probably be the first tool you want to introduce into your server. The first step into organizing your server in a feature based structure\n-   Epoxy is a small util that manages the schema merging. it allow you to merge everything in your schema, starting from types to enums, unions, directives and so on.\n-   This is an important feature of GraphQL Modules ‚Äî you can use it to separate your GraphQL types to smaller pieces and later on combine them into a single type.\n-   We took the inspiration from [merge-graphql-schemas](https://github.com/okgrow/merge-graphql-schemas), and added some features on top of it to allow custom merging rules to make it easier to separate your schema.\n\n\n**@‚Äãgraphql-modules/core**\n\n\n-   [Resolvers Composition](https://graphql-modules.com/docs/introduction/resolvers-composition) ‚Äî manages the app‚Äôs resolvers wrapping\n\n-   [Context building](https://graphql-modules.com/docs/introduction/context) ‚Äî each module can inject custom properties to the schema, and other modules can use it (for example, auth module can inject the current user, and other modules can use it)\n\n-   [Dependency injection and module dependencies management](https://graphql-modules.com/docs/introduction/dependency-injection) ‚Äî when you start, there is no need of using DI is your server. but when your server gets big enough with a large number of modules which depends on each other, only then, DI becomes a very help thing that actually simplifies your code a lot. USE ONLY WHEN NECESSARY ;)\n\n\nYou can find more tooling at your disposal like:\n\n**@‚Äãgraphql-modules/sonar ‚Äî** a small util that helps you to find GraphQL schema and resolvers files, and include them.\n\n\n**@‚Äãgraphql-modules/logger ‚Äî** a small logger, based on [winston 3](https://github.com/winstonjs/winston), which you can easily use in your app.\n\n\n# Get Started\n\nFirst thing, don‚Äôt go full in! Start by simply moving your code into feature based folders and structures with your existing tools.\n\nThen head over to <https://graphql-modules.com/> and check out our tools and use them only when you see that they solve a real problem for you! (for us it has)\n\n\nAlso check out [the repo](https://github.com/Urigo/graphql-modules)‚Äôs README and [a number of example apps](https://github.com/Urigo/graphql-modules#examples).\n\n\nYou probably have many questions ‚Äî How does this compare to other tools, how to use those libraries with X and so on.\n\nWe will publish a series of blog posts in the coming weeks that will dive deep into each of the design decisions made here, so we want to hear your thoughts and questions, please comment here or on the [Github repository](https://github.com/urigo/graphql-modules)!\n\n\nGoing to [GraphQL Summit](https://summit.graphql.com/)? [I](https://github.com/urigo) will be there and would love to get your questions and feedback on behalf of our team.\n\n\nAll those tools were built by a passionate group of individual open source developers, otherwise known as [The Guild](https://medium.com/the-guild).\n\n\nBelow there is a section of more deep dive thoughts that we will publish separate posts about in the coming weeks:\n\n## Core Concepts and deep dive\n\n## Modularizing a schema\n\nEveryone is talking about schema stitching and GraphQL Bindings. Where does that fit into the picture?\n\nSchema stitching is an amazing ability and concept, which helps you merge separated GraphQL servers into a single endpoint and opens up a lot of exciting use cases.\n\nBut, with all the excitement, we‚Äôve missed something much more basic than that ‚Äî sometimes we still want to work on a single logical server, but we just want to separate the code according to features.\n\nWe want to be able to do most of the merging work at build time, and only if really necessary, do the rest of the merging at runtime as a last resort.\n\nWe want to split the code into separate teams and even create reusable modules which define their external APIs by a GraphQL Schema.\n\nThose modules can be npm modules, microservices or just separate folders inside a single server.\n\nSeparating your schema to smaller parts is easier when you are dealing with `typeDefs` and `resolvers`‚Äî it‚Äôs more readable and easy to understand.\n\n\nWe also wanted to allow developers to extend only specific types, without creating the entire schema. With GraphQL schema, you have to specify at least one field under `Query` type, which is something that we did not want to enforce on our users.\n\n\nWe see our approach as complementary to Schema Stitching and works together with it.\n\n## Feature-based implementation\n\nOne of the most important things in GraphQL Module‚Äôs approach is the feature-based implementation.\n\nNowadays, most frameworks are separating the layers based on the role of the layer ‚Äî such as controllers, data-access and so on.\n\nGraphQL Modules has a different approach ‚Äî separate to modules based on your server‚Äôs features, and allow it to manage its own layers within each module implementation.\n\nIt‚Äôs easier to think about apps in a modular way, for example:\n\nYour awesome app needs a basic authentication, users management, user profiles, user galleries and a chat.\n\nEach one of these could be a module, and implement its own GraphQL schema and its own logic, and it could depend on other modules to provide some of the logic.\n\nHere‚Äôs a simple example for a GraphQL Schema as we described:\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*fnGup_baJ6OhKNzNmJ8Wrw.png?raw=true)\n\nBut if we think of apps in terms of features and then separate the schema by module, the modules separation will look like so:\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*ZtOhO2PCRh6FDQanTk_yug.png?raw=true)\n\nThis way, each module can declare only the part of the schema that it contributes, and the complete schema is a representation of all merged type definitions. Module can also depend, import and extend and customize the contents on other modules (for example, `User` module, comes with `Auth` inside it)\n\n\nThe result of course, will be the same, because we are merging the schema into a single one, but the codebase will be much more organized and each module will have its own logic.\n\n## Reusability of backend modules\n\nSo now that we understood the power of feature-based implementation, it‚Äôs easier to grasp the idea behind code reusability.\n\nIf we could implement the schema and the core of Auth and User module as ‚Äúplug-and-play‚Äù ‚Äî we will be able later to import it in other projects, with very minor changes (using configuration, dependency injection, or module composition).\n\n**How could we reuse complete modules that hold part of a schema?**\n\n\nFor example, let‚Äôs take a `User` type.\n\n\nMost of `User` type schemas will contain `id`, `email` and `username` fields. The Mutation type will have `login` and the `Query` will have `user` field to query for a specific user.\n\n\nWe can re-use this type declaration.\n\nThe actual implementation might differ between apps, according to the authentication provider, database and so on, but we can still implement the business logic in a simple resolver, and use dependency injector and ask the app that‚Äôs using the module to provide the actual authentication function (of course, with a complete TypeScript interface so we‚Äôll know that we need to provide it ;) ).\n\nLet‚Äôs take it one step further. If we would like to add a profile picture to a user, we can add a new module named `UserProfile` and re-declare the `User` and `Mutation` types again:\n\n\n```graphql\ntype User {\n  profilePicture: String\n}\n\ntype Mutation {\n  uploadProfilePicture(image: File!): User\n}\n\n```\n\nThis way, GraphQL Modules will merge the fields from this `User` type into the complete `User` type, and this module will only extend the `User` type and `Mutation` type with the required actions.\n\n\nSo let‚Äôs say that we have the schema ‚Äî how can we make this module generic and re-use it?\n\nThis is how you declare this module:\n\n```typescript\nimport { GraphQLModule } from '@graphql-modules/core';\nimport gql from 'graphql-tag';\nimport { UserModule } from '../user';\nimport { Users } from '../user/users.provider';\n\nexport interface IUserProfileModuleConfig {\n  profilePictureFields ?: string;\n  uploadProfilePicture: (stream: Readable) => Promise<string>;\n}\n\nexport const UserProfileModule = new GraphQLModule<IUserProfileModuleConfig>({\n  imports: [\n    UserModule,\n  ],\n  typeDefs: gql`\n    type User {\n      profilePicture: String\n    }\n    type Mutation {\n      uploadProfilePicture(image: File!): User\n    }\n  `,\n  resolvers: config => ({\n    User: {\n      profilePicture: (user: User, args: never, context: ModuleContext) => {\n        const fieldName = config.profilePictureField || 'profilePic';\n  \n        return user[fieldName] || null;\n      },\n    },\n    Mutation: {\n      uploadProfilePicture: async (root: never, { image }: { image: any }, { injector, currentUser }: ModuleContext) => {\n        // using https://www.apollographql.com/docs/guides/file-uploads.html\n        const { stream } = await image;\n  \n        // Get the external method for uploading files, this is provided by the app as config\n        const imageUrl = config.uploadProfilePicture(stream);\n  \n        // Get the field name\n        const fieldName = config.profilePictureField || 'profilePic';\n  \n        // Ask the injector for \"Users\" token, we are assuming that `user` module exposes it for us,\n        // then, update the user with the uploaded url.\n        injector.get(Users).updateUser(currentUser, { [fieldName]: imageUrl });\n        \n        // Return the current user, we can assume that `currentUser` will be in the context because\n        // of resolvers composition - we will explain it later.\n        return currentUser;\n      },\n    },\n  }),\n});\n```\n\n> We declare a config object, and the app will provide it for us, so we can later replace it with a different logic for uploading.\n\n## Scaling the codebase\n\nNow that we broke our app into individual modules, once our codebase grows, we can scale each module individually.\n\nWhat do I mean by scaling a codebase?\n\nLet‚Äôs say we start to have code parts we want to share between different modules.\n\nThe current way of doing it in the existing GraphQL world is through a GraphQL context.\n\nThis approach has proven itself to work, but at some point it becomes a big hassle to maintain, because GraphQL context is an object, which any part of the app can modify, edit and extend, and it can become really big pretty quickly.\n\nGraphQL modules let each module extend and inject fields to the \\`context\\` object, but this is something that you should use with caution, because I recommend the \\`context\\` to contain the actual \\`context\\` ‚Äî which contains data such as global configuration, environment, the current user and so on.\n\nGraphQL modules only adds one field under the `context`, called `injector` which is the bridge that lets you access your GraphQLApp and the application Injector, and it lets you fetch your module‚Äôs config and providers.\n\n\nModules can be a simple directory in a project or in a monorepo, or it could be a published NPM module ‚Äî you have the power to choose how to manage your codebase according to your needs and preferences.\n\n## Dependency Injection\n\nGraphQL Modules‚Äô dependency injection is inspired by .NET and Java‚Äôs dependency injection which has proven itself to work pretty well over the years. With that being said, there were some issues with .NET and Java‚Äôs APIs, which we‚Äôve tried to list and go through. We ran into some pretty interesting conclusions.\n\nWe‚Äôve learn that it‚Äôs not something that should be forced. Dependency injection makes sense in some specific use cases and you should need to use it only when it‚Äôs necessary and when it helps you move faster. So this concept should come more and more in handy as we scale up, we can simplify things, maintain our code with ease and manage our teams‚Äô contributions!\n\nHaving GraphQL Modules deployed across all of our Enterprise customers while also being used on our smaller applications, lead us to believe that we‚Äôve found the optimal point of where you should use the concept of dependency injection, and when not.\n\nWe‚Äôve also came with the optimal API for dependency injection. It‚Äôs extremely easy to understand, and use.\n\nAfter a long research of the existing dependency injection solutions for JavaScript, we‚Äôve decided to implement a simple Injector, that supports the needs of GraphQL-Modules ecosystem, and support circular dependencies and more.\n\nWe‚Äôve simplified the Dependency Injection API and exposed to you only the important parts, that we believe that are necessary for a GraphQL server development.\n\n## Authentication\n\nCheck out the related blog post we wrote about it: <https://medium.com/the-guild/authentication-and-authorization-in-graphql-and-how-graphql-modules-can-help-fadc1ee5b0c2>\n\n\n## Testing and mocking\n\nOn our Enterprise applications, when we started using dependency injection, we no longer had to manage instances and bridge them together.\n\nWe gained an abstraction that allowed us to test things easier and mock all http requests.\n\nYes, mocking. DI really shines here.\n\nThanks to mocking we can simulate many scenarios and check the backend against them.\n\nAnd when your codebase grows, you need to start thinking about managing dependencies between modules and how to avoid things like circular dependencies ‚Äî unless you use DI which solves that problem for you.\n\nWith the power of dependency injection, you can easily create a loose connection between modules, and base this connection on a token and on a TypeScript interface.\n\nIt also means that testing is much easier ‚Äî you can take your class/function and test it as an independent unit, and mock its dependencies easily.\n\n# Summary\n\nWe see GraphQL Modules as the framework that finally being built from the ground up on the new and exciting capabilities of GraphQL and Apollo, while combining it in the right way with good old software best practices for scale like modularizations, strong typings and dependency injection.\n\nNow go and try it out ‚Äî <https://graphql-modules.com/>\n\n\n---\n\n# All posts about GraphQL Modules\n\n1.  [GraphQL Modules ‚Äî Feature based GraphQL Modules at scale](https://medium.com/the-guild/graphql-modules-feature-based-graphql-modules-at-scale-2d7b2b0da6da)\n\n1.  [Why is True Modular Encapsulation So Important in Large-Scale GraphQL Projects?](https://medium.com/the-guild/why-is-true-modular-encapsulation-so-important-in-large-scale-graphql-projects-ed1778b03600)\n\n1.  [Why did we implement our own Dependency Injection library for GraphQL-Modules?](https://medium.com/p/f25a234a9762)\n\n1.  [Scoped Providers in GraphQL-Modules Dependency Injection](https://medium.com/p/949cd2588e0)\n\n1.  [Writing a GraphQL TypeScript project w/ GraphQL-Modules and GraphQL-Code-Generator](https://medium.com/the-guild/writing-strict-typed-graphql-typescript-project-w-graphql-modules-and-graphql-code-generator-c22f6caa17b8)\n\n1.  [Authentication and Authorization in GraphQL (and how GraphQL-Modules can help)](https://medium.com/the-guild/authentication-and-authorization-in-graphql-and-how-graphql-modules-can-help-fadc1ee5b0c2)\n\n1.  [Authentication with AccountsJS & GraphQL Modules](https://medium.com/the-guild/authentication-with-accountsjs-graphql-modules-e0fb9799a9da)\n\n1.  [Manage Circular Imports Hell with GraphQL-Modules](https://medium.com/the-guild/manage-circular-imports-hell-with-graphql-modules-4b1611dee781)\n\n\n---\n\n> _Follow us on [**GitHub**](https://github.com/Urigo/graphql-modules) and [**Medium**](https://medium.com/the-guild), we are planning to release many more posts in the next couple of weeks about what we‚Äôve learned using **GraphQL** in recent years._\n>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"2d7b2b0da6da\",\"publishedDate\":1541425956069,\"url\":\"https://medium.com/the-guild/graphql-modules-feature-based-graphql-modules-at-scale-2d7b2b0da6da\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDoxMzo1NiswMTowMM4izlHN",
            "node": {
              "title": "Rewriting angular-meteor.com in Angular Universal",
              "body": "![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*ChqVouqofNoSwmgp_-Ytag.png?raw=true \"angular-meteor.com is now a universal app!\")\n\nWe recently finished re-writing and deploying our new [angular-meteor.com](https://angular-meteor.com/) website with completely new tooling using Angular Universal and our new tutorial infrastructure.\n\n\nIn this post, I‚Äôll share our experience using Angular Universal, and introduce the tools that we created on top of it. We‚Äôll write about (and open source) our new tutorial infrastructure in a following post, so stay tuned!\n\n## TL;DR\n\nOur former website was a dynamic app. We wanted to rewrite it into a static website because:\n\n1.  It needed a server and hosting.\n1.  We needed a lot of tooling in order to make it SEO compatible.\n1.  It loaded slowly.\n\n**We‚Äôre happy to say‚Ä¶ The transition was successful!** Check it out and take a look at the new tutorials [here](https://angular-meteor.com/).\n\n\nHere are the improvements this made possible:\n\n-   The page loads much faster\n-   No need for servers anymore, we use GitHub Pages\n\nTo accomplish this, we created a tool that takes various content types and renders it to any format we want:\n\n-   Input sources ‚Äî A unique markdown format for our tutorials and a JSDoc format.\n-   Render targets ‚Äî Our angular-meteor.com website, your own website or doc format, or a Medium post API.\n\n# Converting input sources to render outputs\n\nOur new tooling is capable of getting input sources from various content types and generating output in any format we like. Currently, we published it as a package, which includes:\n\n-   Accepting [Markdown](https://github.com/Urigo/tutorial-infrastructure/blob/master/src/steps-templates-loader.ts#L28-L42) + [Git patch](https://github.com/Urigo/tutorial-infrastructure/blob/master/src/tutorials-registry-cache.ts#L54-L85) from our tutorial infrastructure.\n\n-   Accepting [JSDoc](https://github.com/Urigo/tutorial-infrastructure/blob/master/src/api-load-resolve.ts#L20-L78).\n\n-   Angular 2 [Components](https://github.com/Urigo/tutorial-infrastructure/blob/master/src/diffbox.component.ts) and [Directives](https://github.com/Urigo/tutorial-infrastructure/blob/master/src/tutorial-navigation.component.ts), and some utils functions that relate to Angular 2, including [tutorial -> route](https://github.com/Urigo/tutorial-infrastructure/blob/master/src/tutorial-routes.ts).\n\n-   [Static website generator](https://github.com/Urigo/tutorial-infrastructure/blob/master/src/generate-static.ts) ‚Äî think about this as a NgModule to HTML files converter.\n\n\n# Tutorial as input\n\nAs part of the rewrite, we created a new tutorial infrastructure that we‚Äôll talk about in a future post when we release a few more features. You can see it in action here ‚Äî <https://angular-meteor.com/tutorials/whatsapp2/ionic/setup>\n\n\nFor the purpose of this post, the important thing to know about the infrastructure is that the code examples are being generated from a real app using real commits (inspired by Sashko Stubailo‚Äôs work [on the Meteor tutorial](https://blog.meteor.com/building-maintainable-step-by-step-tutorials-with-git-cdb6d77ea966#.lg32xh4c9)).\n\n\nThe infrastructure renders markdown files with links to the git commits, and we need to turn those into a diff-box components with the actual code that changed in the commit, like [here](https://angular-meteor.com/tutorials/whatsapp2/ionic/meteor-server-side#collections) for example.\n\n\n# JSDoc as input\n\nLet‚Äôs start again with the result of this section, so it will be simpler to understand: <https://angular-meteor.com/api/angular2-meteor/latest/Meteor-RxJS>\n\n\nWe want to use the JSDoc standard over our code ([example](https://github.com/Urigo/meteor-rxjs/blob/master/src/MeteorObservable.ts#L13-L24)), take this JSDoc definition, convert it into a standard markdown file, display it in our website, and finally expose it directly inside the repository of the package ([example](https://github.com/Urigo/meteor-rxjs/blob/master/docs/ObservableCollection.md)).\n\n\nWe wanted versioning because our API might change over time ‚Äî that‚Äôs where Git comes to our aid. We also have a Git revision (commit id or tag) for each version of the package. That way, we can take a specific version of the file with it‚Äôs documentation from GitHub and generate the API reference for all of versions of the package and API docs.\n\n# Components, Directives, and utils\n\nThe Angular 2 components and directives are meant to display results of the markdown docs together with the special Git patch handlers. This means it‚Äôs using a regular markdown parser with the small addition of DiffBox, a Component we wrote that displays the changes in each commit in a diff format (just like a diff view in GitHub).\n\nAlso, we have directives that are useful for: navigation, creating links, displaying a list of steps of the tutorial, links to download those steps (based on git commit) and more.\n\nWe also have a route generator for the tutorial, which means that, based on your tutorial definition, this util will generate your routes for the Angular router with all the required resolve phase that the infrastructure needs (load files from GitHub, format, convert and so on).\n\n# Static HTML Generator\n\nOur main output is our [angular-meteor.com](https://angular-meteor.com/) website. The utils wrap the sources with a beautiful design, custom pages and stylesheet, and then uses the last part of the infrastructure ‚Äî the static page generator.\n\n\nUsing your application‚Äôs route definition (the generated tutorial routes, along with the custom pages you need), this tool loads the entire page (generated on the server side as we‚Äôre running in an Angular Universal environment) and saves it into a single HTML file that has no dependencies at all. The whole page is inside a single HTML file ‚Äî no JS and no external CSS files!\n\nOur next step is the deployment of this website, which is easy, because we are using an autonomous HTML files that every single HTTP server can serve. We chose GitHub Pages to host our website, so we don‚Äôt need any external server or hosting.\n\n# The Result\n\nWe managed to accomplish all of our goals for the new website:\n\n**We met our own needs:**\n\n\n-   It‚Äôs easy to maintain because it uses the same GitHub repository that stores the actual tutorial code.\n-   It‚Äôs super fast and because it loads only static HTML files.\n-   Its hosting is simple (GitHub Pages) and it has no server-side at all.\n\n**We created something that might be useful for others:**\n\n\n-   Extensions to Angular Universal that can accept your own inputs and outputs.\n-   Tools for rendering markdown from remote source with Angular Universal.\n\nCheck out the website and code! Maybe you can find some utils for generating routes of API docs, or expose Components and Directives that you can use later to enrich your own website.\n\nWe saw that the Angular team has started working on a new angular.io implementation and would love to help with our tools and experiences from doing very similar work on our own website.\n\nMost importantly ‚Äî enjoy the new [angular-meteor.com](https://angular-meteor.com/) :)\n\n\n# Next steps for Angular-Meteor\n\nIn recent months, both Meteor and Angular have made huge leaps, so we have a lot of goodies to catch up on.\n\nOur vision for the next version of Angular Meteor includes the following features:\n\n-   Support for Angular CLI with [Meteor Client Bundler](https://blog.meteor.com/leverage-the-power-of-meteor-with-any-client-side-framework-bfb909141008) (already works).\n\n-   The easiest way to do lazy load in Angular with [Meteor 1.5 (code splitting and dynamic imports without configuration)](https://blog.meteor.com/dynamic-imports-in-meteor-1-5-c6130419c3cd).\n\n-   AOT out of the box.\n\nBut we want your help! If you‚Äôre interested in helping us tackle these exciting features, [contact us directly!](https://github.com/urigo)\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"9ef7c197d764\",\"publishedDate\":1493316867019,\"url\":\"https://blog.meteor.com/rewriting-angular-meteor-com-in-angular-universal-9ef7c197d764\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDoxMzo0OCswMTowMM4izlGZ",
            "node": {
              "title": "How to Use Subscriptions in GraphiQL",
              "body": "## Easily test GraphQL subscriptions from your browser\n\nThere has been a lot of buzz about GraphQL Subscriptions in the community recently, and a lot of people are excited about the [subscriptions RFC](https://dev-blog.apollodata.com/the-next-step-for-realtime-data-in-graphql-b564b72eb07b#.w9zvvcjbh) opened by Rob Zhu from Facebook.\n\n\nIf you haven‚Äôt tried GraphQL subscriptions yet, check out our docs to learn how to [add subscriptions to your existing Node.js GraphQL server](http://dev.apollodata.com/tools/graphql-subscriptions/index.html). You can also easily try building a React app with them by following [Graphcool‚Äôs tutorial](https://www.graph.cool/docs/tutorials/worldchat-subscriptions-example-ui0eizishe/).\n\n\nToday, I want to tell you about something else that‚Äôs really cool: **Did you know that [Graph_i_QL](https://github.com/graphql/graphiql) already supports subscriptions today?** Don‚Äôt believe me? Here‚Äôs a demo so you can see for yourself:\n\n\n[https://www.youtube.com/watch?v=aAwZrBgmnho](https://www.youtube.com/watch?v=aAwZrBgmnho \"GraphQL Subscriptions with GraphiQL over Githunt Demonstrating GraphQL Subscriptions support in GraphiQL over the Githunt React example.\")\n\n> Check out the working example of GitHunt with Graph**i**QL [here](https://github.com/apollographql/githunt-API) (and the React frontend [here](http://github.com/apollographql/githunt-react)).\n>\n\n## How it works\n\nThe standard GraphiQL library already supports passing in a fetcher that returns an observable _or_ promise. That means that anyone can configure it with their own transport, even if it supports multiple results. We‚Äôve already done that for you, using a new[`graphql-subscriptions-fetcher`](https://github.com/apollographql/GraphiQL-Subscriptions-Fetcher), so you don‚Äôt have to.\n\n\nThe following steps are all you need to do. (We‚Äôre using `graphql-server-express` for the example.)\n\n\nFirst, make sure you have the latest `graphql-server-express` package:\n\n\n```\nnpm install ‚Äî-save graphql-server-express\n```\n\nNow, all you need to do is to set a new field we added to `graphqlExpress` config, called `subscriptionsEndpoint`, with the Websocket URL subscriptions endpoint (this is the same endpoint you use in your `SubscriptionClient`). For example:\n\n\n```\napp.use(‚Äò/graphiql‚Äô, graphiqlExpress({\n  endpointURL: ‚Äò/graphql‚Äô,\n  subscriptionsEndpoint: `ws://localhost:3000/subscriptions`,\n}));\n```\n\nThat‚Äôs it! Finally, all you have to do is start your server, open your browser in [http://localhost:3000/graph_i_ql](http://api.githunt.com/graphiql), write a GraphQL subscriptions query inside, and the published data from the server will be pushed into your Graph_i_QL client and displayed in the result screen of Graph_i_QL.\n\n\n> This example uses GraphQL server with express ‚Äî but it also works with graphql-server-hapi, Koa, Restify and Lambda. Just add the `_subscriptionsEndpoint_` field to your GraphiQL configuration and you are good to go! You can also check out the live GitHunt example [here](http://api.githunt.com/graphiql).\n>\n\n## What if you don‚Äôt use [graphql-server](http://dev.apollodata.com/tools/graphql-server/index.html)?\n\n\nWe added the new Graph_i_QL subscriptions support to [graphql-server](http://dev.apollodata.com/tools/graphql-server/index.html) by default, but in case you‚Äôre not using it, it‚Äôs still very easy to add that support to your own server.\n\n\nGraph_i_QL is usually served as static HTML ([here‚Äôs how we do it in graphql-server](https://github.com/apollographql/graphql-server/blob/master/packages/graphql-server-module-graphiql/src/renderGraphiQL.ts#L39)), so first you need to load [`subscriptions-transport-ws`](https://github.com/apollographql/subscriptions-transport-ws) and [`graphql-subscriptions-fetcher`](https://github.com/apollographql/GraphiQL-Subscriptions-Fetcher)  inside the tag. We‚Äôve published the transport client so that it‚Äôs easy to use in a script tag from [Unpkg](https://unpkg.com/):\n\n\n```\n<script src=‚Äù//unpkg.com/subscriptions-transport-ws@0.5.4/browser/client.js‚Äù></script>\n```\n\n```\n<script src=\"//unpkg.com/graphiql-subscriptions-fetcher@0.0.2/browser/client.js\"></script>\n```\n\nNext, you need to create a `SubscriptionClient` with your subscriptions endpoint:\n\n\n```\nvar subscriptionsClient = new window.SubscriptionsTransportWs.SubscriptionClient(‚ÄòYOUR_SUBSCRIPTIONS_ENDPOINT_HERE‚Äô, { reconnect: true });\n```\n\n```\nvar subscriptionsFetcher = window.SubscriptionsTransportWs.graphQLFetcher(subscriptionsClient, graphQLFetcher);\n```\n\nFinally, replace the regular `graphqlFetcher` you use in Graph_i_QL with the one that uses the fetcher from [`graphql-subscriptions-fetcher`](https://github.com/apollographql/GraphiQL-Subscriptions-Fetcher)  when creating your Graph_i_QL instance:\n\n\n```\nReactDOM.render(\n  React.createElement(GraphiQL, {\n    fetcher: subscriptionsFetcher,\n    onEditQuery: onEditQuery,\n    onEditVariables: onEditVariables,\n    onEditOperationName: onEditOperationName,\n    query: ${safeSerialize(queryString)},\n    response: ${safeSerialize(resultString)},\n    variables: ${safeSerialize(variablesString)},\n    operationName: ${safeSerialize(operationName)},\n}), document.body);\n```\n\n[Here](https://github.com/urigo/graphql-server/blob/feat/subscriptions-graphiql/packages/graphql-server-module-graphiql/src/renderGraphiQL.ts) is a complete example of how it should look.\n\n\n## What‚Äôs happening behind the scenes?\n\n[`subscriptions-transport-ws`](https://github.com/apollographql/subscriptions-transport-ws)is a GraphQL subscriptions network transport. Loading it into Graph_i_QL client and replacing the `graphQLFetcher` function with [`graphql-subscriptions-fetcher`](https://github.com/apollographql/GraphiQL-Subscriptions-Fetcher)‚Äôs fetcher will give you a plug-and-play solution for live-stream subscriptions into your app‚Äôs Graph_i_QL editor!\n\n\n> Note that we are still using the original `_graphQLFetcher_` inside the new fetcher. We fall back to the original for GraphQL operations that aren‚Äôt subscriptions (queries and mutations).\n>\n\n## Try it today!\n\nEven though GraphQL subscriptions are still at the RFC stage, it is already being used by many companies in production, and the libraries and tools have been evolving to support a wide range of use cases. So try GraphQL subscriptions in order to add real time ability to your apps today!\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*tVIRc087V_7VlSs46TwlYQ.png?raw=true)\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"1d6ab8dbd74b\",\"publishedDate\":1491940559569,\"url\":\"https://blog.apollographql.com/how-to-use-subscriptions-in-graphiql-1d6ab8dbd74b\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDoxMzozOCswMTowMM4izlE9",
            "node": {
              "title": "Leverage the power of Meteor with any client-side framework",
              "body": "## Introduction to Meteor-Client-Bundler\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*CKGGtcy7rgOwCQ-mAFmw0g.png?raw=true \"Meteor Javascript Client bundle can run on any frontend app\")\n\nMeteor was first released back in 2011, and since then it‚Äôs been one of the most powerful platforms for web developers. It brought many new concepts to the table ‚Äî one of the more powerful ones is where the client, server and the database can share code, almost the same API and code snippets, which really accelerated the development process.\n\nThis has been a very big advantage that‚Äôs proven itself to be worthy, but has also created a misconception that Meteor is a monolith that can‚Äôt be broken down to smaller parts. But in fact, when you build a Meteor app for deployment to [Galaxy](https://www.meteor.com/hosting) or any other hosting platform, Meteor essentially generates a stand-alone Node application that you can run anywhere Node is installed. This built application can be easily consumed by a wide variety other tools that work with Node and Javascript apps.\n\n\nIn this post, I will show how you can use your existing React, Angular, or WebPack front-end app (or break up your existing Meteor front-end app away from the Meteor CLI) while still using Meteor‚Äôs benefits like Meteor Collections, Minimongo, real time updates and DDP, accounts packages and more‚Ä¶\n\n## Introducing Meteor Client Bundler\n\nTwo example scenarios could be: a) We want to use React Native‚Äôs CLI to build our client, since it provides us with native mobile components, and a configurable bundler; or b) We want to use WebPack and the great [create-react-app](https://github.com/facebookincubator/create-react-app).\n\n\nBecause we‚Äôre using Meteor, you might think we‚Äôre obligated to use the Meteor CLI, leaving WebPack‚Äôs great tools impractical to use. We can therefore ask the following question: ‚ÄúIs there a way to use WebPack, or any other similar tool, to create our client, and Meteor as our backend?‚Äù Well folks, the answer is ‚Äî YES!\n\nI present you ‚Äî [**Meteor Client Bundler**](https://github.com/Urigo/meteor-client-bundler) (it‚Äôs a long name, so we‚Äôre gonna refer it as **MCB**).\n\n\n**MCB**, as we can infer, is a module-bundler which will take a bunch of Meteor packages and bundle them into a single script, based on a specified configuration. This means we can load Meteor‚Äôs core client-script, along with other desired packages, like `mys:accounts-phone`, `jalik:ufs`, `matb33:collection-hooks` etc into any front-end app!\n\n\nThis will give us the ability to create two separate projects: one is made with WebPack CLI (the client) and other is made with Meteor‚Äôs CLI (the server). Furthermore, with a little help from bundling tools like Webpack, we can even achieve the effect of shared code snippets between the two apps, which will be shown further in this article.\n\nSome of the advantages of such a strategy are:\n\n-   Applications which are not based on Meteor can use the DDP client to fetch data from a Meteor-service\n-   We can gradually migrate outdated front-end applications into Meteor\n-   We can use other CLI tools besides Meteor‚Äôs like WebPack, Angular and Ionic CLIs and more and not be locked in on a single CLI\n-   Use Meteor when and where it excels and where it fits your needs\n\nI believe that through practical example you can get the hang of it and understand exactly what I‚Äôm talking about, by simply fulfilling the scenario described in the second paragraph.\n\n## How it works\n\nLet‚Äôs dive in! We will begin with creating our client using [create-react-app](https://github.com/facebookincubator/create-react-app), by running the following command:\n\n\n```\n$ create-react-app my-frontend-app\n```\n\nThen, we will create a web API service using Meteor‚Äôs CLI by typing the following command:\n\n```\n$ meteor create api\n```\n\nNow that they are both created, Let‚Äôs connect them to each other, so the React client will know how to use Meteor collections and retrieve data from them using MCB.\n\nFirst, you‚Äôll need to install MCB globally using NPM using the following command:\n\n```\n$ npm install -g meteor-client-bundler\n```\n\nThis will make MCB available globally as a CLI under the name `meteor-client`:\n\n\n```\n$ meteor-client ‚Äî help\n```\n\nThanks to MCB, we can create a Meteor client with all the necessary dependencies in it using the `bundle` command. The `bundle` command takes a configuration file and can be operated differently. The easiest and fastest solution would be providing it the path where the Meteor server is at, using the `-s, ‚Äî source` option:\n\n\n```\n$ meteor-client bundle ‚Äî source=api\n```\n\nThis will create a new file called `meteor-client.js` under the directory `node_modules`, which can easily be loaded anywhere in the project like so:\n\n\n```\nimport ‚Äúmeteor-client‚Äù;\n```\n\nIf you want, you can change the output destination by providing a `-d, ‚Äî destination` option:\n\n\n```\n$ meteor-client bundle ‚Äî destination=dist/meteor-client.bundle.js\n```\n\nMoreover, you don‚Äôt necessarily have to have the client and server on the same machine. The server can be hosted on a completely different computer, yet we can generate its appropriate client. This can be achieved by providing the `-c, ‚Äî config` option:\n\n\n```\n$ meteor-client bundle ‚Äî config=meteor-client.config.json\n```\n\nHere‚Äôs an example config:\n\n```\n{\n  ‚Äúruntime‚Äù: {\n    ‚ÄúDDP_DEFAULT_CONNECTION_URL‚Äù: ‚Äúhttp://127.0.0.1:8100‚Äù\n  },\n  ‚Äúimport‚Äù: [\n    ‚Äúmeteor-base@1.0.4‚Äù,\n    ‚Äúmongo@1.1.14‚Äù,\n    ‚Äúreactive-var@1.0.11‚Äù,\n    ‚Äújquery@1.11.10‚Äù,\n    ‚Äútracker@1.1.1‚Äù,\n    ‚Äústandard-minifier-css@1.3.2‚Äù,\n    ‚Äústandard-minifier-js@1.2.1‚Äù,\n    ‚Äúes5-shim@4.6.15‚Äù,\n    ‚Äúecmascript@0.6.1‚Äù,\n    ‚Äúshell-server@0.2.1‚Äù\n  ]\n}\n```\n\nEach field in the configuration file represents the following:\n\n-   **runtime** ‚Äî Meteor‚Äôs runtime config. Most commonly used to set the URL of the Meteor server we would like to interface with.\n\n-   **import** ‚Äî A list of packages we would like to include in our bundle. The bundle will also take care of loading them in the right order and with the required dependencies\n\n\nYou can also specify the server‚Äôs URL explicitly using the `‚Äî url` option:\n\n\n```\n$ meteor-client bundle ‚Äî url=http://127.0.0.1:8100\n```\n\n## **How MCB works under the hood**\n\n\nBasically, MCB takes a list of Meteor packages we would like to load in our client. Based on these, it builds a temporary Meteor application and composes a unified file from the fetched packages, with a focus in their chronological loading order.\n\n## **Still sharing Client and Server code**\n\n\nIf you‚Äôre using any sort of a configurable module bundler like Webpack, you can recreate one of Meteor‚Äôs greatest behaviors where we can load the same script on both client and server with a single definition. This will require you to add an alias for the server‚Äôs directory path, and define a special handler for imported Meteor packages. In the case of Webpack, the config extension should look like so:\n\n```\nmodule.exports = {\n  // ‚Ä¶\n  resolve: {\n    alias: [\n      api: ‚Äúpath/to/meteor/server‚Äù\n    ]\n  },\n  externals: function (context, request, callback) {\n    var match = request.match(/^meteor\\/(.+)$/);\n    var pack = match && match[1];\n    if (pack) {\n      callback(null, ‚ÄòPackage[‚Äú‚Äò + pack + ‚Äò‚Äú]‚Äô);\n    }\n  }\n  // ‚Ä¶\n};\n```\n\nThis should achieve the following result on the client:\n\n```\nImport { FooCollection, BarCollection } from ‚Äúapi/collections‚Äù;\nImport { Accounts } from ‚Äúmeteor/accounts-base‚Äù;\n```\n\nAnd at the same time, we can use almost identical importations on the server:\n\n```\nImport { FooCollection, BarCollection } from ‚Äú./collections‚Äù;\nImport { Accounts } from ‚Äúmeteor/accounts-base‚Äù;\n```\n\n## **In conclusion**\n\n\nThese were the key-concepts of Meteor Client Bundler. If you want to build an app while using the Meteor platform for all your stack, or you want to interact with a Meteor server and use any other front-end library or setup, MCB got everything you need, and will get you on the right track.\n\nFor a simple example of using MBC, check out this [React-Meteor Todo app remake](https://github.com/Urigo/React-Meteor-Todo-app) and for a more full-scale app check out the [Ionic CLI WhatsApp clone project](https://github.com/Urigo/Ionic2CLI-Meteor-WhatsApp).\n\n\nMore information regards MCB can be found in its official Github repository over here: <https://github.com/Urigo/meteor-client-bundler>\n\n\n> I want to thank Eytan Manor for helping me make this library!\n>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"bfb909141008\",\"publishedDate\":1490210149671,\"url\":\"https://blog.meteor.com/leverage-the-power-of-meteor-with-any-client-side-framework-bfb909141008\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDoxMzoyOCswMTowMM4izlDp",
            "node": {
              "title": "New release of GraphQL Subscriptions for Javascript",
              "body": "## Lifecycle events, async configuration, MQTT/Redis integrations and feedback from the community\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*OI8unw4F2B2NF37jeRaypw.png?raw=true \"Try it today from npm!\")\n\nGraphQL subscriptions are a way to add realtime data streaming to your GraphQL API. Yesterday, we wrote about an exciting new development for the community: [the new RFC to add GraphQL subscriptions to the spec](https://dev-blog.apollodata.com/the-next-step-for-realtime-data-in-graphql-b564b72eb07b#.1dax8i99c). Today, we‚Äôll talk about the new versions we recently released for our GraphQL subscriptions implementation, and the work we‚Äôve done to get to this exciting place.\n\n\n## Where subscriptions started\n\nOn the Apollo team, we‚Äôve been passionate about realtime data in GraphQL, and subscriptions in particular, for a long time. We [released the first version of our GraphQL subscriptions library](https://dev-blog.apollodata.com/graphql-subscriptions-in-apollo-client-9a2457f015fb#.lg5kcvr7u), which was the start of our exploration, almost 6 months ago in September.\n\n\nWhile we initially launched this as a feature for Apollo Client, we quickly realized there was a lot of demand for this across the community, so we put together [a proposal for a subscriptions architecture](https://dev-blog.apollodata.com/a-proposal-for-graphql-subscriptions-1d89b1934c18) that could work with any client or server.\n\n\nSince then, we‚Äôve been hard at work improving the implementation libraries, using GraphQL subscriptions internally and getting feedback from the community.\n\n## The new releases\n\nIn this post I want to talk about the latest releases:\n\n-   [graphql-subscriptions](https://github.com/apollographql/graphql-subscriptions) 0.3.0\n\n-   [subscriptions-transport-ws](https://github.com/apollographql/subscriptions-transport-ws) 0.5.0\n\n\nThese releases included lots of merged PRs and issues fixed from community members who use GraphQL subscriptions in production. We put most of the effort into areas where we had received a lot of feedback from the community:\n\n-   Improvements for authorization flows\n-   More lifecycle hooks for the client, giving more control and expression with the connection\n-   Improved websockets implementation\n-   Integration with the MQTT protocol in addition to Redis\n\nThe goal was to make a flexible implementation while keeping the app-specific code easier. On top of that, we wanted to create smaller and more modular package by splitting the subscriptions client and subscriptions server into separate bundles.\n\n# Client and server lifecycle events\n\nOne of the features most requested by the community was more lifecycle events to track both the state of a subscription and the state of the connection overall. Many of the issues we closed in the last few weeks were related to this missing feature ‚Äî and now it‚Äôs finally here.\n\nWith the new version of [subscriptions-transport-ws](https://github.com/apollographql/subscriptions-transport-ws) you can subscribe for client lifecycle events: _connect_, _disconnect_, and _reconnect_.\n\n\nThis gives client developers the ability to respond to those network changes. For example, you can let the user know the app is offline, clear state after logout, disconnect the websocket, or initiate a retry after the connection has reconnected.\n\nThe new version also adds server lifecycle events: _connect_, _disconnect_, _subscribe_, and _unsubscribe_.\n\n\nThis gives the server developer easier control over authentication logic and the ability to clean up state on the client if the server decides to terminate the connection.\n\n## New INIT transport message\n\nIn addition to independent life cycle events, in the new version of [subscriptions-transport-ws](https://github.com/apollographql/subscriptions-transport-ws), we added a new type of WebSocket message, called `INIT` , which gives developers the ability to pass custom arguments from the client to the server. You can think of this as a way to pass information would have been a header in HTTP.\n\n\nUsing this new type of message, you can create an authorized WebSocket by passing your authorization data in the initial request and writing code that accepts or rejects the connection before accepting subscriptions from the client using the `onConnect` callback.\n\n\nThe following example creates a GraphQL subscriptions client and server, using the new initialization feature and lifecycle events:\n\n## **client.js**\n\n\n```\nimport { SubscriptionClient } from ‚Äòsubscriptions-transport-ws‚Äô;\n```\n\n```\nconst getAuthToken = () => {\n  // Implement your logic to get the client‚Äôs auth details\n  return ‚ÄòDUMMY_TOKEN‚Äô;\n};\n```\n\n```\nconst wsClient = new SubscriptionClient(`SERVER_URL_HERE`, {\n  reconnect: true,\n  connectionParams: {\n    authToken: getAuthToken()\n  }\n});\n```\n\n```\nwsClient.subscribe({ query: `...` }, (errors, result) => {\n  console.log(errors, result);\n});\n```\n\n```\n// If you're using apollo, you can use `addGraphQLSubscriptions` to\n// attach this client to your network interface\n```\n\n## **server.js**\n\n\n```\nimport { SubscriptionManager, PubSub } from ‚Äògraphql-subscriptions‚Äô;\nimport { SubscriptionServer } from ‚Äòsubscriptions-transport-ws‚Äô;\nimport schema from ‚Äò./schema‚Äô;\n```\n\n```\nconst pubsub = new PubSub();\nconst subscriptionManager = new SubscriptionManager({\n  schema,\n  pubsub\n});\n```\n\n```\nconst server = createServer(); // create new connect/express server\n```\n\n```\nconst subscriptionServer = new SubscriptionServer({\n  subscriptionManager,\n  onConnect: async ({ authToken }) => {\n    const user = await validateUser(authToken);\n    if (!user) {\n      throw new Error(‚ÄòUnauthorized!‚Äô);\n    } else { \n      // The returned value will be part of the `context`\n      // for the filter functions and resolvers\n      return {\n        user\n      };\n    }\n  },\n}, {\n  server // or use existing server with different path\n});\n```\n\n# Refactor and dependency improvements\n\nWe also did some code refactor and made the API more flexible. For example, you can now use a Promise for lifecycle events, setupFunctions, setting up the pub/sub engine, and more.\n\nAlso, there is now a `addGraphQLSubscriptions` method in the client side bundle of [subscriptions-transport-ws](https://github.com/apollographql/subscriptions-transport-ws) so that developers using Apollo Client no longer need to write this code every time. This method allows you to extend your Apollo network interface to execute GraphQL subscriptions over the WebSocket transport, while using the regular network interface for queries and mutations.\n\n\nWe updated our implementation to use the [ws](https://www.npmjs.com/package/ws) package for the server side websocket implementation. This means you can also use the client if your subscriptions client is in a server-side NodeJS environment (in browser environment, it‚Äôs better to use the native implementation of your browser).\n\n\nThe new `ws` dependency is much [faster](http://websockets.github.io/ws/benchmarks.html) than our previous websocket library. It‚Äôs also smaller library and adds less overhead over the websocket standard, which means it‚Äôs easier to abstract out and change the implementation if you need to.\n\n\n# MQTT and Redis support\n\n[graphql-subscriptions](https://github.com/apollostack/graphql-subscriptions) package exports a default in-process pub/sub implementation, but for the best result in production it‚Äôs better to use an external pub/sub product, such as Redis or an MQTT service.\n\n\nWe worked with David Yahalomi to create the [graphql-redis-subscriptions](https://github.com/davidyaha/graphql-redis-subscriptions) and [graphql-mqtt-subscriptions](https://github.com/davidyaha/graphql-mqtt-subscriptions) packages, which can be easily dropped in as a replacement for the default PubSub object without making any changes to the rest of your code. Using an external pub/sub system gives you more publication features ‚Äî such as persistence, caching, delivery guarantees and other optimizations.\n\n\n# What‚Äôs next\n\nThough we‚Äôve been working on subscriptions for a while, there‚Äôs still a lot to be done. In the near future, we‚Äôre going to be making the experience of using GraphQL subscriptions a lot better:\n\n-   **GraphQL subscriptions specification.** Sashko Stubailo has been [working closely](https://dev-blog.apollodata.com/the-next-step-for-realtime-data-in-graphql-b564b72eb07b#.1dax8i99c) with the GraphQL team from Facebook to add subscriptions to the official spec. We‚Äôre incorporating the lessons we learned from using subscriptions in production and the feedback we hear from the community.\n\n-   **Documentation.** We are working on adding more documentation to our official docs site about how to add subscriptions to your app. In the meantime, the best place to read and learn about setting up GraphQL subscriptions are the [readme](https://github.com/apollographql/graphql-subscriptions/blob/master/README.md) [files](https://github.com/apollographql/subscriptions-transport-ws/blob/master/README.md) of the libraries and the [GitHunt example](https://github.com/apollographql/?utf8=%E2%9C%93&q=githunt&type=&language=) apps. **Update**: check out our new docs for [Subscriptions with React](http://dev.apollodata.com/react/subscriptions.html) and [Subscriptions with GraphQL Server](http://dev.apollodata.com/tools/graphql-subscriptions/index.html)\n\n-   **Making it easier to use subscriptions with Apollo Client.** We [plan to improve](https://github.com/apollographql/apollo-client/issues/1224) \\`updateQuery\\` and \\`updateQueries\\` and expose a simpler, yet flexible, API for updating the store when data arrives from subscriptions.\n\n-   **Real-life case studies.** Many of the improvements described in this post came from working on our internal apps that use these libraries, while also getting feedback from developers in the community who are using subscriptions in production. We‚Äôre going to tell that story in more detail soon.\n\n\nWe‚Äôre going to write many more blog posts about those experiences and lessons we learned from using GraphQL subscriptions in production. Make sure to follow our publication so you won‚Äôt miss it!\n\n---\n\nWe also want to hear more from you! Try out GraphQL subscriptions with our libraries and tell us what we should do next, and where we can best improve! And if you are _really_ interested in GraphQL subscriptions and real-time features, did you know [we‚Äôre hiring](https://www.meteor.com/careers#open-source-engineer)?\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"f11be19e6569\",\"publishedDate\":1487355315387,\"url\":\"https://blog.apollographql.com/new-release-of-graphql-subscriptions-for-javascript-f11be19e6569\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDoxMzoyMCswMTowMM4izlC0",
            "node": {
              "title": "Build a WhatsApp Clone with Ionic 2, Angular 2, and Meteor!",
              "body": "![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*ePy_CSbglLEynzp104qiCw.png?raw=true)\n\n_A version of this post was originally published on the [Ionic Blog](http://blog.ionic.io/build-a-whatsapp-clone-with-ionic-2-angular-2-and-meteor/)._\n\n\nNow, a year has passed and a lot has happened: Angular 2.0 is now stable, including astonishing amount of new features for the platform. Ionic 2.0 entered RC stage and is very close to being final. Finally, Meteor [reached version 1.4.2](http://info.meteor.com/blog/announcing-meteor-1.4.2), with many improvements the community asked for (fast build times, full npm and yarn support, Node 4.6.1 and MongoDB 3 by default, etc..).\n\n\n## New Ionic/Meteor Whatsapp Tutorials\n\nToday, I‚Äôm happy to announce we are releasing two new versions of the Ionic/Meteor Whatsapp tutorial, this time with Angular 2.0 and Ionic 2.0, one using the **Ionic CLI** and one using the **Meteor CLI.**\n\n\nIn these tutorials, we‚Äôll create a full WhatsApp clone using Angular 2 and Ionic 2. We‚Äôll use Meteor‚Äôs realtime collections for the chat and Meteor‚Äôs simple Authentication packages for SMS-based authentication.\n\nIt‚Äôs great to see the power of these two solutions working together, keeping the platforms up-to-date with the latest improvements in the Javascript ecosystem!\n\n## Angular2-Meteor\n\nBy the way, if you noticed that the [Angular-Meteor.com](https://angular-meteor.com/) website is much faster, it‚Äôs because we‚Äôve completely re-written it using Angular 2 and universal rendering to generate it as a static website. On top of that, more features are coming to Angular2-Meteor very soon, including lazy loading of modules and support for the AOT compiler.\n\n\nIf you‚Äôre thinking about migrating from Blaze to Angular2, or using them side by side, check out our [migration tutorial here](https://angular-meteor.com/tutorials/migration/angular2/introduction).\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"17aa24433cd8\",\"publishedDate\":1480492800000,\"url\":\"https://blog.meteor.com/build-a-whatsapp-clone-with-ionic-2-angular-2-and-meteor-17aa24433cd8\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDoxMzoxMiswMTowMM4izlB4",
            "node": {
              "title": "Data management and AJAX server fetching for Angular Component based apps",
              "body": "One of the most powerful concepts introduced by Angular 2 is the move to a Component based architecture.\n\nComponents are pieces of UI and logic bound together into **reusable** and **self contained** units.\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*-xibJG0BNHwXZxEvOwadIQ.png?raw=true \"Components in Angular 2 and data flow between them\")\n\nThere are two important benefits about Components:\n\n1.  We can **reuse** Components throughout our apps\n\n1.  When something changes in the inner logic and UI of a Component, it **shouldn‚Äôt affect** the other Components outside of it\n\n\nThose are great benefits, but are they still valid when we start interacting with the server?\n\nI‚Äôll argue in this article that the current way of calling the server with REST API through central Angular services is not a good fit and that co-locating queries with view logic is the natural extension to the component based architecture.\n\n## Calling the server with REST API through central services\n\nCurrently in Angular apps, in order to fetch data from the server, we usually import a service that handle the fetching logic for us:\n\n```\nvar app = angular.module('myApp', ['ngResource']);\n```\n\n```\napp.factory(\"Friend\", function($resource) {\n  return $resource(\"/api/friend/:id\");\n});\n```\n\n```\napp.controller(\"FriendListItemCtrl\", function($scope, Friend) {\n  Friend.get({ id: 1 }, function(data) {\n    $scope.friend = data;\n  });\n});\n```\n\nWhen we moved to Component based architecture, we switched the Controller to the Component class, but in most examples out there, the way we fetch data hasn‚Äôt really changed.\n\n```\n...\nimport { Headers, Http } from '@angular/http';\nimport 'rxjs/add/operator/toPromise';\n```\n\n```\nimport { Friend } from ‚Äò./friend‚Äô;\n```\n\n```\n@Injectable()\nexport class FriendService {\n  constructor(private http: Http) { }\n```\n\n```\n  getFriend(id: string): Promise<Friend[]> {\n    return this.http.get(`/api/friend/${id}`)\n                    .toPromise()\n                    .then(res => res.json().data as Friend[]);\n  }\n}\n```\n\n```\n........................\n```\n\n```\nimport { Component } from ‚Äò@angular/core‚Äô;\nimport { FriendService } from ‚Äò./friend.service‚Äô;\n```\n\n```\n...\n```\n\n```\n@Component({\n  selector: ‚Äòfriend‚Äô,\n  templateUrl: ......\n})\nexport class FriendComponent implements OnInit {\n  friend: Friend;\n```\n\n```\n  constructor(private friendService: FriendService){\n    this.friendService.getFriend(id)\n                      .then(friend => this.friend = friend);\n  }\n}\n```\n\nAnd that introduces an issue ‚Äî What happens if now we need to get different data from the server?\n\n**Let‚Äôs look at an example of the issue,** we‚Äôll use this Component tree as an example:\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*FBqKwp2v4wvhFEGYtUGDgg.jpeg?raw=true)\n\nand let‚Äôs say the we call a service on the parent \\`FriendsList\\` Component that fetches all the data for the Component tree.\n\nNow let‚Äôs ask two simple questions:\n\n1.  **What happens when we need to change Component to display new fields?**\n\n1.  **How do we reuse Component in a different place in our app and still fetch the data it needs?**\n\n\n**For the first question**, we will need to change the server endpoint to either:\n\n\n-   Change the existing one to fetch the new data (might change other Components who use the same endpoint and service)\n\nor\n\n-   Add a new endpoint with the new data structure we want and change the service to support the new endpoint\n\nIn either of those solutions ‚Äî Our Components are no longer **self contained**\n\n\n**As for the second question**, we would need to create or change the service to support the new Component tree that in under, making it **not reusable!**\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*zOY5GybNa8FxdBiLQCa9pw.png?raw=true \"A diagram I stole from a talk (referenced at the end) that shows that if child component‚Äôs AJAX requirements has changed, it will change the whole tree and the server as well\")\n\n## Needed solution\n\nSo what do we need that is missing with current solutions:\n\n1.  Each Component could **specify its own data dependencies** without knowing a central service or another parent Component in the current render tree\n\n1.  When we render a tree of Components, we will **fetch exactly** the information that this Component tree needs which is a **combination of the requirements of each Component**\n\n1.  We would do that in **one single request**\n\n1.  We need an **API layer** that will bring us **new fields without changing** existing and exposing new endpoint\n\n\n## Solution ‚Äî GraphQL Client\n\nWith GraphQL, we can **co-locate the server data requirements** for each Component, and then use a GraphQL Client like [angular2-apollo](https://github.com/apollostack/angular2-apollo) to handle the merging of those needs into one single request that gets exactly what we need.\n\n\nLet‚Äôs have a look:\n\n\n\n\n```\nimport { Component } from '@angular/core';\nimport { Angular2Apollo } from 'angular2-apollo';\nimport gql from 'graphql-tag';\n\nconst FriendsQuery = gql`\n  query getFriends {\n    friends {\n      id\n    }\n  }\n`;\n\n@Component({\n  selector: 'friends-list',\n  template: `\n    <div *ngFor=\"let friend of friends\">\n      <friends-list-item [friendId]=\"friend.id\"></friends-list-item>\n    </div>\n  `\n})\nexport class FriendsListComponent {\n  friends: FriendId[];\n\n  constructor(private apollo: Angular2Apollo) {\n    this.friends = this.apollo.watchQuery({\n      query: FriendsQuery\n    });\n  }\n}\n```\n\n\n\n\n```\nimport { Component, Input } from '@angular/core';\nimport { Angular2Apollo } from 'angular2-apollo';\nimport gql from 'graphql-tag';\n\nconst FriendItemQuery = gql`\n  query getFriendItem($id: Int!) {\n    Friend(id: $id) {\n      id\n      is_viewer_friend\n      profilePicture {\n        url      \n      }\n    }\n  }\n`;\n\n@Component({\n  selector: 'friends-list-item',\n  template: `\n    <div>\n      <img src=\"friend.profilePicture.url\"/>\n      <friend-info [friendId]=\"friend.id\"></friend-info>\n      {{friend.is_viewer_friend}}       \n    </div>\n  `\n})\nexport class FriendListItemComponent {\n  @Input() friendId: number;\n  friend: FriendListItem;\n```\n\n```\nconstructor(private  apollo: Angular2Apollo) {\n    this.friend = this.apollo.watchQuery({\n      query: FriendItemQuery,\n      variables: {id: this.friendId}\n    });\n  }  \n}\n```\n\n\n\n\n```\nimport { Component, Input } from '@angular/core';\nimport { Angular2Apollo } from 'angular2-apollo';\nimport gql from 'graphql-tag';\n\nconst FriendInfoQuery = gql`\n  query getFriendInfo($id: Int!) {\n    Friend(id: $id) {\n      id\n      name\n      mutual_friends {\n        count      \n      }\n    }\n  }\n`;\n\n@Component({\n  selector: 'friends-info',\n  template: `\n    <div>\n      <p>{{friend.name}}</p>\n      <p>{{friend.mutual_friends.count}} mutual friends</p>\n    </div>\n  `\n})\nexport class FriendInfoComponent {\n  @Input() friendId: number;\n  friend: FriendInfo;\n\n  constructor(private  apollo: Angular2Apollo) {\n    this.friend = this.apollo.watchQuery({\n      query: FriendInfoQuery,\n      variables: {id: this.friendId}\n    });\n  }  \n}\n```\n\n> this is of course not a full working app, I‚Äôll add links to full implementation at the end\n\nNow let‚Äôs get back to our original questions:\n\n1.  **What happens when we need to change Component to display new fields?**\n\n1.  **How do we reuse Component in a different place in our app and still fetch the data it needs?**\n\n\nThe answer now, is that you only need to change \\<FriendInfo> Component itself and that‚Äôs it:\n\n```\nconst FriendInfoQuery = gql`\n  query getFriendInfo($id: Int!) {\n    Friend(id: $id) {\n      id\n      name\n      mutual_friends {\n        count      \n      }\n      age\n    }\n  }\n`;\n...\n  template: `\n    <div>\n      <p>{{friend.name}}</p>\n      <p>{{friend.mutual_friends.count}} mutual friends</p>\n      <p>{{friend.age}} years old</p>\n    </div>\n  `\n})\nexport class FriendInfoComponent {\n...  \n}\n```\n\nThat‚Äôs it!\n\n-   We don‚Äôt need to change any of its parent Components\n-   We don‚Äôt need to change the API endpoint\n-   We can move it around and reuse it in any Component tree\n\nIt is now a true **reusable, self contained** Component.\n\n\n## Summary\n\nIn this article I‚Äôve tried to make the point that we should adjust our way of fetching data from the server to the new paradigms Angular 2.0 introduced.\n\nIt‚Äôs Important to note that those concepts and solutions are also true and valid in an **Angular 1.x** app that is Component based (and Apollo Client work with it as well).\n\n\nAlso, an important point is that you can use this solution alongside your regular REST services and not instead of them, add it where it fits and make sense to you.\n\n> There are many more benefits for this type of architecture and more details about how we manage those queries and app state which I‚Äôll touch on [later posts](https://medium.com/apollo-stack/)\n>\n\nHere are few notable talks and resources about those techniques, some are for React but the concepts are still the same:\n\n-   [Data fetching for React applications at Facebook](https://www.youtube.com/watch?v=9sc8Pyc51uU)\n\n-   [Modernize your Angular apps with GraphQL](https://www.youtube.com/watch?v=qpGnPbpkcZM&index=3&list=PLhCf3AUOg4PgQoY_A6xWDQ70yaNtPYtZd)\n\n-   [Angular2-Githunt example](https://github.com/apollostack/GitHunt-angular2)\n\n\n---\n\n_To learn more about how Angular works with GraphQL, hear directly from Angular core team member Jeff Cross at the upcoming [GraphQL Summit](http://graphqlsummit.com) in San Francisco on October 26th!_\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*LJ-QIT-8DRycuYjPnQnkvA.png?raw=true)\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"70aedb98244b\",\"publishedDate\":1473444565891,\"url\":\"https://blog.apollographql.com/data-management-and-ajax-server-fetching-for-angular-components-70aedb98244b\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDoxMjo0MyswMTowMM4izk-1",
            "node": {
              "title": "GraphQL as a best practice for modern Angular apps?",
              "body": "## **_Angular, meet GraphQL_**\n\n\nIn this post, I‚Äôll make the case for why Angular needs a best practice for communicating with the server, and why GraphQL should be that best practice.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*yTMBzO8zfEhKr4Lky6pjZQ.png?raw=true)\n\n## Best practices\n\nThe Angular community is establishing best practices so that we all can benefit from making our apps more performant, easier to maintain, and more modern.\n\nSome of the current best practices include composing everything into [Components](https://docs.angularjs.org/guide/component), using one-way data binding, lazy loading, having an immutable global state management (Redux & ng-rx), and more‚Ä¶\n\n\nThat is all great, and means that if we will follow those best practices our apps will behave better and will look more modern‚Ä¶\n\n‚Ä¶until we get to data fetching from the server.\n\n## Data fetching\n\nToday, whether we are developing in a large company, consulting, or writing our own app, when we fetch data from the server we are often left with old practices that don‚Äôt address the needs of a modern app.\n\nAlso, we are kind of powerless and unable to decide how the data will be supplied to our apps by the server, even though the way we fetch the data to our app is at least as meaningful to the way our app behaves as how we present it.\n\n**We should come up with best practices for data fetching that is more in line with the modern way we write our apps. These should take into consideration the following needs: data documentation, network latency, server side rendering and faster initial loading, real time communication patterns, latency compensation, and optimistic UI.**\n\n\n## REST\n\nREST is the current protocol we go around when we talking about app data fetching. REST has its benefits, but it was evolved in a time where the web was very different from today, when everything was about static HTML and forms and not about apps.\n\nHere are the areas where REST is currently lacking:\n\n-   **self documentation** ‚Äî when you send a request to a REST endpoint, there is nothing in the protocol that tells you what you are going to get (and not everyone has the resources to create a nice, updated documentation like Twitter)\n\n-   REST doesn‚Äôt support **real time data** fetching\n\n-   tough choices when designing your REST endpoint, which I‚Äôll elaborate on below\n\n**Over-fetching** ‚Äî When one endpoint serves all the data, each Component calls it again and again. This means it serves more fields than the component needed _and_ we call it many times, creating more load on the server\n\n\n**Under-fetching** ‚Äî When many endpoints serve multiple resources and fields. This creates many round trips for one Component as well as complex joins on the client.\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*d7JZJH23iJZONJV536q2iQ.png?raw=true \"The Discourse REST API ‚Äî look on the links at the bottom on the GraphQL version of this\")\n\n## Rethinking data fetching\n\nSo it looks like we need to rethink data fetching, just like we rethought web apps.\n\nLuckily, Facebook ran into the same problem in 2012 when they needed to rethink the way they fetch data as they wrote their mobile apps on top of their existing stack.\n\nThey developed a solution, and open sourced it as [GraphQL](http://graphql.org/).\n\n\n## GraphQL\n\nGraphQL is the new data communication protocol for modern apps.\n\nThe server communicates what data it can provide and the client specifies what data it needs in a **simple, graph-like structure**, in **one round trip**, no matter how deep, how complex, or how many resources the data contains.\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*vPIBVnQZAlRws-aXo6kksQ.gif?raw=true \"GraphQL has built in documentation so any server can use the GraphiQL editor without the need of setup\")\n\nThis means: one request to get exactly the information the app needs, when it needs it. **No over-fetching and under-fetching.**\n\n\nWith that, each component needs to specify its data dependencies and a client library will merge them into one request. There‚Äôs no need for a shared service with prepared fetching functions.\n\nGraphQL is also not a storage engine! You can connect it to an existing REST endpoint or SQL and NoSql databases.\n\n## Shared best practices between frameworks\n\nFor all the reasons above, GraphQL is already the best practice for fetching data with React. Also, all the Facebook apps and clients use GraphQL.\n\nIf the Angular community embraces GraphQL as a best practice, it would open the door to sharing more tools and knowledge with the React community.\n\n---\n\nTo start learning about GraphQL, take a look at these sources:\n\n-   [Why GraphQL is the future](https://medium.com/apollo-stack/why-graphql-is-the-future-3bec28193807#.3wpy7r34b)\n\n-   [The basics of GraphQL in 5 minutes](https://medium.com/apollo-stack/the-basics-of-graphql-in-5-links-9e1dc4cac055#.uvh5c43kt)\n\n-   [Replacing Discourse REST API with GraphQL](https://medium.com/apollo-stack/discourse-in-graphql-part-1-ee1ffd8a22df#.ehvb5vgl1)\n\n-   [Angular-Apollo Docs](http://docs.apollostack.com/apollo-client/angular2.html) and [Github Repo](https://github.com/apollostack/angular2-apollo)\n\n-   [Building faster modern apps with Angular and GraphQL](http://www.graphql.com/articles/angular-graphql-faster-modern-apps)\n\n\n[https://www.youtube.com/watch?v=qpGnPbpkcZM](https://www.youtube.com/watch?v=qpGnPbpkcZM \"Modernize your Angular apps with GraphQL by Uri Goldshtein How to move you stack towards the future gradually Uri is the developer of the popular angular-meteor library and core developer at Meteor. Before that Uri has worked as a programmer, team manager and architect in a large defence company building infrastructure for tactical information systems. Uri was the first employee of Bink, a startup for the banking industry, where he learned and later lectured on Angular at Google and ng-conf.\")\n\n---\n\n> Join the fastest-growing GraphQL community on [Apollo Slack](http://www.apollostack.com/#slack) or [subscribe to this publication](https://medium.com/apollo-stack) for more articles like this and get involved!\n>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"c84cb21e1037\",\"publishedDate\":1469724849492,\"url\":\"https://blog.apollographql.com/graphql-as-the-new-standard-for-modern-angular-apps-c84cb21e1037\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDoxMjoyMyswMTowMM4izk8Q",
            "node": {
              "title": "Every ‚ÄúAngular 2 vs. React‚Äù article out there",
              "body": "Something about Apples and Oranges.\n\nSome content that is being ‚Äúborrowed‚Äù from the frameworks websites about Typescript vs Javascript, JSX vs HTML, native support for both and performance that is great on both.\n\nLots of outdated information about old versions of the frameworks.\n\n## Conclusion\n\nA generic, saying nothing sentence like ‚Äúthe choice between Angular 2 and React comes down to a style preference.‚Äù\n\nBy the way, just by chance we are also mentioning our ‚Äúclickbait.js‚Äù product that let‚Äôs you work with Angular/React in the best possible way if you‚Äôll pay us tons of money.\n\nComment about our amazing article so that our SEO score will be higher!\n\nEnd.\n\nP.S. Update\n\nIt‚Äôs amazing how serious are the comments on Hacker News! <https://news.ycombinator.com/item?id=11674669>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"cfd4f557be9b\",\"publishedDate\":1462918465161,\"url\":\"https://medium.com/the-guild/every-angular-2-vs-react-article-out-there-cfd4f557be9b\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDoxMjoyMCswMTowMM4izk7w",
            "node": {
              "title": "Angular Meteor 1.3, now closer to the standard Meteor API",
              "body": "I‚Äôm excited to announce the new 1.3 release for the Angular package. This version is a huge step for working with Angular in the most native and performant way inside Meteor. Here are some of the biggest changes we made in this release:\n\n1.  Introducing a new concept called helpers that makes it easier to use standard Meteor APIs to manage your data.\n1.  Removing `autobind` to encourage people to use best practices of event handling to get better performance and easier maintainability.\n\n1.  Simplifying the package by removing non-core integration parts, like `getCamera`, which are now easier to use because of `helpers`.\n\n\nThe Angular package has become one of the most popular packages in [Atmosphere](https://atmospherejs.com/) and the new version will make the Angular Meteor community use exactly the same APIs as the rest of the community, increasing the collaboration across view technologies. The new API also makes it easier to share and migrate code and packages between Blaze and Angular.\n\n\nThis post will start with the highlights but towards the end it will dig down into all of the technical details and decisions for this release.\n\n## Give feedback\n\nWe‚Äôre constantly improving Angular Meteor, so please post your thoughts in the comments!\n\n-   Angular developers: Please let me know if the new changes are easy for you to understand and upgrade your existing apps.\n-   Blaze developers: I would love to hear your thought on the syntax, how easy or hard it will be for you to migrate and if it makes Angular a possibility for you.\n\nAlso, I would love to get feedback on the [implementation itself](https://docs.google.com/document/d/1rRV323is8YuSidgHmfHBgju-1LjzjY5iU-Ah53cdbZs/edit).\n\n\n## Try it out\n\nTo check out the new changes in action, you can clone the [Socially app](https://github.com/Urigo/meteor-angular-socially/tree/new_1.3) (the app built in the [Angular Meteor tutorial](http://www.angular-meteor.com/tutorials/socially/angular1/bootstrapping)), do the tutorial itself, or just continue reading this long post.\n\n\n-   Important point ‚Äî The credit for this version goes to [Netanel Gilad](https://github.com/netanelgilad/) and [Dotan Simha](https://github.com/dotansimha). They thought about the solutions and made the implementations. I started the conversations and reviewed at the end.\n\n\n## Features and Improvements\n\n[**Helpers**](http://www.angular-meteor.com/api/1.3.1/helpers)\n\n\nA new `helpers` syntax, which lets you use exactly the same syntax as Blaze helpers with the same Meteor code inside. No more special Angular wrappers for Mongo Collections. it gives us better integration with the rest of the community packages using the same API. For example, no need for special code to use the CollectionFS package. also, it means an easy migration for Blaze developers - even though Meteor is supporting and developing an easy way for Blaze developers to migrate to React, we also wanted to do our part and offer an easy migration path for Blaze developers both to Angular 1.x and Angular 2.0. A migration tutorial will also be published soon\n\n\nRead more about helpers [here](http://www.angular-meteor.com/api/1.3.1/helpers).\n\n\n**Reactive `subscribe` function**\n\n\nThe `subscribe` function parameters are now automatically wrapped in `autorun` to make them reactive by default and the rest of the API is exactly like Meteor.subscribe.\n\n\nRead more about subscribe [here](http://www.angular-meteor.com/api/1.3.1/subscribe).\n\n\n**$reactive**\n\n\nAll the new features use the `$reactive` service to make the reactivity abilities stem from one source.\n\n\nRead more about $reactive [here](http://www.angular-meteor.com/api/1.3.1/reactive).\n\n\n**Diff Array**\n\n\nUntil now we used our own implementation for diffing arrays and objects to change only the needed fields. Now we use an [existing 3rd party solution](https://github.com/benjamine/jsondiffpatch).\n\n\n## Migrating your app to the new API\n\nAlthough we are introducing a completely new API, **we are leaving the old API until version 1.4 so you can gradually migrate your code**. (but once we will remove the old code, you will see how little code we use right now compared to the old source).\n\n\n**Removing `autobind`**\n\n\nInstead of using `autobind` to update the scope from both directions, the `$scope` will be automatically updated from the server with `helpers` and the updates from the client will happen with the native Meteor API. We gain much better performance and easier maintainability both for the library and the apps developed with it.\n\n\n**$meteor.collection/$scope.$meteorCollection**\n\n\nThere is no need for `$meteor.collection` anymore as with the helpers function we can use regular Mongo.Collections directly without any wrappers. Helpers will make sure to update Angular.\n\n\nOld code:\n\n```\n$scope.parties = $scope.$meteorCollection(function(){ Parties.find({}, {sort: {createdAt: -1}}) });\n```\n\nNew code:\n\n```\n$scope.helpers({ parties() { return Parties.find({}, {sort: {createdAt: -1}}) } });\n```\n\nRead more about that [here](http://www.angular-meteor.com/api/1.3.0/meteorCollection).\n\n\n**$meteor.object/$scope.$meteorObject**\n\n\nThere is no need for `$meteor.object` anymore as we can use Mongo Collection‚Äôs `findOne` function.\n\n\nOld code:\n\n```\n$scope.party = $meteor.object(Parties, $stateParams.partyId);\n```\n\nNew code:\n\n```\n$scope.helpers({ party() { return Parties.findOne($stateParams.partyId); }\n```\n\n```\n});\n```\n\nRead more about that [here.](http://www.angular-meteor.com/api/1.3.0/meteorObject)\n\n\n**$meteor.subscribe/$scope.$meteorSubscribe**\n\n\nWe made some changes in the way we use subscribe. Usually when the subscription needs to get arguments that are reactive, you wrapped it with `$meteorAutorun`.\n\n\nThe new API wraps the subscriptions with `Autorun` for you, but you need to send the parameters inside an anonymous function:\n\n\nOld code:\n\n```\nangular.module(`myApp`, []).controller(`MyCtrl`, function($scope) { $scope.myVar = `name`;\n $scope.meteorAutorun(function() { $scope.meteorSubscribe(`data`, $scope.getReactively(`myVar`), 10); }); });\n```\n\nNew code:\n\n```\nangular.module('myApp', []).controller('MyCtrl', function($scope) {\n $scope.myVar = 'name'; $scope.subscribe('data', () => { return [ $scope.getReactively('myVar'), 10 ] }); // This now will trigger the subscription update! $scope.myVar = 'age'; });\n```\n\nRouting example ‚Äî old code:\n\n```\n.state('tab', { url: '/tab', abstract: true, templateUrl: 'templates/tabs.html', resolve: { chats: ['$meteor', function ($meteor) { return $meteor.subscribe('chats'); }] } })\n```\n\nRouting example ‚Äî new code:\n\n```\n.state('tab', { url: '/tab', abstract: true, templateUrl: 'templates/tabs.html', resolve: { chats: ['$q', function ($q) { var deferred = $q.defer(); Meteor.subscribe('chats', { onReady: deferred.resolve, onStop: deferred.reject }); return deferred.promise; }] } })\n```\n\nRead more about that [here](http://www.angular-meteor.com/api/1.3.1/subscribe).\n\n\n**$meteor.call**\n\n\nJust call `Meteor.call` directly and work with the callback instead of the promise. Working with callback gives you the ability to close the subscription before it‚Äôs prepared, which you can‚Äôt do right now with the current Promise API. Also, if promise is a good idea, we should add it to Meteor and not just Angular Meteor.\n\n\nOld code:\n\n```\n$meteor.call('invite', $scope.party._id, user._id).then( function(data){ console.log('success inviting', data); }, function(err){ console.log('failed', err); } );\n```\n\nNew code:\n\n```\nMeteor.call('invite', $scope.party._id, user._id, function(error, result){ if (error) { console.log('failed', err); } else { console.log('success inviting', data); } });\n```\n\nRead more about that [here](http://www.angular-meteor.com/api/1.3.0/methods).\n\n\n**$scope.getReactively**\n\n\nWe improved \\`getReactively\\` to work on any context, both on \\`$scope\\` and on \\`this\\`\n\nOld code:\n\n```\n$scope.parties = $scope.$meteorCollection(function(){ Parties.find({name : $scope.getReactively(‚Äúsearch‚Äù)}) }); $scope.search = ‚Äúnew search‚Äù; // Will trigger an update to `parties`\n```\n\nNew code:\n\n```\nthis.search = 'search';this.helpers({ parties() { Parties.find({name : this.getReactively('search')}) }, });\n```\n\n```\nthis.search = ‚Äúnew search‚Äù; // Will trigger an update to `parties`\n```\n\nRead more about that [here](http://www.angular-meteor.com/api/1.3.1/get-reactively).\n\n\n**$meteor.autorun / $scope.$meteorAutorun**\n\n\nIn the previous version of Angular-Meteor we wrapped Meteor‚Äôs autorun method, but now we put that wrapper on your context (controllerAs or $scope).\n\nAngular-Meteor will also automatically stop the autorun when the $scope is destroyed.\n\nOld Code:\n\n```\nangular.module(`myApp`, []).controller(`MyCtrl`, function($scope) { $scope.meteorAutorun(function() {\n }); });\n```\n\nNew Code:\n\nExample using $scope:\n\n```\nangular.module(`myApp`, []).controller(`MyCtrl`, function($scope) { $scope.autorun(function() {\n }); });\n```\n\nExample using `controllerAs` and components:\n\n\n```\nangular.module(`myApp`, []).directive(`myComponent`, function() { return { restrict: `E`, controllerAs: `myCtrl`, controller: function($scope, $reactive) { $reactive(this).attach($scope); this.autorun(function() {\n }); } }; });\n```\n\nExample using [angular2now](https://github.com/pbastowski/angular2-now) and ReactiveComponent:\n\n\n```\nlet {Component} = angular2now; angular.module(`myApp`); @Component({selector: `my-component`}) class myComponent extends ReactiveComponent { constructor() { super(arguments); this.autorun(function() {\n```\n\n```\n}); } }\n```\n\nRead more about that [here](http://www.angular-meteor.com/api/1.3.1/autorun).\n\n\n**$meteor.collectionFS**\n\n\nNo need for special wrapper anymore. In the previous version, we wrapped [CollectionFS](https://github.com/CollectionFS/Meteor-CollectionFS) because we needed to manage it inside Angular-Meteor just like any other collection.\n\n\nIn 1.3, we removed the $meteor.collectionFS because we no longer need it ‚Äî you can just create a helper for your collection that returns a cursor, just like any other collection.\n\nOld code:\n\n```\nangular.module(`myApp`, []).controller(`MyCtrl`, function($scope) { $scope.myImages = $scope.meteorCollectionFs(Images); $scope.subscribe(`images`); $scope.myImages.save({ ‚Ä¶ }); $scope.imageUrl = $scope.myImages[0].url(); });\n```\n\nNew code:\n\n```\nangular.module(`myApp`, []).controller(`MyCtrl`, function($scope) { $scope.subscribe(`images`); $scope.helpers({ myImages() { return Images.find({}); } }); $scope.imageUrl = $scope.myImages[0].url();\n```\n\n```\n// This is the original Meteor API for using CollectionFS Images.insert({ ‚Ä¶ }); });\n```\n\n**$meteor.getPicture ‚Äî Removed**\n\n\nYou can use the regular Meteor package. If you still want a wrapper for Meteor camera it should be in a separate package. Community packages are encouraged.\n\nRead more about that [here](http://www.angular-meteor.com/api/1.3.0/camera).\n\n\n**$meteor.session ‚Äî Removed**\n\n\nJust like all other wrappers, we would like our users to use Meteor‚Äôs API, so instead of using unnecessary wrappers you can use the Meteor API directly.\n\nOld Code:\n\n```\nangular.module(`myApp`, []).controller(`MyCtrl`, function($scope, $meteor) { $scope.myModel = 20; $meteor.session(`mySession`).bind($scope, `myModel`); });\n```\n\nNew Code:\n\n```\nangular.module(`myApp`, []).controller(`MyCtrl`, function($scope) { Session.set(`mySession`, `myValue`); $scope.helpers({ myModel() { return Session.get(`mySession`); } }); });\n```\n\nNote that you are no longer be able to bind $scope to your session! if you are using `sessions` in order to get Reactive Vars, then it‚Äôs better that you will use reactive vars in `scope` with the new `helpers` syntax.\n\n\nRead more about that [here](http://www.angular-meteor.com/api/1.3.0/session).\n\n\n**Accounts**\n\n\nAccounts is now no longer a part of Angular-Meteor core, so the following methods are no longer available:\n\n-   $rootScope.currentUser\n-   $rootScope.loggingIn\n-   $meteor.waitForUser()\n-   $meteor.requireUser()\n-   $meteor.requireValidUser(validatorFn)\n-   $meteor.loginWithPassword(user, password) ‚Äî also for all loginWith‚Ä¶\n-   $meteor.createUser(options)\n-   $meteor.changePassword(oldPassword, newPassword)\n-   $meteor.forgotPassword(options)\n-   $meteor.resetPassword(token, newPassword)\n-   $meteor.verifyEmail(token)\n-   $meteor.logout()\n-   $meteor.logoutOtherClients()\n\nInstead of these methods, you can just use Meteor‚Äôs API for those methods.\n\nWe will release a separate package with the existing functionality if anyone wants to keep using it. read more about that [here](http://www.angular-meteor.com/api/1.3.0/auth).\n\n\nFor example, in the old version you needed to use `$rootScope.currentUser` in order to get the current logged in user, and now you can use `Meteor.user()` or `Meteor.userId()`.\n\n\nOne of the usages of this wrapper was inside the view ‚Äî `$root.currentUser`, now you will have to create an helper for that using the new API we provided, for example:\n\n\nExample using `controllerAs` and components:\n\n\n```\nangular.module(`myApp`, []).directive(`myComponent`, function() { return { restrict: `E`, controllerAs: `myCtrl`, controller: function($scope, $reactive) { $reactive(this).attach($scope); this.helpers({ isLoggedIn() { return Meteor.userId() != null; }, currentUser() { return Meteor.user(); } }); } }; });\n```\n\nOne other usage of the old API was to reject the state `resolve` phase using angular-ui-router, so now you need to wrap the Meteor method with a promise created by `$q`, but don‚Äôt worry because Angular provides a simple API for creating promises.\n\n\nFor example:\n\n```\nangular.module(`myApp`, []).config(function($urlRouterProvider, $stateProvider, $locationProvider) {\n```\n\n```\n$locationProvider.html5Mode(true);\n```\n\n```\n $stateProvider.state('parties', {\n```\n\n```\nurl: '/parties',\n template: '<parties-list></parties-list>',\n resolve: {\n currentUser: ($q) => {\n var deferred = $q.defer();\n```\n\n```\n Meteor.autorun(function () {\n if (!Meteor.loggingIn()) {\n if (Meteor.user() == null) {\n deferred.reject('AUTH_REQUIRED');\n } else {\n deferred.resolve(Meteor.user());\n } }\n```\n\n```\n});\n```\n\n```\n return deferred.promise;\n }\n```\n\n```\n}\n```\n\n```\n};\n```\n\n```\n $urlRouterProvider.otherwise(\"/parties\");\n});\n```\n\nIf you still think it‚Äôs a good idea to create wrappers around those, please feel free to create a separate package for Angular Accounts, we would be happy to see those.\n\n## How it all looks together in a full component\n\n```\nangular.module('module').controller(function($scope) { $scope.search = ''; $scope.helpers({ parties() { return Parties.find({name : $scope.getReactively('search')})\n```\n\n```\n} }); $scope.subscribe('myParties', () => [$scope.getReactively('search')]); $scope.autorun(() => { console.log('current search string is: ', $scope.getReactively('search')); }); });\n```\n\nBoth the `subscribe` and the `autorun` will close automatically when the scope is destroyed.\n\n\n**Here is how it looks with the controllerAs syntax**:\n\n\n```\nangular.module(`module`).controller(function($scope, $reactive) { // extend this variable with functionality of $reactive instead of $scope $reactive(this).attach($scope); this.search = '';\n```\n\n```\nthis.helpers({ parties() { return Parties.find({name:this.getReactively('search')}) } }); this.subscribe('myParties', () => [this.getReactively('search')]); this.autorun(() => { console.log(`current search string is: `, this.getReactively('search')); }); });\n```\n\n**And with the [Angular2Now](https://github.com/pbastowski/angular2-now) syntax** ([Angular2Now](https://github.com/pbastowski/angular2-now) is a way to write Angular 1.x apps in Angular 2.0 Syntax for better practice and easier migration):\n\n\n```\nlet {Inject, Component, View} = angular2now;\n```\n\n```\nangular.module('module');\n```\n\n```\n@Component({selector: 'parties-list'})\n@Inject(['$scope, $reactive'])\n@View({templateUrl: 'parties-list.html'})\nclass partiesList {\n constructor($scope, $reactive) {\n $reactive(this).attach($scope);\n this.helpers({\n parties() { \n return Parties.find({ name: this.getReactively('search') }) \n },\n });\n```\n\n```\n this.subscribe('myParties', () => [ this.getReactively('search') ]);\n```\n\n```\n this.autorun(() => {\n console.log('Current search string is: ', this.getReactively('search'));\n });\n }\n}\n```\n\n**Example walkthrough**:\n\n\n`$scope.helpers` works just like Blaze Helpers.\n\n\nIt will make the parties properties equal to the array result of the find function.\n\nThe parties property on $scope will update as the cursor returned by `find` gets updated.\n\n\nAlso, the `search` property defined will become a `reactive` property on `$scope` when used explicitly with `getReactively`. whenever it changes the parties property will update to the new returned cursor by the anonymous function.\n\n\nIn the example above we are subscribing to the `_myParties_` publication. We are doing it using the `subscribe` function on the `scope`, which would close the subscription when the `$scope` gets destroyed.\n\n\nWe send the second parameter to subscribe as an anonymous function that returns an array of parameters that will get sent to the publication. Any reactive functions called inside that anonymous function will cause the subscription to get updates with the new values (that anonymous function is automatically wrapped in a `Meteor.autorun`).\n\n\nAlso in that example we are using an example of `$scope.autorun`. The function inside the autorun will log the current search string every time it changes. That is achieved because we set up search on the $scope using `getReactively`, which makes the Angular search variable reactive everytime it changes.\n\n\n**Docs:**\n\n\n-   We have updated the [docs](http://www.angular-meteor.com/) to the new version\n\n-   We‚Äôve added support for API versions of docs so you will be able to switch between version 1.2 and 1.3\n-   We‚Äôve changed the tutorial to use best practices by using `Angular components` and the `controllerAs syntax`\n\n-   We‚Äôve added a chapter on [Angular2Now](https://github.com/pbastowski/angular2-now) syntax to the tutorial as we think this is the best syntax to use in your Angular 1.x apps as we transition towards Angular 2\n\n-   I want to re-take the videos of the socially tutorial and also take videos for the rest of the tutorials (WhatsApp clone, Angular 2.0). would love to get help with that, even just a single chapter. please contact me if you would like to help with that\n-   We are writing a Blaze to Angular migration tutorial\n-   Now it‚Äôs easier for Angular developers to use any existing Meteor resource, like the great [Meteor guide](http://guide.meteor.com/)\n\n\n**Technical considerations and design docs for this version [can be found in this design doc](https://docs.google.com/document/d/1rRV323is8YuSidgHmfHBgju-1LjzjY5iU-Ah53cdbZs/edit).**\n\n\n[**Angular 2.0 Meteor**](http://www.angular-meteor.com/angular2):\n\n\nIn parallel, we keep updating and improving the Angular 2.0 Meteor package.\n\nBoth Angular 1.x and Blaze developers can start using Angular 2.0 Meteor right now.\n\nMy personal opinion is that it is the best and the cleanest integration with Meteor.\n\nExample:\n\n```\nimport {Parties} from 'collections/parties';\nimport {MeteorComponent} from 'angular2-meteor';\n```\n\n```\n@Component({selector: 'parties-list'})\n@View({templateUrl: 'parties-list.html'})\nclass partiesList extends MeteorComponent {\n parties: Mongo.Cursor<Party>;\n party: Party;\n```\n\n```\n constructor() {\n super();\n this.subscribe(`parties`, () => {\n this.parties = Parties.find();\n };\n this.subscribe(`parties`, partyId, () => {\n this.party = Parties.findOne(partyId);\n };\n }\n}\n```\n\n[**Angular 2.0 Meteor Design doc**](https://docs.google.com/document/d/1rRV323is8YuSidgHmfHBgju-1LjzjY5iU-Ah53cdbZs/edit) **(at the bottom)**\n\n\n## Conclusion\n\nAs I‚Äôve said at the beginning, this change is great for all Angular Meteor developers as it brings better performance. It has better support and access to resources as now you can use the same syntax and packages as the rest of the Meteor community.\n\nAngular is now one of the official view layers of Meteor and the community and adoption are increasing extremely fast. This version puts Angular support where I always wanted it to be.\n\nLooking forward we will continue to support and improve Angular 1.x Meteor and Angular 2.0 Meteor to keep Meteor as the best backend for Angular applications.\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"71bca6b80a6e\",\"publishedDate\":1449648000000,\"url\":\"https://blog.meteor.com/angular-meteor-1-3-now-closer-to-the-standard-meteor-api-71bca6b80a6e\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDoxMjoxNyswMTowMM4izk7T",
            "node": {
              "title": "Angular Meteor 1.2.0 Released",
              "body": "![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*sDjbDGF8hKvcHoCSgGClBw.png?raw=true)\n\nWe are happy to announce the release of the new angular 1.2.0 package, which takes advantage of the new build process introduced in Meteor 1.2 to make Angular developers feel even more comfortable and productive.\n\nThe main difference between older versions is that now, we use Angular to process regular `HTML` and `JS` files instead of `.ng.html` and `.ng.js.`\n\n\nWe worked hard to make migrating an existing Angular app to Meteor easier. You can migrate by simply moving your entire existing project into Meteor, or also by using your own tools and connecting to a Meteor server, like [we demonstrated with Ionic](http://blog.ionic.io/ionic-and-meteor/).\n\n\nFor existing users, as the `HTML` parsing is now happening by the `angular` package, we should rename all `.ng.html` files to `.html` and remove the `blaze-html-templates` package to reduce load time on the client.\n\n\nAlso, the new `angular` package processes `JS` files with Babel for `Ecmascript 2015` support and `ng-annotate` out of the box.\n\n\nIt also adds the `decorators` syntax from Babel so it will be easier to use the [`pbastowski:angular2-now`](https://github.com/pbastowski/angular2-now/) package. This lets you write Angular 2.0 syntax in your Angular 1.x application, which we recommend as a best practice.\n\n\nThat means we should rename all `.ng.js` files to `.js` and remove the default `ecmascript` Meteor core package from our projects.\n\n\nThe new package also uses the Meteor 1.2 caching compilers to make the build process faster.\n\nIf you are using the `accounts-ui` package, we now have [`dotansimha:accounts-ui-angular`](https://github.com/dotansimha/accounts-ui-angular) package instead.\n\n\nIf you still want to continue using the old build process and combine Blaze and Angular templates, you can use the `angular-with-blaze` package instead of the \\`angular\\` package and keep using the same `ng.html` and `ng.js` file extensions and the [`urigo:angular-blaze-template`](https://github.com/Urigo/angular-blaze-template) package to include Blaze templates inside your Angular templates.\n\n\nGoing forward to version 1.3, we will start changing our API to be directed into the best practices we‚Äôve recommended:\n\n-   Making the data API as similar as possible to the current and the future native Meteor API\n-   Removing the `autobind` feature to get better performance out of the box\n\n\nTo get ready, you can start using your `$meteor` [services](http://angular-meteor.com/api/meteorCollection) without `autobind` (sending `false` to that parameter).\n\n\nThanks for all the help we got from the community on this release!\n\n[Idan Wender](https://github.com/idanwe), [Chris Antoine](https://github.com/cantoine), [Eytan Manor](https://github.com/DAB0mB), [Caleb Cox](https://github.com/canac), [barbatus](https://github.com/barbatus), [Uri Goldshtein](https://github.com/Urigo), [Joseph Kimberger](https://github.com/kimberger), [Birk Skyum](https://github.com/birkskyum), [Tally Barak](https://github.com/Tallyb), [Dotan Simha](https://github.com/dotansimha), [Netanel Gilad](https://github.com/netanelgilad), [dinesh36](https://github.com/dinesh36), [DumpOfTheVar](https://github.com/DumpOfTheVar), [Karim Abuzaid](https://github.com/Vercryger), [marvinmarnold](https://github.com/marvinmarnold), [David Carter](https://github.com/dajocarter), [Eyal Ronel](https://github.com/EyalRonel), [MarkPhillips7](https://github.com/MarkPhillips7), [Nick Benes](https://github.com/nickbenes), [Shawn Mckay](https://github.com/ShMcK), [Erdou](https://github.com/Erdou), [Sompop Suksawat](https://github.com/ssuksawat), [Milo≈° Staniƒá](https://github.com/MilosStanic), [BEAUDRU Manuel](https://github.com/mbeaudru), [BrainCrumbz](https://github.com/BrainCrumbz), [David Yahalomi](https://github.com/davidyaha)\n\n\nPlease let me know what you think in the comments below.\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"33fc3a4a45a6\",\"publishedDate\":1447228800000,\"url\":\"https://blog.meteor.com/angular-meteor-1-2-0-released-33fc3a4a45a6\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDoxMjoxMCswMTowMM4izk6a",
            "node": {
              "title": "A Recap of AngularConnect 2015 in London",
              "body": "Last week I was invited to participate and speak at the AngularConnect conference.\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/1*fW_4Miryv7D-RRykz3OUjw.jpeg?raw=true)\n\nIt was the largest Angular conference to date with over 1000 developers and like all major Angular conferences, tickets were completely sold in a matter of minutes.\n\nI was honored to be invited to the conference by the Angular team, after doing a lot of collaboration work with them on the new [Angular 2.0 Meteor package](http://angular-meteor.com/angular2).\n\n\nAt the beginning of the conference, I was invited by [Brad Green](https://twitter.com/bradlygreen), Angular‚Äôs team manager at Google, to join his [Keynote speech](https://youtu.be/UxjgUjVpe24?t=9m56s) and talk about the blog post we wrote [comparing two top frontend frameworks](http://info.meteor.com/blog/comparing-performance-of-blaze-react-angular-meteor-and-angular-2-with-meteor]) in the industry ‚Äî Angular 1.x, Angular 2.0, React and Blaze, all written in an app on top the [Meteor Platform](https://www.meteor.com/why-meteor/features).\n\n\nOn the second day I gave a talk about the Meteor platform and how it integrates with Angular 1.x and Angular 2.0:\n\n[https://youtu.be/3FT0BqYASCo](https://youtu.be/3FT0BqYASCo \"Creating realtime apps with Angular 2 and Meteor - Uri Goldshtein AngularConnect - The official European Angular conference 2015 - http\\://angularconnect.com Premier sponsor: http\\://rangle.io Meteor is an open source JavaScript application platform for building realtime web and mobile applications. Meteor is also the perfect backend for Angular 2.0 applications. In this talk, you will learn how to create a real time full-stack Angular 2.0 Meteor app in minutes.\")\n\n[Download the slides from this session ¬ª](https://www.icloud.com/keynote/000XFHp2pQR8_LJ9BFb1RUlMQ#AngularConnect)\n\n\nI received a lot of positive feedback from fellow Angular developers about Meteor and it‚Äôs benefits to the Angular community:\n\n[https://twitter.com/juristr/status/656783455498477568?ref_src=twsrc%5Etfw](https://twitter.com/juristr/status/656783455498477568?ref_src=twsrc%5Etfw 'Juri Strumpflohner on Twitter Meteor is the huge infrastructure team you never had\" by @UriGoldshtein Focus on the frontend and let 'em do the hard stuff #angularconnect')\n\n[https://twitter.com/cassilup/status/656786242374402048/photo/1?ref_src=twsrc%5Etfw](https://twitter.com/cassilup/status/656786242374402048/photo/1?ref_src=twsrc%5Etfw \"Cassi LUP on Twitter @UriGoldshtein claims @meteorjs is the best backend for @angularjs apps. #FutureIsNow #angularconnect\")\n\n[https://twitter.com/ionutroghina/status/656787400132317185?ref_src=twsrc%5Etfw](https://twitter.com/ionutroghina/status/656787400132317185?ref_src=twsrc%5Etfw \"Ionut Roghina on Twitter The best Backend for Angular apps? Meteor, according to @UriGoldshtein. #AngularConnect #AngularJS #meteorjs\")\n\n[https://twitter.com/cassilup/status/656783227517030401?ref_src=twsrc%5Etfw](https://twitter.com/cassilup/status/656783227517030401?ref_src=twsrc%5Etfw \"Cassi LUP on Twitter Never wait for spinners again! Livequery is like $watch on your db. @UriGoldshtein crushing it with his @meteorjs talk. #angularconnect\")\n\n[https://twitter.com/designorant/status/656782326614069249/photo/1?ref_src=twsrc%5Etfw](https://twitter.com/designorant/status/656782326614069249/photo/1?ref_src=twsrc%5Etfw \"Micha≈Ç Ordon on Twitter @UriGoldshtein on stage at #AngularConnect showing @meteorjs magic!\")\n\n[https://twitter.com/ManifestoLondon/status/657553524344139777?ref_src=twsrc%5Etfw](https://twitter.com/ManifestoLondon/status/657553524344139777?ref_src=twsrc%5Etfw \"Manifesto on Twitter What's new in #Angular2? Mario Martinez's report from @AngularConnect featuring @UriGoldshtein https\\://t.co/FYVPvakQJq #Meteor\")\n\nThe conference was full of interesting talks about many new features in Angular 2.0. I‚Äôve started writing my own summary of the talks to present to the Meteor team and how Meteor could use, integrate, and be part of the new stuff that is coming from the Angular community.\n\nI would love your feedback on it! [View my notes here.](https://meteor.quip.com/5nkIAfdndFbM) It‚Äôs less of an event recap and more specifically relevant to current Meteor Developers.\n\n\nI‚Äôm very excited about the strong collaboration work of the Angular and Meteor teams and what it will bring to the whole Javascript community!\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"4bcd3c593643\",\"publishedDate\":1445583600000,\"url\":\"https://blog.meteor.com/a-recap-of-angularconnect-2015-in-london-4bcd3c593643\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDoxMTo1OSswMTowMM4izk5L",
            "node": {
              "title": "Build a WhatsApp clone with Meteor and Ionic ‚Äî Meteor Platform version",
              "body": "![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*IOU-i2x6jqoD6aZD.?raw=true)\n\n> For the newer, Angular 2 version post, [click here](https://blog.meteor.com/build-a-whatsapp-clone-with-ionic-2-angular-2-and-meteor-17aa24433cd8#.2synviq0s)‚Ä¶\n>\n\nNow that Angular is a [first class citizen in Meteor](https://blog.meteor.com/official-angular-support-with-angular-meteor-1-0-0-784f0cd7094a#.smxto0ghf), you can use all of its vast libraries, giving you full access to the Angular ecosystem.\n\n\nAlso, [Ionic recently added official support for Meteor‚Äôs packaging system](https://github.com/driftyco/ionic/pull/3133), and now their package is available on [Atmosphere](https://atmospherejs.com/driftyco/ionic).\n\n\nIn this tutorial, we will build a WhatsApp clone using Meteor, Angular, and the Ionic Framework for CSS and mobile components. I‚Äôve also released a [clone of this tutorial on the Ionic Blog](http://blog.ionic.io/ionic-and-meteor) that uses the Ionic CLI instead of the Meteor build system.\n\n\nIt‚Äôs a good resource for people who wants to use Meteor for their backend and Meteor‚Äôs client side libraries in a separate front end application, also a good migration strategy.\n\nIf you are using Blaze, you can still use Ionic‚Äôs CSS libraries or the [Meteoric package](https://atmospherejs.com/meteoric/ionic).\n\n\nContents:\n\n1.  **Installing the platform and creating a base app**\n\n1.  **WhatsApp views with static data**\n\n1.  **Create the server and share data with the client**\n\n1.  **Chat view and send messages**\n\n1.  **Users and (SMS) authentication**\n\n1.  **Create and remove chats**\n\n1.  **Privacy and publish/subscribe**\n\n1.  **Step 8 ‚Äî User profile picture**\n\n1.  **Send image messages**\n\n\n## [Start here](https://angular-meteor.com/tutorials/whatsapp2-tutorial).\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"f2f4a45af1a8\",\"publishedDate\":1444978800000,\"url\":\"https://blog.meteor.com/build-a-whatsapp-clone-with-meteor-and-ionic-meteor-platform-version-f2f4a45af1a8\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDoxMTo1MSswMTowMM4izk4D",
            "node": {
              "title": "Official Angular support with angular-meteor 1.0.0",
              "body": "As announced earlier in this [blog post](http://info.meteor.com/blog/announcing-meteor-1.2), Angular is now officially supported in Meteor 1.2.\n\n\nThat means we‚Äôve released the official `angular` [package](https://atmospherejs.com/meteor/angular)! To start using the new package just go to your Meteor console and type: `meteor add angular`\n\n\nFrom this point on, `urigo:angular` is deprecated in favor of the `angular` package.\n\n\nWe released [version 1.0.0](https://github.com/Urigo/angular-meteor/releases/) of the `angular` package which supports Meteor 1.2 as well as older versions.\n\n\n![](https://github.com/the-guild-org/oneblog/blob/master/img/704/0*d5dzP6_lD4gG9Ajn.?raw=true)\n\n## The `angular` package let's you:\n\n\n-   Use Angular templates inside a Meteor project\n-   Connect Angular and Meteor data in the most seamless way across your stack\n-   Add any existing Angular app or 3rd party libraries to Meteor\n-   Angular wrappers for all of Meteor‚Äôs API\n-   Ability to use Blaze templates inside your angular-meteor project\n\nWe‚Äôve also updated our [tutorials](http://angular-meteor.com/tutorials/angular1/bootstrapping) accordingly. On a personal note, this has been an amazing personal journey for me, working for this goal for about a year now. It‚Äôs only symbolic that we just passed the [1000 stars on Github](https://github.com/urigo/angular-meteor/) ‚Äî and it‚Äôs just the start!\n\n\n## What‚Äôs next?\n\n-   Moving to develop version 1.2.0 which will support the new build process introduced in Meteor 1.2\n-   Creating more resources on using **Angular with ES2015** which is supported by default from version 1.2\n\n-   Strengthening the **collaboration with the Angular team,** releasing an improved version of the **Angular 2.0 Meteor** integration and update the [Angular 2.0 Meteor tutorial](http://angular-meteor.com/tutorials/angular2/bootstrapping)\n\n-   **Ionic Framework** documentation ‚Äî many of our users use angular-meteor with the Ionic Framework. Ionic [just added an official release to Meteor](https://github.com/driftyco/ionic/pull/3133) and we will release two blog posts and a tutorial about how to use that in the best way.\n\n-   Code improvements by the notes of an internal **code review by Sashko**\n\n-   Like always, the roadmap will be motivated by our amazing growing community\n\nThis great accomplishment couldn‚Äôt be possible without our amazing community members and especially our contributors who submitted great PRs:\n\n[Uri Goldshtein](https://github.com/Urigo), [Androo](https://github.com/loneleeandroo), [Yago Ferrer](https://github.com/yagoferrer), [Netanel Gilad](https://github.com/netanelgilad), [ShMcK](https://github.com/ShMcK), [Alex](https://github.com/barbatus), [Dotan Simha](https://github.com/dotansimha), [Simon](https://github.com/simonv3), [Eytan Manor](https://github.com/DAB0mB), [David Yahalomi](https://github.com/davidyaha), [Tally Barak](https://github.com/Tallyb), [Fredrik Ekelund](https://github.com/fredrikekelund), [L√©o Lam](https://github.com/leoetlino), [Richard Smith](https://github.com/rjsmith), [okland](https://github.com/okland), [Radoslav Kirilov](https://github.com/smoke), [Cristiano Cortezia](https://github.com/ccortezia), [Martin McCormack](https://github.com/modcoms), [Max Bruchmann](https://github.com/mxab), [oshai](https://github.com/oshai), [Idan Wender](https://github.com/idanwe), [Mark Leusink](https://github.com/markleusink), [Emmanuel Potvin](https://github.com/epotvin), [pbastowski](https://github.com/pbastowski), [Igor Minar](https://github.com/IgorMinar), [Nieziemski](https://github.com/Nieziemski), [PeterHB999](https://github.com/PeterHB999), [sebastian kr√§mer](https://github.com/dotob),[Emanuel Nedelcu](https://github.com/EmmN), [NazarK](https://github.com/NazarK), [Pavel Potoplyak](https://github.com/ppotoplyak), [freezby](https://github.com/freezby), [Christopher Blevins](https://github.com/blevinscm), [Simon Tucker](https://github.com/srtucker22), [Jaakko Nissi](https://github.com/JNissi), [Eric Wyne](https://github.com/ecwyne), [Asaf David](https://github.com/asafdav), [Magnus Lund](https://github.com/mgnusl), [Milo≈° Staniƒá](https://github.com/MilosStanic), [Alexander Gusev](https://github.com/goooseman), [GongYi](https://github.com/topikachu), [Stoyan Revov](https://github.com/revov), [Thomas Spellman](https://github.com/thos37), [Travis Dart](https://github.com/TravisDart), [Sashko Stubailo](https://github.com/stubailo), [Diego](https://github.com/diego-vieira), [Jeremy Plack](https://github.com/stlouisweb), [Nick Janssen](https://github.com/nickjanssen),[Pierre PIRONIN](https://github.com/PierrePIRONIN), [Richard Littauer](https://github.com/RichardLitt), [Richard Lai](https://github.com/rclai), [fmachucas](https://github.com/fmachucas), [oneonestar](https://github.com/oneonestar), [Colby Tucker](https://github.com/Zeakk), [Alexander Kuzmin](https://github.com/Kuzmin), [Cedric Nicoloso](https://github.com/cedric25), [Dovydas](https://github.com/junglerocket), [Evgeniy Demidchenko](https://github.com/eugene-d), [Gil Nisan](https://github.com/gilnis2), [Ivan](https://github.com/ivanproskuryakov), [James Pieper](https://github.com/pieperz),[jonmc12](https://github.com/jonmc12), [Juan Vazquez](https://github.com/jvaz11), [Kai Haase](https://github.com/kaihaase), [Khashayar Pourdeilami](https://github.com/kpourdeilami), [Leroy Campbell](https://github.com/artisonian), [Lukas Paul](https://github.com/Unavi),[Nelieru](https://github.com/Haellsigh), [Oak Chantosa](https://github.com/digioak), [Omer Etrog](https://github.com/omer72), [Pan](https://github.com/panw), [Patrick Metzdorf](https://github.com/batjko), [dt-pward](https://github.com/dt-pward), [Peter Pavlovich](https://github.com/pavlovich), [AJ](https://github.com/AJ-Acevedo),[Robert Lachance](https://github.com/robdotis), [Sebastian Sauer](https://github.com/basti1253), [SyedWasiHaider](https://github.com/SyedWasiHaider), [The Gitter Badger](https://github.com/gitter-badger), [Thomas Farla](https://github.com/TFarla),[TzachDesign](https://github.com/TzachDesign), [dj0nes](https://github.com/dj0nes), [lucky code dog](https://github.com/cuitianze), [scresawn](https://github.com/scresawn), [thomkaufmann](https://github.com/thomkaufmann), [tschaei](https://github.com/tschaei)\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"784f0cd7094a\",\"publishedDate\":1443510000000,\"url\":\"https://blog.meteor.com/official-angular-support-with-angular-meteor-1-0-0-784f0cd7094a\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDoxMTo0MiswMTowMM4izk2r",
            "node": {
              "title": "Meteor hot code push ‚Äî with great power comes great responsibility",
              "body": "Out of the box, Meteor comes with an amazing ability called ‚Äòhot code push‚Äô. Hot code push lets you update all of your connected clients, browsers and mobile apps when the server is updated, without going through any app reviews. It‚Äôs the dream of every mobile developer who has waited 14 days to update their iOS app through Apple‚Äôs app store. But with this awesome power comes great responsibility. If handled incorrectly, hot code push can cause user experience issues in your app, like a reload of the app when the user doesn‚Äôt expect it.\n\nHere are some best practices and tips for working with Meteor‚Äôs hot code push:\n\n1.  Release to the App Store **as** often as possible. When a Meteor PhoneGap application starts, it first runs the code shipped through the App Store or Play Store and then checks for an update from the server. If there is an updated version, it is being downloaded to application‚Äôs internal storage and then the app reloads. If the initial code shipped by the App Stores is up to date, we can prevent that process from our users.\n\n1.  If you need to push new code fast, you can **control when the app reloads** with the help of the `mdg:reload-on-resume` package. The package will apply the update **only when the user closes the app and reopens it again**, without interrupting the user in the middle of his work.\n\n1.  To avoid slowing down your local development process with the reload on resume package, you can use the `arsnebula:appupdate` community package so you can still use the regular **instant hot code push while developing** your app locally.\n\n1.  Remember, you still need to handle breaking changes very carefully. Even after you have pushed a new update, there might be users who are running **older versions of your code** with different routes or schemas. So when introducing breaking changes to your schema, routes, and methods, keep in mind that you might need to support both versions of the frontend code until all users migrate.\n\n1.  Remember, **Cordova plugins are not updated by hot code push** so you will need to update your store listings in order to use the new cordova plugins. You will need to be aware of this when writing your code, and add conditionals to detect if the user has the new plugins installed.\n\n1.  To make mobile hot code push faster, try to **limit the size of files in your project**. Meteor pushes all files in the app‚Äôs client folder to the mobile device, so if you have a web app, landing page, or admin dashboard on the same meteor app, you should try to separate those into different packages where can control whether the files are built for the web browser, Cordova, or both.\n\n1.  Last but not least, you should know about `nucleuside:live-update`, which lets you hot code push specific files without reloading the whole app.\n\n\nNow you are ready to master the Hot Code Push magic! Meteor 1.2 will introduce a lot of improvements to the Cordova integration, so this workflow is going to get even better soon.\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"7e9e8f7312d5\",\"publishedDate\":1442300400000,\"url\":\"https://blog.meteor.com/meteor-hot-code-push-with-great-power-comes-great-responsibility-7e9e8f7312d5\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDoxMTozOSswMTowMM4izk2W",
            "node": {
              "title": "Thoughts on angular-meteor as a great MEAN Stack",
              "body": "_We‚Äôre delighted to announce that Uri Goldshtein, creator of the popular [angular-meteor](http://angular-meteor.com/) package ‚Äî which lets Angular developers use Meteor within their new or existing Angular applications ‚Äî has joined Meteor Development Group. Uri will be working to continue to drive integration between Meteor and Angular as part of his role to make Meteor home for Angular developers. Welcome Uri and take it away‚Ä¶_\n\n\nHi! I‚Äôm excited to join Meteor so I can make my dream of Angular and Meteor working together a reality! I‚Äôm very passionate about this dream because I think `angular-meteor` is a great MEAN stack and an option I wish I had long time ago.\n\n\nIn this post, I‚Äôll share with you why I think using Angular within the Meteor platform is a great MEAN stack for building web and mobile applications.\n\nTo get started right away just go to <http://angular-meteor.com/tutorial> and follow the tutorial.\n\n\n## What‚Äôs in a MEAN Stack?\n\nMany people look at the MEAN stack as what the acronym actually means ‚Äî Mongo, Express, AngularJS and Node. But since it was [first suggested on the MongoDB blog](http://blog.mongodb.org/post/49262866911/the-mean-stack-mongodb-expressjs-angularjs-and), a lot has changed.\n\n\nWhile Angular, Mongo and Node are getting more popular and the communities keep growing, it seems like Express‚Äô trend is going on the opposite direction. For example, hapi.js is taking a more dominant role.\n\nOn top of that, there is an increasing demand for:\n\n-   Real time updates through sockets\n-   Built-in local storage support\n-   Mobile\n\nSo perhaps today a MEAN stack is more about ‚ÄúThe best Angular, Mongo, and Node stack‚Äù than strictly the acronym per se.\n\nLet‚Äôs compare angular-meteor with the most popular implementation in the followings areas:\n\n## 1. Simplicity\n\nUsing `angular-meteor` can dramatically simplify and shorten your coding. For example I‚Äôve taken the first MEAN stack tutorial result from Google - [Thinkster‚Äôs tutorial](https://thinkster.io/mean-stack-tutorial/) and implemented it with angular-meteor.\n\n\nHere is the angular-meteor version on Github ‚Äî <https://github.com/Urigo/Thinkster-MEAN-Tutorial-in-angular-meteor>\n\n\nLet‚Äôs compare number of code lines, client and server (with the same HTML templates):\n\nThinkster‚Äôs Javascript lines: 532\n\nangular-meteor‚Äôs Javascript lines: 80\n\nSo how does Meteor creates that big difference between the other MEAN solutions?\n\nFull stack data binding\n\nIt starts with the way Angular syncs its data with the server. One of the best things about Angular is data binding, with no need for explicitly updating the UI like jQuery. That‚Äôs amazing, but when we begin to communicate with the server side, things become more complex. We need to explicitly Get, Update and Delete, write specific functions and services for that.\n\nThen, once we define those actions in the client, we need to do exactly the same on the server and handle those actions for each Model we change, again and again.. This doesn‚Äôt sound like the Angular way. It feels like jQuery all over again!\n\nWouldn‚Äôt it be easier to bind our Angular data all the way to the server and then reactively sync everything, in real time? Thats exactly what Meteor does for you when you use angular-meteor.\n\nLet‚Äôs look at this angular-meteor one liner:\n\n```\n$scope.cars = $meteor.collection(‚ÄúCars‚Äù);\n```\n\nThat‚Äôs all you need to know about http, websockets, getting, updating, and deleting data. All you need to do now is to continue updating the $scope array in Angular exactly like you did before.\n\nAll that with a single line of server code:\n\n```\nCars = new Mongo.Collection(‚Äúcars‚Äù);\n```\n\nUser Authentication\n\nSome of the existing MEAN stack solutions offer pre defined Passport.js support. Passport.js take a lot of configuration and code and works only for the server‚Äôs middleware. With angular-meteor you get full support for the Meteor accounts system.\n\nAll you need to do is to add a package with a single command, and your entire system, from UI to Model to Database, will be ready for a User facing application with Login, Logout, Signup and Reset password, all with Email support. That‚Äôs closer to Rails‚Äô devise gem than to Passport.js.\n\nSince in MEAN it‚Äôs not that simple, there are a few services that offer Authentication services to developers but in the price of not owning your data. angular-meteor is as simple as those solutions but it‚Äôs all open source and you have full control over everything.\n\nMobile Development\n\nThere is no specific methods to support mobile and PhoneGap apps in the existing stacks.\n\nMeteor has a built in PhoneGap integration for installing, running and deploying PhoneGap apps and updating them automatically, even through the app stores. And again with just a few command lines.\n\nMoreover, Angular-Meteor allows you to use any 3rd party libraries like [Ionic](https://github.com/Urigo/meteor-ionic).\n\n\n## 2. Architecture\n\nA good way to see the how Meteor‚Äôs architecture differs from the main MEAN stacks solutions is how those stacks handle real time applications. Most of the MEAN stack solutions are built on a REST architecture and not an architecture that fits real time applications. You can add sockets support to them but there is more to real time than that.\n\nLet‚Äôs look at the 4 layers comprising Meteor‚Äôs architecture ‚Äî Database, Communication, Local Storage and UI.\n\nDatabase\n\nIn order to respond to changes in real time, you have to watch the database in real time.\n\nThe other MEAN stacks don‚Äôt offer anything for recursively watching over the database.\n\nMeteor‚Äôs [‚ÄòLive Query‚Äô package](https://www.meteor.com/livequery) creates a reactive database cursor that updates in real time and notifies the server and the clients about those changes in a performant way.\n\n\nCommunication layer\n\nWhile the MEAN solutions offer some tools for real time communication like socket.io, Meteor is built upon an open, real-time communication protocol named [DDP](https://www.meteor.com/ddp). That means that you get a standard for real time communication, it‚Äôs open and simple as REST but for real time.\n\n\nThere are DDP clients in almost every major technology out there ‚Äî Javascript, Objective C, Android, C#, Go, Ruby etc.. ([More here](http://meteorpedia.com/read/DDP_Clients)) and you can easily work with them.\n\n\nLocal Storage\n\nThe MEAN solutions just offers you to choose your own solution and handle the syncing yourself. In Meteor, the whole architecture is built to support that out of the box, including making local changes in real time and later syncing them automatically over the wire in case the network is slow, which is very important for mobile apps.\n\nThere are a lot of considerations and cases to handle and most developers just don‚Äôt take care of those while Meteor takes care of that for you.\n\nUI layer\n\nWhile in the other solutions the UI communicates straight to the server, angular-meteor knows how to listen to DDP changes from the local cache and to listen to Angular changes and transmit them to the local cache for a true latency compensation architecture.\n\nMeteor‚Äôs architecture is similar to the architecture that large scale applications like Gmail, Facebook and Trello use. Angular 2.0 is built on top of those ideas because they want to better support large scale applications.\n\nThe reason why most smaller applications don‚Äôt use that architecture is because it was very expensive until now and you had to assemble those solutions yourself, but Meteor gives you that without any development cost or time.\n\nIsomorphic JavaScript and [Angular-Server](http://angular-meteor.com/server) ‚Äî Sharing code between the client and the server\n\n\nAlthough the MEAN stack is built with technologies that are based on Javascript, the solutions don‚Äôt use the Isomorphic capabilities that it brings with it. Meteor is built from the ground up taking that into consideration and gives you the ability to write lots of your code (Model, Methods and packages) once and use it both on the client and on the server.\n\nFor example, in Meteor, you define your model in a single file and that model object is available for you to use both on the client and then server.\n\nYou can also use exactly the same API to update the model both on the client and the server and write your functions once and use them everywhere. In `angular-meteor` we‚Äôve taken it one step further and let you write regular Angular code on the server, so you can use your existing knowledge and code to write server side logic.\n\n\n## Getting Started with Angular and Meteor for a MEAN Stack\n\nI believe that the biggest promise of angular-meteor is to enable Angular Front-End developers to become full stack developers.\n\nEven as an Angular developer, Meteor always made sense to me. We created `angular-meteor` so that you can use Angular, your existing applications and your 3rd party libraries (Ionic, ui-bootstrap etc.)\n\n\nSo now, if you‚Äôre an Angular developer, you can easily dive into Meteor too. Get started here: <http://angular-meteor.com/>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"1b441ad0d303\",\"publishedDate\":1432191600000,\"url\":\"https://blog.meteor.com/thoughts-on-angular-meteor-as-a-great-mean-stack-1b441ad0d303\"}\n```\n"
            }
          },
          {
            "cursor": "Y3Vyc29yOnYyOpK5MjAyMC0wMy0xOFQyMDoxMTozNiswMTowMM4izk2B",
            "node": {
              "title": "Open (source) peace talks",
              "body": "For a long time now i‚Äôve been avoiding writing about the Israel-Palestine conflict in Facebook and the public media.\n\nIt is not that I have nothing to say, it is because the more i‚Äôm growing up inside this conflict (i‚Äôve been a part of it all my life) and listening to both sides, I realize I just don‚Äôt know enough.\n\nBut to my surprise, i‚Äôm the only one who doesn‚Äôt know enough. everyone knows everything and they have the perfect solution, doesn‚Äôt matter if they are Israelis, Palestinians or people from all over the world.\n\nBut how can both sides be sure they know so much, when the other side thinks it knows so much as well and he knows completely different thing?\n\nSo how do they know? who are everyone‚Äôs sources? The news, social media and the political leaders.\n\nBut those sources are questionable ‚Äî When there are peace or ceasefire talks, the people in the room are leaders from both sides. and they all have something in common ‚Äî they are the people in power in their own country, and they want to stay that. that goal is far greater for them then to solve the conflict.\n\nWe choose our stand from the minimal information the people in power provide us. No wonder the current conversation that is happening on TV, newspapers and social media is in a very low standard and mostly a huge simplification of the problem, in both sides of the conflict.\n\nBut what we are actually doing is making things worse. By simplifying stuff, we are simplifying the other side‚Äôs needs. this is exactly the opposite of what we need to do. to solve conflicts you need to step into the other side‚Äôs shoes, not simplifying him.\n\nWe know something is not right when we look at the media and the news are so different from station to station.\n\nImagine two leaders sitting in a closed room. Each one is sending different messages about what‚Äôs happening in the room to his people. Usually imformation that makes him look good and the other side look bad. then those people fight each based on this partial information and the men in power remain the ones sitting in the closed room.\n\nWe don‚Äôt demand the knowledge we deserve! we are easy on the trigger of blaming the other side.\n\nBut how can we, the public, know enough?\n\nWe need to open our peace talks. publish it in live stream and in a public document. no more closed doors.\n\nThen, when one side is declining a solution, everyone knows exactly why. No more stories.\n\nThe people on each side have to start demanding opening the talks.\n\nI wouldn‚Äôt rely on foreign governments as people often suggest. they are also leaders, and they don‚Äôt want this ‚Äúopen‚Äù culture to spread into their own countries. no matter if they are western or eastern.\n\nThe movement needs to start from the people. we need to create a open document and start building the peace contract. after this document will pick up by people from both sides, the leadership will have to respond to that.\n\nSo here is a starting document of a peace process (can be changed into anything): <https://www.penflip.com/Urigo/peace-contract>\n\n\nPeople might say that this can prevent the process from moving forward because the public might prevent those solutions immediately and also it will be hard to publish incentives from foreign countries.\n\nI believe that a better informed public can make better choices ‚Äî there is more chance that the public will prevent a peace process that its not a part of then a one it understands and feel in power with.\n\nIt is also not something that ‚Äúwe will think about later, after the current events will calms down‚Äù. it is the thing that will make the current events calm down and not repeated again ‚Äî we need to start opening the current ceasefire talks.\n\nOnce people from both sides will start working on this open contract, the leaders couldn‚Äôt ingnore it and will have to use it at least as reference.\n\nOpen the solution for peace. <https://www.penflip.com/Urigo/peace-contract>\n\n\nEdit suggestions here: <https://www.penflip.com/Urigo/open-source-peace-talks>\n\n\n```backmatter\n{\"source\":\"medium\",\"postId\":\"a37da6c1b065\",\"publishedDate\":1407270136736,\"url\":\"https://medium.com/@urigo/open-source-peace-talks-a37da6c1b065\"}\n```\n"
            }
          }
        ]
      }
    }
  }
}
